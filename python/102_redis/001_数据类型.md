# x.01 数据类型

## redisObject

##### 编码方式

<img src=".\image\数据结构2.webp" alt="数据结构2" style="zoom:80%;" />

<img src=".\image\数据结构3.webp" alt="数据结构3" style="zoom:100%;" />



```
1. redis 用 c 语言开发
2. redis 的 key 限制为 512MB
3. redis 中所有 key 和 value 都包含 redisObject 结构体
```

##### redisObject 结构体

```c
// 4 + 4 + 24 + 32 + 64 = 128bits = 16bytes
struct RedisObject {
    int4 type; 				// 数据类型(string、list、hash等), 4bits
    int4 encoding; 			// 编码形式, 4bits
    int24 lru; 				// 对象的LRU信息, 24bits
    int32 refcount; 		// 引用计数器, 32bits
    void *ptr; 				// 指针指向对象的具体内容, 64bits
}
```

## string

#### 底层实现

<img src=".\image\int2.webp" alt="int2" style="zoom:80%;" />

```
1. string 内部 encoding 有 3 种: 
	int, raw 和 embstr
2. string 底层数据结构有 2 种: 
	int 和 SDS
3. redis 的 key 和 string 类型 value 限制均为 512MB. key 太大影响检索性能
4. encoding 方式如何选择 (分界值不同版本不一样, 44 是最新的)
    1. 如果字符串对象保存的是整数值, 并且这个整数值可以用 long 类型来表示, 会用 int 数据结构, 编码是 int, 整数值保存在 ptr 属性里面
    2. 如果字符串对象保存的是字符串, 并且这个字符申的长度 <= 44, 会用 SDS 数据结构, SDS 编码是 embstr 
    3. 如果字符串对象保存的是字符串, 并且这个字符申的长度 > 44, 会用 SDS 数据结构, SDS 编码是 raw 
```

#### int

<img src=".\image\int2.jpg" alt="int2" style="zoom:50%;" />

```
8字节的长整型 long, 范围 2^63-1 (40亿)
```

#### SDS

> 二进制安全: c 语言 "\0" 表示字符串的结束, 如果字符串本身就有 "\0" 字符, 字符串就会被截断, 即非二进制安全. 若通过某种机制保证读写字符串时不损害其内容, 则是二进制安全.
>
> SDS (Simple Dynamic string): 简单动态字符串

1. Redis 用 C 语言编写, 但 Redis 没用 char 来表示字符串, 而是用 SDS 来存储字符串数据.
2. c 语言字符串不记录长度, 每次获取长度都需要遍历, 时间的复杂度是O(n); SDS 用 len 属性记录长度, 获取长度时间复杂度变为O(1).
4. c 语言字符串以空字符串 "\0" 作为结束符, 一些图片中含有结束符, 不是二进制安全; SDS 是二进制安全的, 使用 len 属性的值判断字符串是否结束, 而不是空字符来 "\0". SDS 所有 API 都会以处理二进制的方式来处理存放在 buf[ ] 数组里的数据. 所以可以保存文本数据和二进制数据(图片, 视频等).
6. c 语言两个字符串拼接, 若没有分配足够长度的内存空间就会出现缓冲区溢出; SDS 先根据 len 判断空间是否满足要求, 若是空间不够, 就会进行相应的空间扩展, 不会出现缓冲区溢出.
5. SDS 空间预分配: 给字符串分配空间时, 分配的空间比实际要多, 减少连续的执行字符串增长带来内存重新分配的次数
    1. 如果 SDS 的长度 len 小于 1MB，redis 会分配和 len 同样大小的未使用空间 (例如 len 为 13字节, redis 也会分配 13字节的未使用空间, 因此 SDS 的 buf 数组实际长度 13+13+1=27 字节, 额外的 1 字节用于保存空字符)
    2. 如果 SDS 的长度 len 大于等于 1MB，redis 会分配 1MB 的未 使用空间。例如, len 的长度为 30MB，那么将分配 1MB 的未使用空间，因此 SDS 的 buf 数组实际长度变 30MB + 1MB + 1byte
6. SDS 惰性空间释放: 当字符串被缩短的时候, SDS也不会立即回收不适用的空间, 而是通过 free 属性将不使用的空间记录下来, 等后面使用的时候再释放, 并为将来可能的增长操作提供了优化. 在需要的时候回释放 SDS 未使用的空间, 不会浪费内存.

```

```



##### raw 编码

<img src=".\image\raw编码结构2.webp" alt="raw编码结构2" style="zoom:100%;" />

##### embstr 编码

<img src=".\image\embstr编码结2.png" alt="embstr编码结2" style="zoom:40%;" />

##### embstr 对比 raw

```
1. embstr 和 raw 都是由 redisObject 和 sds 组成
2. raw 需要为 redisObject 和 sds 内存不是连续的
	a. 分配内存时, 要分配 2 次内存
	b. 释放内存时, 要调用 2 次内存释放函数
3. embstr 的 redisObject 和 sds 内存是连续的
	a. 分配内存时, 要分配 1 次内存
	b. 释放内存时, 要调用 1 次内存释放函数
	c. 字符串的长度增加需要重新分配内存时, redisObject 和 sds 都需要重新分配内存
	d. embstr 编码的字符串对象实际上是只读的, redis 没有为 embstr 编码的字符串对象编写任何相应的修改程序. 对 embstr 编码字符串对象执行任何修改命令 (例如 append) 时, 会先将对象的编码从 embstr 转换成 raw, 然后再执行修改命令


例如:
    > set test3 ccc
    OK
    > object encoding test3
    embstr
    > append test3 eee
    6
    > object encoding test3
    raw
    > set test3 ccc
    OK
    > object encoding test3
    embstr	
```

##### SDS 内存优化

```
1. 优化了 sds 的内存使用, 用于存储字符串的内存就会变大
2. raw 和 embstr 编码的分界线:
	redis 2.+ 是 32 字节
	redis 3.0-4.0 是 39 字节
	redis 5.0 是 44 字节
```

- 旧版 sds 占用内存

  ```c
  // 内存分配器 jemalloc 分配的内存如果超出了64个字节就认为是一个大字符串, 用 raw 编码
  // SDS 结构体中的 content 的字符串是以字节 \0 结尾的字符串 (是为了便于直接使用 glibc 的字符串处理函数, 以及为了便于字符串的调试打印输出)
  // 64byte - 16byte - 8byte - 1byte = 39byte
  struct SDS {
      unsigned int capacity;	// 4byte
      unsigned int len; 		// 字符串长度, 4byte
      byte[] content; 		// 数组, 保存字符串的每一个字符元素
  }
  ```
  
- 新版 sds 占用内存

  <img src=".\image\sds.png" alt="sds" style="zoom:90%;" />

  ```c
  // unsigned int 变成了 uint8_t, uint16_t, 还加了一个char flags标识, 总共只用了3个字节的大小。相当于优化了sds的内存使用, 相应的用于存储字符串的内存就会变大
  // 64byte - 16byte -3byte -1byte = 44byte。  
  struct SDS {
      int8 capacity; // 1byte
      int8 len; // 1byte
      int8 flags; // 1byte
      byte[] content; // 内联数组, 长度为 capacity
  }
  ```

#### 命令

```
set k v
get k
del k

incr k                  值自增1
decr k                  值自减1
incrby k n              值加n
decrbu k n              值减n
incrbyfloat k n         值加浮点n

append k v              值末尾追加字符串
getrange k start end    获取start和end之间字符
setrange k start v      从start开始替换为v
getbit
setbit
bitcount
bitop

EXISTS k						判断是否存在
STRLEN k						字符串长度
MSET key1 value1 key2 value2	批量设置
MGET key1 key2 					批量获取
SET number 0					设置 key-value 类型的值 
INCR number						将 key 中储存的数字值增一 
INCRBY number 10				将key中存储的数字值加 10
DECR number						将 key 中储存的数字值减一
DECRBY number 10				将key中存储的数字值键 10
EXPIRE name  60					设置 key 在 60 秒后过期（该方法是针对已经存在的key设置过期时间）
TTL name						查看数据还有多久过期
SETNX key value					不存在就插入
SET key value EX 60				设置 key-value 类型的值, 并设置该key的过期时间为 60 秒
SETEX key  60 value				设置 key-value 类型的值, 并设置该key的过期时间为 60 秒
```

## list

#### 底层实现

```
1. list 是字符串列表, 按照插入顺序排序, 可以从列表头部/尾部的添加/移除元素
2. list 的最大长度为 2^32 - 1 个元素 (40 亿)
3. Redis 3.2 版本前底层数据结构是 ziplist 和 linkedlist, 3.2 后只有 quicklist


3.2 前
如果列表元素个数小于 512 个（默认值, 可由 list-max-ziplist-entries 配置）, 列表每个元素的值都小于 64 字节（默认值, 可由 list-max-ziplist-value 配置）, Redis 会使用压缩列表作为 List 类型的底层数据结构；如果列表的元素不满足上面的条件, 用双向链表作为 List 类型的底层数据结构；
```

#### ziplist (压缩列表)

##### 概念

```
ziplist 是一组连续内存块组成的顺序的数据结构, 压缩列表能够节省空间, 压缩列表中使用多个节点来存储数据

当哈希类型中元素个数小于 hash-max-ziplist-entries 配置(默认 512 个), 同时所有值都小于 hash-max-ziplist-value 配 (默认 64 字节) 置时, Redis 会使用 ziplist 作为哈希的内部实现
hashtable: 当上述条件不满足时, Redis 则会采用 hashtable 作为哈希的内部实现。
```

##### 结构体

```c
struct ziplist<T> {
    int32 zlbytes; 			// 整个压缩列表占用字节数, 4byte
    int32 zltail_offset; 	// 最后一个元素距离压缩列表起始位置的偏移量, 用于快速定位到最后一个节点, 4byte
    int16 zllength; 		// 元素个数, 2byte
    T[] entries; 			// 列表中的每一个节点
    int8 zlend; 			// 压缩列表特殊结束符号, 值恒为 0xFF
}
```

<img src=".\image\hash2.png" alt="hash2" style="zoom:80%;" />

<img src=".\image\hash3.png" alt="hash3" style="zoom:60%;" />

```
entry 节点
	previous_entry_ength: 表示前一个节点 entry 的长度, 可用于计算前一个节点的其实地址, 因为他们的地址是连续的
	content:每个节点的内容
	encoding: content 内容类型和长度
```



```
127.0.0.1:6379> rpush dotahero sf qop doom
(integer) 3
127.0.0.1:6379> object encoding dotahero
"ziplist"
```

#### linkedlist (双向列表)

<img src=".\image\链表.webp" alt="链表" style="zoom:80%;" />

```
字符串列表
```

```
Redis 中的列表在3.2之前的版本是使用 ziplist 和 linkedlist 进行实现的, 在 3.2 之后 quicklist


linkedlist: 是一个双向链表, 他和普通的链表一样都是由指向前后节点的指针。插入、修改、更新的时间复杂度尾O(1), 但是查询的时间复杂度确实O(n)

linkedlist和 quicklist 的底层实现是采用链表进行实现, 在c语言中并没有内置的链表这种数据结构, Redis实现了自己的链表结构。
```

#### quicklist (快速列表)

```
quicklist(快速列表)实现的, 快速列表支持从链表头和尾添加元素, 并且可以获取指定位置的元素内容。
```

#### 命令

```
lpush k v1 v2           左边添加多个元素
rpush k v1 v2           右边添加多个元素
lpop k
rpop k
lindex k v              获取指定位置上一个元素
lrange k start end      获取指定范围所有元素
ltrim k start end       只保留start和end及之间的元素  

blpop k timeout         从第一个非空列表中弹出最左边元素, 或timeout内等待可弹出的元素出现                   
brpop                                        右
rpoplpush k1 k2         弹出 k1 list 最右边, 推入 k2 list 最左, 并获取这个元素 
brpoplpush k1 k2 timeout弹出 k1 list 最右边, 推入 k2 list 最左, 并获取这个元素, 如果k1位空则阻塞timeout直到元素出现
```

## hash

##### 定义

```
Hash 对象的实现方式有两种分别是 ziplist, hashtable
	hashtable的存储方式key是string类型的, value也是以key value的形式进行存储

两者在新增时都会通过key计算出数组下标, 不同的是计算法方式不同, HashMap中是以hash函数的方式, 而 hashtable 中计算出 hash 值后, 还要通过sizemask 属性和哈希值再次得到数组下标

redis 中每个 hash 可以存储 2^32 - 1 键值对 (40多亿)



ziplist（压缩列表）：当哈希类型中元素个数小于 hash-max-ziplist-entries配置（默认 512 个）, 同时所有值都小于 hash-max-ziplist-value 配置（默认 64 字节）时, Redis 会使用 ziplist 作为哈希的内部实现。
hashtable（哈希表）：当上述条件不满足时, Redis 则会采用 hashtable 作为哈希的内部实现。

```

##### 渐进式 rehash 

```
1. rehash: hash 的扩容和缩容
2. 渐进式 rehash: redis 是单线程, 大字典 rehash 耗时久, 阻塞时间长, 因此逐步操作

1. 扩容和缩容都会通过 rehash 来实现
2. 渐进式rehash: 是指我们的大字典的扩容是比较消耗时间的, 需要重新申请新的数组, 然后将旧字典所有链表的元素重新挂接到新的数组下面, 是一个O(n)的操作。但 redis 是单线程, 无法承受这样的耗时过程, 所以采用了渐进式rehash小步搬迁, 虽然慢一点, 但是可以搬迁完毕


扩容时新建一个长度为原始长度 2 倍的空哈希表
, 然后原哈希表上的元素重新 rehash 到新的哈希表中去
```

##### 渐进式 rehash 过程

```
redis 采用渐进式 rehash, 有个变量指向第一个哈希桶, 然后 redis 每执行一个添加key, 删除key的类似命令, 就顺便copy一个哈希桶中的数据到新的哈希表中去,就会所有的数据都被重新hash到新的哈希表中。
那么在这个过程中, 当然再有写的操作, 会直接把数据放到新的哈希表中, 保证旧的肯定有copy完的时候, 如果这段时间对数据库的操作比较少, 也没有关系, redis内部也有定时任务, 每隔一段时间也会copy一次

redis 通过链式哈希解决冲突, 也就是同一个桶里面的元素使用链表保存。但是当链表过长就会导致查找性能变差可能。所以redis为了追求块, 使用了两个全局哈希表。用于rehash操作, 增加现有的哈希桶数量, 减少哈希冲突
开始默认使用hash表1保存键值对数据, hash表2此刻没有分配空间。当数据越来越多的触发rehash操作, 则执行以下操作：

    给hash表2分配更大的空间
    将hash表1的数据重新映射拷贝到hash表2中
    将hash表1的数据重新映射到hash表2的过程并不是一次性的, 这样会造成redis阻塞, 无法提供服务
    释放hash表1的空间

详细步骤：

    为ht[1]分配空间, 让字典同时持有ht[0]和ht[1]两个hash表
    在字典中维持一个索引计数器变量rehashidx, 并将它的值设置为0, 表示rehash工作正式开始
    在rehash进行期间, 每次对字典执行添加, 删除, 查找或者更新操作时, 程序除了执行特定的操作以外, 还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1], 当rehash工作完成之后, 程序将rehashidx属性的值增1
    随着字典操作的不断执行, 最终在某个时间点上, ht[0]的所有键值对都会被rehash至ht[1], 这时程序将rehashidx属性的值设为-1, 表示rehash操作已完成
    将ht[0]释放, 然后将ht[1]设置成ht[0], 最后为ht[1]分配一个空白哈希表

```

##### rehash触发条件

```
1. 扩容
扩容一般会在 Hash 表中的元素个数等于第一维数组的长度的时候, 就会开始扩容。
扩容的大小是原数组的两倍。不过在redis在做bgsave（RDB持久化操作的过程）时, 为了减少内存页的过多分离（Copy On Write）, redis不会去扩容。
但是如果hash表的元素个数已经到达了第一维数组长度的5倍的时候, 就会强制扩容, 不管你是否在持久化。

2. 缩容
当我们的hash表元素逐渐删除的越来越少的时候。redis就会对hash表进行缩容来减少第一维数组长度的空间占用。缩容的条件是元素个数低于数组长度的10%, 并且缩容不考虑是否在做redis持久化。
不用考虑bgsave主要原因是因为我们的缩容的内存都是已经使用过的, 缩容的时候可以直接置空, 而且由于申请的内存比较小, 同时会释放掉一些已经使用的内存, 不会增大系统的压力。
```





##### 底层实现

```
Redis 7.0 前, 底层数据结构是 ziplist 或 hashtable
Redis 7.0 后, 弃用 ziplist 和 hashtable, 由 listpack 实现


如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用压缩列表作为 Hash 类型的底层数据结构；如果哈希类型元素不满足上面条件，Redis 会使用哈希表作为 Hash 类型的 底层数据结构。
```

##### 命令

```
hset k1 k2 v
hget k1 k2
hdel k1 k2
hgetall k1              获取所有键值对
hmget K k1 k2           获取1个/多个键的值
hmset K k1 v1 k2 v2     添加1个/多个值
hdel K k1 k2            获取成功删除的数量
hlen K                  获取键值对的数量
hexists K k             查看k是否存在
hkeys K k               删除
hvals K                 获取所有值
hgetall K               获取所有键值对
hincrby K k count       值加上count
hincrbyfloat K k count  值加上count 浮zrange点
```



#### hashtable

##### hash 冲突

<img src=".\image\hash.webp" alt="hash" style="zoom:100%;" />

```
hash 表存在 hash 冲突, 为了解决 hash 冲突, 假如hashtable中不同的key通过计算得到同一个index, 就会形成单向链表（「链地址法」）
```

##### rehash

```
rehash: 字典底层实现中, value 是 dictEntry 结构体进行存储, 当 hash 表中的键值对不断的增加或者减少时, 需要对 hash 表进行一个扩展或者收缩

这里就会和HashMap一样也会就进行rehash操作, 进行重新散列排布。



dictEntry 属性
    dictEntry **table: 哈希表数组
    unsigned long size: hash 表大小
    unsigned long sizemask: 用于计算索引值
    unsigned long used: hash表中已有的节点数


有ht[0]和ht[1]两个对象
ht[0]是用来最开始存储数据的, 当要进行扩展或者收缩时, ht[0]的大小就决定了ht[1]的大小, 
ht[0]中的所有的键值对就会重新散列到ht[1]中。

扩展操作：ht[1]扩展的大小是比当前 ht[0].used 值的二倍大的第一个 2 的整数幂；收缩操作：ht[0].used 的第一个大于等于的 2 的整数幂。

当ht[0]上的所有的键值对都rehash到ht[1]中, 会重新计算所有的数组下标值, 当数据迁移完后ht[0]就会被释放, 然后将ht[1]改为ht[0], 并新创建ht[1], 为下一次的扩展和收缩做准备。
```

##### 渐进式 rehash

```
假如在 rehash 的过程中数据量非常大, Redis 不是一次性把全部数据 rehash 成功, 这样会导致Redis对外服务停止, Redis内部为了处理这种情况采用「渐进式的rehash」。

Redis将所有的rehash的操作分成多步进行, 直到都rehash完成, 具体的实现与对象中的rehashindex属性相关, 「若是rehashindex 表示为-1表示没有rehash操作」。

当rehash操作开始时会将该值改成0, 在渐进式rehash的过程「更新、删除、查询会在ht[0]和ht[1]中都进行」, 比如更新一个值先更新ht[0], 然后再更新ht[1]。

而新增操作直接就新增到ht[1]表中, ht[0]不会新增任何的数据, 这样保证「ht[0]只减不增, 直到最后的某一个时刻变成空表」, 这样rehash操作完成。

上面就是字典的底层hashtable的实现原理, 说完了hashtable的实现原理, 我们再来看看Hash数据结构的两一种存储方式「ziplist（压缩列表）」
```

## set



```
存储 string 类型, 无序, 不重复
集合是通过哈希表实现的, 所以添加, 删除, 查找的复杂度都是O(1)



Set 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。

一个集合最多可以存储 2^32-1 个元素。概念和数学中个的集合基本类似，可以交集，并集，差集等等，所以 Set 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集。

Set 类型和 List 类型的区别如下：

List 可以存储重复元素，Set 只能存储非重复元素；List 是按照元素的先后顺序存储元素的，而 Set 则是无序方式存储元素的。

Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞

```

#### 底层实现

```
底层数据结构是 hashtable 或 intset

如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用整数集合作为 Set 类型的底层数据结构；如果集合中的元素不满足上面条件，则 Redis 使用哈希表作为 Set 类型的底层数据结构。
```



##### 命令

```
sadd k v1 v2            添加1个/多个元素, 获取不存在新增加的个数        
srem k v1 v2            删除1个/多个元素, 获取删除的个数
scard k                 获取元素个数
smembers k              获取所有元素
sismember k v           是否包含元素v
srandmember k count     随机获取count个元素, 当count为正数时元素不重复, 负数时可以重复
spop k                  随机移除一个元素并获取元素
smove k1 k2 v           如果k1有元素v则移动到k2则
```

```
# 交集运算
SINTER key [key ...]
# 将交集结果存入新集合destination中
SINTERSTORE destination key [key ...]

# 并集运算
SUNION key [key ...]
# 将并集结果存入新集合destination中
SUNIONSTORE destination key [key ...]

# 差集运算
SDIFF key [key ...]
# 将差集结果存入新集合destination中
SDIFFSTORE destination key [key ...]
```



```

```

#### 底层实现

```

```





#### inset

```
inset: 整数集合, 用于保存整数值的数据结构类型, 如 int16_t, int32_t, int64_t

在整数集合中, 有三个属性值
encoding: 编码方式
contents[]: 元素的内容
length: 整数集合的长度


在整数集合新增元素的时候, 若是超出了原集合的长度大小, 就会对集合进行升级, 具体的升级过程如下
	首先扩展底层数组的大小, 并且数组的类型为新元素的类型。
	然后将原来的数组中的元素转为新元素的类型, 并放到扩展后数组对应的位置。
	整数集合升级后就不会再降级, 编码会一直保持升级后的状态。
```



#### 应用

##### 点赞

```
Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章id，value 是用户id。

uid:1 、uid:2、uid:3 三个用户分别对 article:1 文章点赞了。

# uid:1 用户对文章 article:1 点赞
> SADD article:1 uid:1
(integer) 1
# uid:2 用户对文章 article:1 点赞
> SADD article:1 uid:2
(integer) 1
# uid:3 用户对文章 article:1 点赞
> SADD article:1 uid:3
(integer) 1

uid:1 取消了对 article:1 文章点赞。

> SREM article:1 uid:1
(integer) 1

获取 article:1 文章所有点赞用户 :

> SMEMBERS article:1
1) "uid:3"
2) "uid:2"

获取 article:1 文章的点赞用户数量：

> SCARD article:1
(integer) 2

判断用户 uid:1 是否对文章 article:1 点赞了：

> SISMEMBER article:1 uid:1
(integer) 0  # 返回0说明没点赞，返回1则说明点赞了

```



##### 共同关注

```


Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。

key 可以是用户id，value 则是已关注的公众号的id。

uid:1 用户关注公众号 id 为 5、6、7、8、9，uid:2 用户关注公众号 id 为 7、8、9、10、11。

# uid:1 用户关注公众号 id 为 5、6、7、8、9
> SADD uid:1 5 6 7 8 9
(integer) 5
# uid:2  用户关注公众号 id 为 7、8、9、10、11
> SADD uid:2 7 8 9 10 11
(integer) 5

uid:1 和 uid:2 共同关注的公众号：

# 获取共同关注
> SINTER uid:1 uid:2
1) "7"
2) "8"
3) "9"

给 uid:2 推荐 uid:1 关注的公众号：

> SDIFF uid:1 uid:2
1) "5"
2) "6"

验证某个公众号是否同时被 uid:1 或 uid:2 关注:

> SISMEMBER uid:1 5
(integer) 1 # 返回0，说明关注了
> SISMEMBER uid:2 5
(integer) 0 # 返回0，说明没关注

```



##### 抽奖活动

```


存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。

key为抽奖活动名，value为员工名称，把所有员工名称放入抽奖箱 ：

>SADD lucky Tom Jerry John Sean Marry Lindy Sary Mark
(integer) 5

如果允许重复中奖，可以使用 SRANDMEMBER 命令。

# 抽取 1 个一等奖：
> SRANDMEMBER lucky 1
1) "Tom"
# 抽取 2 个二等奖：
> SRANDMEMBER lucky 2
1) "Mark"
2) "Jerry"
# 抽取 3 个三等奖：
> SRANDMEMBER lucky 3
1) "Sary"
2) "Tom"
3) "Jerry"

如果不允许重复中奖，可以使用 SPOP 命令。

# 抽取一等奖1个
> SPOP lucky 1
1) "Sary"
# 抽取二等奖2个
> SPOP lucky 2
1) "Jerry"
2) "Mark"
# 抽取三等奖3个
> SPOP lucky 3
1) "John"
2) "Sean"
3) "Lindy"

```

## zset

<img src=".\image\zset.jpg" alt="zset" style="zoom:50%;" />

```
zset 是有序集合
zset 底层实现是 ziplist 和 skiplist 实现的


Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序结合的元素值，一个是排序值。

有序集合保留了集合不能有重复成员的特性（分值可以重复），但不同的是，有序集合中的元素可以排序。



zset(有序集合)
string类型元素的集合, 且不允许重复的成员。
格式: zadd  name score value
不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。
zset的成员是唯一的,但分数(score)却可以重复。
```

#### 底层实现

```
内部实现

Zset 类型的底层数据结构是由压缩列表或跳表实现的：

    如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 类型的底层数据结构；如果有序集合的元素不满足上面的条件，Redis 会使用跳表作为 Zset 类型的底层数据结构；

在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。
```

#### 命令

```
zadd k s1 v1 s2 v2      将分数s1 s2和元素添加到集合
zrem k v1 v2            移除元素, 并获取成功的数量            
zcard k                 获取元素数量
zincrby k count v       v的分数增加count
zcount k s1 s2          获取分数s1和s2之间元素数量
zrank k v               获取元素的排名
zscore k v              获取元素的分值
zrange k start stop [withscores]    返回排名start和stop之间的成员, 如果有withscores则一起返回分数
```

```
# 往有序集合key中加入带分值元素
ZADD key score member [[score member]...]   
# 往有序集合key中删除元素
ZREM key member [member...]                 
# 返回有序集合key中元素member的分值
ZSCORE key member
# 返回有序集合key中元素个数
ZCARD key 

# 为有序集合key中元素member的分值加上increment
ZINCRBY key increment member 

# 正序获取有序集合key从start下标到stop下标的元素
ZRANGE key start stop [WITHSCORES]
# 倒序获取有序集合key从start下标到stop下标的元素
ZREVRANGE key start stop [WITHSCORES]

# 返回有序集合中指定分数区间内的成员，分数由低到高排序。
ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]

# 返回指定成员区间内的成员，按字典正序排列, 分数必须相同。
ZRANGEBYLEX key min max [LIMIT offset count]
# 返回指定成员区间内的成员，按字典倒序排列, 分数必须相同
ZREVRANGEBYLEX key max min [LIMIT offset count]


Zset 运算操作（相比于 Set 类型，ZSet 类型没有支持差集运算）：
# 并集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积
ZUNIONSTORE destkey numberkeys key [key...] 
# 交集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积
ZINTERSTORE destkey numberkeys key [key...]
```

#### skiplist

<img src=".\image\skiplist.jpg" alt="skiplist" style="zoom:80%;" />

```
skiplist: 跳跃表, 是一种有序的数据结构, 它通过每一个节点维持多个指向其它节点的指针, 从而达到快速访问的目的。

skiplist由如下几个特点：
有很多层组成, 由上到下节点数逐渐密集, 最上层的节点最稀疏, 跨度也最大。
每一层都是一个有序链表, 只扫包含两个节点, 头节点和尾节点。
每一层的每一个每一个节点都含有指向同一层下一个节点和下一层同一个位置节点的指针。如果一个节点在某一层出现, 那么该以下的所有链表同一个位置都会出现该节点。


在跳跃表的结构中有head和tail表示指向头节点和尾节点的指针, 能后快速的实现定位。level表示层数, len表示跳跃表的长度, BW表示后退指针, 在从尾向前遍历的时候使用。

BW下面还有两个值分别表示分值（score）和成员对象（各个节点保存的成员对象）。

跳跃表的实现中, 除了最底层的一层保存的是原始链表的完整数据, 上层的节点数会越来越少, 并且跨度会越来越大。

跳跃表的上面层就相当于索引层, 都是为了找到最后的数据而服务的, 数据量越大, 条表所体现的查询的效率就越高, 和平衡树的查询效率相差无几。
```



### 应用

##### 排行榜

```


有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。

我们以博文点赞排名为例，小林发表了五篇博文，分别获得赞为 200、40、100、50、150。

# arcticle:1 文章获得了200个赞
> ZADD user:xiaolin:ranking 200 arcticle:1
(integer) 1
# arcticle:2 文章获得了40个赞
> ZADD user:xiaolin:ranking 40 arcticle:2
(integer) 1
# arcticle:3 文章获得了100个赞
> ZADD user:xiaolin:ranking 100 arcticle:3
(integer) 1
# arcticle:4 文章获得了50个赞
> ZADD user:xiaolin:ranking 50 arcticle:4
(integer) 1
# arcticle:5 文章获得了150个赞
> ZADD user:xiaolin:ranking 150 arcticle:5
(integer) 1

文章 arcticle:4 新增一个赞，可以使用 ZINCRBY 命令（为有序集合key中元素member的分值加上increment）：

> ZINCRBY user:xiaolin:ranking 1 arcticle:4
"51"

查看某篇文章的赞数，可以使用 ZSCORE 命令（返回有序集合key中元素个数）：

> ZSCORE user:xiaolin:ranking arcticle:4
"50"

获取小林文章赞数最多的 3 篇文章，可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）：

# WITHSCORES 表示把 score 也显示出来
> ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES
1) "arcticle:1"
2) "200"
3) "arcticle:5"
4) "150"
5) "arcticle:3"
6) "100"

获取小林 100 赞到 200 赞的文章，可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员，分数由低到高排序）：

> ZRANGEBYSCORE user:xiaolin:ranking 100 200 WITHSCORES
1) "arcticle:3"
2) "100"
3) "arcticle:5"
4) "150"
5) "arcticle:1"
6) "200"

```

##### 电话、姓名排序

```
电话、姓名排序

使用有序集合的 ZRANGEBYLEX 或 ZREVRANGEBYLEX 可以帮助我们实现电话号码或姓名的排序，我们以 ZRANGEBYLEX （返回指定成员区间内的成员，按 key 正序排列，分数必须相同）为例。

注意：不要在分数不一致的 SortSet 集合中去使用 ZRANGEBYLEX和 ZREVRANGEBYLEX 指令，因为获取的结果会不准确。

1、电话排序

我们可以将电话号码存储到 SortSet 中，然后根据需要来获取号段：

> ZADD phone 0 13100111100 0 13110114300 0 13132110901 
(integer) 3
> ZADD phone 0 13200111100 0 13210414300 0 13252110901 
(integer) 3
> ZADD phone 0 13300111100 0 13310414300 0 13352110901 
(integer) 3

获取所有号码:

> ZRANGEBYLEX phone - +
1) "13100111100"
2) "13110114300"
3) "13132110901"
4) "13200111100"
5) "13210414300"
6) "13252110901"
7) "13300111100"
8) "13310414300"
9) "13352110901"

获取 132 号段的号码：

> ZRANGEBYLEX phone [132 (133
1) "13200111100"
2) "13210414300"
3) "13252110901"

获取132、133号段的号码：

> ZRANGEBYLEX phone [132 (134
1) "13200111100"
2) "13210414300"
3) "13252110901"
4) "13300111100"
5) "13310414300"
6) "13352110901"

2、姓名排序

> zadd names 0 Toumas 0 Jake 0 Bluetuo 0 Gaodeng 0 Aimini 0 Aidehua 
(integer) 6

获取所有人的名字:

> ZRANGEBYLEX names - +
1) "Aidehua"
2) "Aimini"
3) "Bluetuo"
4) "Gaodeng"
5) "Jake"
6) "Toumas"

获取名字中大写字母A开头的所有人：

> ZRANGEBYLEX names [A (B
1) "Aidehua"
2) "Aimini"

获取名字中大写字母 C 到 Z 的所有人：

> ZRANGEBYLEX names [C [Z
1) "Gaodeng"
2) "Jake"
3) "Toumas"

```



## HyperLogLogs (基数统计)

```
    基数统计（hyperloglog）: 基于概率的数据结构, 2.8.9新增
2.8 版新增
```

```
介绍

Redis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型，是一种用于「统计基数」的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。

所以，简单来说 HyperLogLog 提供不精确的去重计数。

HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。

在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。

这什么概念？举个例子给大家对比一下。

用 Java 语言来说，一般 long 类型占用 8 字节，而 1 字节有 8 位，即：1 byte = 8 bit，即 long 数据类型最大可以表示的数是：2^63-1。对应上面的2^64个数，假设此时有2^63-1这么多个数，从 0 ~ 2^63-1，按照long以及1k = 1024 字节的规则来计算内存总数，就是：((2^63-1) * 8/1024)K，这是很庞大的一个数，存储空间远远超过12K，而 HyperLogLog 却可以用 12K 就能统计完。
```

#### 内部实现

```


HyperLogLog 的实现涉及到很多数学问题，太费脑子了，我也没有搞懂，如果你想了解一下，课下可以看看这个：HyperLogLog。
```

#### 常见命令

```


HyperLogLog 命令很少，就三个。

# 添加指定元素到 HyperLogLog 中
PFADD key element [element ...]

# 返回给定 HyperLogLog 的基数估算值。
PFCOUNT key [key ...]

# 将多个 HyperLogLog 合并为一个 HyperLogLog
PFMERGE destkey sourcekey [sourcekey ...]

```

#### **应用场景**

##### 百万级网页 UV 计数

```

Redis HyperLogLog 优势在于只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。

所以，非常适合统计百万级以上的网页 UV 的场景。

在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。

PFADD page1:uv user1 user2 user3 user4 user5

接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。

PFCOUNT page1:uv

不过，有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。

这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。
```



## Geospatial 地理位置

```
地理位置（Geo）: 地理位置信息储存起来,  并对这些信息进行操作 3.2新增
3.2 版新增
Redis GEO 是 Redis 3.2 版本新增的数据类型，主要用于存储地理位置信息，并对存储的信息进行操作。

在日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中。
```



#### 内部实现

```
GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。

GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。

这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。
```

#### 常用命令

```
常用命令

# 存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。
GEOADD key longitude latitude member [longitude latitude member ...]

# 从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。
GEOPOS key member [member ...]

# 返回两个给定位置之间的距离。
GEODIST key member1 member2 [m|km|ft|mi]

# 根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]


```



#### 应用场景

##### 滴滴叫车

```



这里以滴滴叫车的场景为例，介绍下具体如何使用 GEO 命令：GEOADD 和 GEORADIUS 这两个命令。

假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。

执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：

GEOADD cars:locations 116.034579 39.030452 33

当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。

例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。

GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10

```



## BitMaps (位图)

<img src=".\image\bitmap.png" alt="bitmap" style="zoom:40%;" />

```
位操作（bitmap）: 更细化的一种操作, 以bit为单位。
2.2 版新增
```

```
介绍

Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。

由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用二值统计的场景。
内部实现

Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。

String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组。
```

#### 常用命令

```
bitmap 基本操作：

# 设置值，其中value只能是 0 和 1
SETBIT key offset value

# 获取值
GETBIT key offset

# 获取指定范围内值为 1 的个数
# start 和 end 以字节为单位
BITCOUNT key start end

bitmap 运算操作：

# BitMap间的运算
# operations 位移操作符，枚举值
  AND 与运算 &
  OR 或运算 |
  XOR 异或 ^
  NOT 取反 ~
# result 计算的结果，会存储在该key中
# key1 … keyn 参与运算的key，可以有多个，空格分割，not运算只能一个key
# 当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0。返回值是保存到 destkey 的字符串的长度（以字节byte为单位），和输入 key 中最长的字符串长度相等。
BITOP [operations] [result] [key1] [keyn…]

# 返回指定key中第一次出现指定value(0/1)的位置
BITPOS [key] [value]

```

#### 应用

```
Bitmap 类型非常适合二值状态统计的场景，这里的二值状态就是指集合元素的取值就只有 0 和 1 两种，在记录海量数据时，Bitmap 能够有效地节省内存空间。
```

##### 签到统计

```


在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。

签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。

假设我们要统计 ID 100 的用户在 2022 年 6 月份的签到情况，就可以按照下面的步骤进行操作。

第一步，执行下面的命令，记录该用户 6 月 3 号已签到。

SETBIT uid:sign:100:202206 2 1

第二步，检查该用户 6 月 3 日是否签到。

GETBIT uid:sign:100:202206 2 

第三步，统计该用户在 6 月份的签到次数。

BITCOUNT uid:sign:100:202206

这样，我们就知道该用户在 6 月份的签到情况了。

    如何统计这个月首次打卡时间呢？

Redis 提供了 BITPOS key bitValue [start] [end]指令，返回数据表示 Bitmap 中第一个值为 bitValue 的 offset 位置。

在默认情况下， 命令将检测整个位图， 用户可以通过可选的 start 参数和 end 参数指定要检测的范围。所以我们可以通过执行这条命令来获取 userID = 100 在 2022 年 6 月份首次打卡日期：

BITPOS uid:sign:100:202206 1

需要注意的是，因为 offset 从 0 开始的，所以我们需要将返回的 value + 1 。
```

##### 判断用户登陆态

```


Bitmap 提供了 GETBIT、SETBIT 操作，通过一个偏移值 offset 对 bit 数组的 offset 位置的 bit 位进行读写操作，需要注意的是 offset 从 0 开始。

只需要一个 key = login_status 表示存储用户登陆状态集合数据， 将用户 ID 作为 offset，在线就设置为 1，下线设置 0。通过 GETBIT判断对应的用户是否在线。 50000 万 用户只需要 6 MB 的空间。

假如我们要判断 ID = 10086 的用户的登陆情况：

第一步，执行以下指令，表示用户已登录。

SETBIT login_status 10086 1

第二步，检查该用户是否登陆，返回值 1 表示已登录。

GETBIT login_status 10086

第三步，登出，将 offset 对应的 value 设置成 0。

SETBIT login_status 10086 0

```

##### 连续签到用户总数

```


如何统计出这连续 7 天连续打卡用户总数呢？

我们把每天的日期作为 Bitmap 的 key，userId 作为 offset，若是打卡则将 offset 位置的 bit 设置成 1。

key 对应的集合的每个 bit 位的数据则是一个用户在该日期的打卡记录。

一共有 7 个这样的 Bitmap，如果我们能对这 7 个 Bitmap 的对应的 bit 位做 『与』运算。同样的 UserID offset 都是一样的，当一个 userID 在 7 个 Bitmap 对应对应的 offset 位置的 bit = 1 就说明该用户 7 天连续打卡。

结果保存到一个新 Bitmap 中，我们再通过 BITCOUNT 统计 bit = 1 的个数便得到了连续打卡 3 天的用户总数了。

Redis 提供了 BITOP operation destkey key [key ...]这个指令用于对一个或者多个 key 的 Bitmap 进行位元操作。

    opration 可以是 and、OR、NOT、XOR。当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0 。空的 key 也被看作是包含 0 的字符串序列。

举个例子，比如将三个 bitmap 进行 AND 操作，并将结果保存到 destmap 中，接着对 destmap 执行 BITCOUNT 统计。

# 与操作
BITOP AND destmap bitmap:01 bitmap:02 bitmap:03
# 统计 bit 位 =  1 的个数
BITCOUNT destmap

即使一天产生一个亿的数据，Bitmap 占用的内存也不大，大约占 12 MB 的内存（10^8/8/1024/1024），7 天的 Bitmap 的内存开销约为 84 MB。同时我们最好给 Bitmap 设置过期时间，让 Redis 删除过期的打卡数据，节省内存。
```

## Stream (流)

```
Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。

list 实现消息队列问题:
发布订阅模式，
不能持久化也就无法可靠的保存消息
并且对于离线重连的客户端不能读取历史消息的缺陷；
List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且生产者需要自行实现全局唯一 ID

基于以上问题，Redis 5.0 便推出了 Stream 类型也是此版本最重要的功能，用于完美地实现消息队列，
    它支持消息的持久化、
    支持自动生成全局唯一 ID、
    支持 ack 确认消息的模式、
    支持消费组模式等，
    让消息队列更加的稳定和可靠。
```

#### 命令

```
XADD：插入消息，保证有序，可以自动生成全局唯一 ID；
XLEN ：查询消息长度；
XREAD：用于读取消息，可以按 ID 读取数据；
XDEL ： 根据消息 ID 删除消息；
DEL ：删除整个 Stream；
XRANGE ：读取区间消息XREADGROUP：按消费组形式读取消息；
XPENDING 和 XACK：
        XPENDING 命令可以用来查询每个消费组内所有消费者「已读取、但尚未确认」的消息
        XACK 命令用于向消息队列确认消息处理已完成；
```

#### 应用

##### 消息队列

```
生产者通过 XADD 命令插入一条消息
> XADD mymq * name xiaolin
"1654254953808-0"


往名称为 mymq 的消息队列中插入一条消息，消息的键是 name，值是 xiaolin
* 表示让 Redis 为插入的数据自动生成一个全局唯一的 ID

插入成功后会返回全局唯一的 ID："1654254953808-0"。消息的全局唯一 ID 由两部分组成：
    1654254953808 是数据插入时当前服务器时间
    0 是当前毫秒内的消息序号
    1654254953808-0 表示在 1654254953808 毫秒内的第 1 条消息
```

```
消费者通过 XREAD 命令从消息队列中读取消息时，可以指定一个消息 ID，并从这个消息 ID 的下一条消息开始进行读取（注意是输入消息 ID 的下一条信息开始读取，不是查询输入ID的消息）。


# 从 ID 号为 1654254953807-0 的消息开始，读取后续的所有消息（示例中一共 1 条）。
> XREAD STREAMS mymq 1654254953807-0
1) 1) "mymq"
   2) 1) 1) "1654254953808-0"
         2) 1) "name"
            2) "xiaolin"
            
            
如果想要实现阻塞读（当没有数据时，阻塞住），可以调用 XRAED 时设定 BLOCK 配置项，实现类似于 BRPOP 的阻塞读取操作。

比如，下面这命令，设置了 BLOCK 10000 的配置项，10000 的单位是毫秒，表明 XREAD 在读取最新消息时，如果没有消息到来，XREAD 将阻塞 10000 毫秒（即 10 秒），然后再返回。
# 命令最后的“$”符号表示读取最新的消息
> XREAD BLOCK 10000 STREAMS mymq $
(nil)
(10.00s)
```

```
Stream 可以以使用 XGROUP 创建消费组，创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。

创建两个消费组，这两个消费组消费的消息队列是 mymq，都指定从第一条消息开始读取：


# 创建一个名为 group1 的消费组，0-0 表示从第一条消息开始读取。
> XGROUP CREATE mymq group1 0-0
OK
# 创建一个名为 group2 的消费组，0-0 表示从第一条消息开始读取。
> XGROUP CREATE mymq group2 0-0
OK



消费组 group1 内的消费者 consumer1 从 mymq 消息队列中读取所有消息的命令如下：
# 命令最后的参数“>”，表示从第一条尚未被消费的消息开始读取。
> XREADGROUP GROUP group1 consumer1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1654254953808-0"
         2) 1) "name"
            2) "xiaolin"
            
            
息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了，即同一个消费组里的消费者不能消费同一条消息
比如说，我们执行完刚才的 XREADGROUP 命令后，再执行一次同样的命令，此时读到的就是空值了：
> XREADGROUP GROUP group1 consumer1 STREAMS mymq >
(nil)

不同消费组的消费者可以消费同一条消息（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息）。
比如说，刚才 group1 消费组里的 consum
> XREADGROUP GROUP group2 consumer1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1654254953808-0"
         2) 1) "name"
            2) "xiaolin"


使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的
```

```
基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？

Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。
消费确认增加了消息的可靠性，一般在业务处理完成之后，需要执行 XACK 命令确认消息已经被消费完成，整个流程的执行如下图所示：
如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。

```

##### 总结

```
消息保序：XADD/XREAD阻塞读取：XREAD block重复消息处理：Stream 在使用 XADD 命令，会自动生成全局唯一 ID；消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息；支持消费组形式消费数据
```

##### Redis 基于 Stream 消息队列与专业的消息队列有哪些差距

```
一个专业的消息队列，必须要做到两大块：

    消息不丢。消息可堆积。
```

##### Redis Stream 消息会丢失吗？

<img src=".\image\Stream消息队列.webp" alt="Stream消息队列" style="zoom:80%;" />

```
    Redis 生产者会不会丢消息？生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。 从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 （ MQ 中间件） 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。Redis 消费者会不会丢消息？不会，因为 Stream （ MQ 中间件）会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，但是未被确认的消息。消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。等到消费者执行完业务逻辑后，再发送消费确认 XACK 命令，也能保证消息的不丢失。Redis 消息中间件会不会丢消息？会，Redis 在以下 2 个场景下，都会导致数据丢失：
        AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能主从复制也是异步的，主从切换时，也存在丢失数据的可能。

可以看到，Redis 在队列中间件环节无法保证消息不丢。像 RabbitMQ 或 Kafka 这类专业的队列中间件，在使用时是部署一个集群，生产者在发布消息时，队列中间件通常会写「多个节点」，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。
https://xiaolincoding.com/redis/cluster/master_slave_replication.html#%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%8C%E6%AD%A5



```

##### Redis Stream 消息可堆积吗？

```\
Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。

所以 Redis 的 Stream 提供了可以指定队列最大长度的功能，就是为了避免这种情况发生。

当指定队列最大长度时，队列长度超过上限后，旧消息会被删除，只保留固定长度的新消息。这么来看，Stream 在消息积压时，如果指定了最大长度，还是有可能丢失消息的。

但 Kafka、RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上，当消息积压时，无非就是多占用一些磁盘空间。

因此，把 Redis 当作队列来使用时，会面临的 2 个问题：

    Redis 本身可能会丢数据；面对消息挤压，内存资源会紧张；

所以，能不能将 Redis 作为消息队列来使用，关键看你的业务场景：

    如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。
```

##### Redis 发布/订阅机制为什么不可以作为消息队列？

```
发布订阅机制存在以下缺点，都是跟丢失数据有关：

    发布/订阅机制没有基于任何数据类型实现，所以不具备「数据持久化」的能力，也就是发布/订阅机制的相关操作，不会写入到 RDB 和 AOF 中，当 Redis 宕机重启，发布/订阅机制的数据也会全部丢失。发布订阅模式是“发后既忘”的工作模式，如果有订阅者离线重连之后不能消费之前的历史消息。当消费端有一定的消息积压时，也就是生产者发送的消息，消费者消费不过来时，如果超过 32M 或者是 60s 内持续保持在 8M 以上，消费端会被强行断开，这个参数是在配置文件中设置的，默认值是 client-output-buffer-limit pubsub 32mb 8mb 60。

所以，发布/订阅机制只适合即使通讯的场景，比如构建哨兵集群的场景采用了发布/订阅机制。
```



# redis 发布订阅模式

# redis 为什么高性能







```
expire
persist
```

<img src=".\image\redis过期时间.png" alt="redis过期时间" style="zoom:80%;" />

# x.03 内存管理

```
设置最大内存, 避免redis内存使用过多对其他程序造成影响

redis.conf 文件, redis.conf 文件默认的最大内存 maxmemory=0 表示不限制redis内存的使用
```

### 删除策略

> 只能删除过期数据
>
> redis 同时使用了惰性删除与定期删除

##### 1. 定时删除

- 含义: 在设置 key 的过期时间的同时, 为该key创建一个定时器, 让定时器在 key 的过期时间来临时对 key 进行删除

- 优点: 保证内存被尽快释放

- 缺点:

  - 若过期 key很多, 删除这些key会占用很多的CPU时间, 在CPU时间紧张的情况下, CPU不能把所有的时间用来做要紧的事儿, 还需要去花时间删除这些key
  - 定时器的创建耗时,若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生）, 性能影响严重


##### 2. 惰性删除

- 含义: key 过期的时候不删除, 每次通过key获取值的时候去检查是否过期, 若过期则删除并返回不存在
- 优点: 节约CPU性能, 发现不得不删除的时候才删除
- 缺点: 内存空间压力大

##### 3. 定期删除

- 每隔一段时间, 我们就对一些key进行检查, 删除里面过期的key。
- 优点
  - 可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响, 解决"定时删除"对 cpu 影响的问题
  - 释放过期键占用的内存, 解决"惰性删除"对内存占用的问题.
- 缺点
  - 难以确定删除操作执行的时长（每次删除执行多长时间）和频率（每隔多长时间做一次删除)。如果执行的太频繁, 定期删除策略变得和定时删除策略一样, 对CPU不友好。如果执行的太少, 那又和惰性删除一样了, 过期键占用的内存不会及时得到释放。
  - 在获取某个键时, 如果某个键的过期时间已经到了, 但是还没执行定期删除, 那么就会返回这个键的值

### 淘汰策略

> 新数据写入时, redis 使用的内存达到上限时
>
> 设置 redis 使用内存的上限

> https://blog.csdn.net/qq_37325859/article/details/125331084

- 每次存储数据前调用 freeMemoryIfNeeded() 检测内存是否充足。如果内存不满足新加入数据的最低存储要求, redis要临时删除一些数据为当前指令清理存储空间. 有时需要反复执行才能才是释放足够的空间. 当对所有数据尝试完毕后, 如果不能达到内存清理的要求, 将出现错误 "OOM command not allowed when used memory>'maxmemory'"

##### 参数

```
maxmemory: redis可使用内存占物理内存的最大比例, 默认为0, 表示不限制redis使用内存。生产环境中根据需求设定, 通常设置在50%以上
maxmemory-samples: 每次选取待删除数据的个数, 选取数据时并不会全库扫描, 导致严重的性能消耗, 降低读写性能。因此采用随机获取数据的方式作为待检测删除数据
maxmemory-policy: 达到最大内存后的, 对被挑选出来的数据进行删除的算法
```

##### 淘汰算法

```
volatile-lru, 针对设置了过期时间的key, 使用lru算法进行淘汰
volatile-lfu, 针对设置了过期时间的key, 使用lfu算法进行淘汰。
volatile-random, 从所有设置了过期时间的key中使用随机淘汰的方式进行淘汰。
volatile-ttl, 针对设置了过期时间的key, 越早过期的越先被淘汰。
allkeys-lru, 针对所有key使用lru算法进行淘汰。
allkeys-lfu, 针对所有key使用lfu算法进行淘汰。
allkeys-random, 针对所有的key使用随机淘汰机制进行淘汰。
noeviction, 不会淘汰任何数据, 当使用的内存空间超过 maxmemory 值时, 再有写请求来时会引发错误OOM（Out Of Memory）
```

##### LRU

```
Least Recently Used 最近很少使用




问题:
一个很久没有被访问的key, 偶尔被访问一次, 导致被误认为是热点数据的问题
```

##### redis LRU

- 3.0 版本以前

  ```
  随机采集淘汰的key, 每次随机选出5个key, 然后淘汰这5个key中最少使用的key
  数量可设置, 值越大越准确, 道消耗资源增加
  ```

- 3.0 版本以后

- > 空闲时长: 多久没有用了. 优先淘汰空闲时长大的

  ```
  1. 维护一个池子存放随机选取的 key, 并根据空闲时长排序
  2. 大于池内最小空闲时长的才能追加入池子
  3. 池子满了以后, 将空闲时长最长的移出池子并淘汰.
  ```

##### LFU

> 4.0 版本加入

```
根据key最近被访问的频率进行淘汰, 比较少访问的key优先淘汰, 反之则保留。
LFU的原理是使用计数器来对key进行排序, 每次key被访问时, 计数器会增大, 当计数器越大, 意味着当前key的访问越频繁, 也就是意味着它是热点数据
```

##### 最大限制

```
string 最大 512M

List、Set、Sorted Set 可以放 2 的 32 次方个元素(受内存影响)
```



# x.04 持久化



> 持久化: 把内存的数据写入磁盘, 防止服务宕机内存数据丢失. 持久化所得的文件最好备份到不同的服务器

### rdb 快照

##### 快照频率

```
save N M
	在 N 秒内至少 M 个改动才触发一次 rdb
	
save 200 20
	200 秒内至少 20 个改动
```

##### 手动执行快照

```
save
或
gbsave
```



```
redis 默认使用快照方式, 默认文件名 dump.rdb 的二进制文件, 每次执行覆盖之前的内容.


创建子进程进行快照
系统发生崩溃丢失快照后更改的所有数据. 适用于丢失一部份数据也不会造成问题的应用程序

例子
  - 如果内存有10GB数据, 上一个快照2:31开始创建并成功, 3:12开始创建快照, 创建之前有51个键进行更新
  - 如果创建成功之前系统崩溃, 则丢失2:31之后的所有数据
  - 如果创建成功以后系统崩溃, 则丢失51的更新

配置文件
save 60 1000
stop-writes-on-bgsave-error no
rdbcompression yes
dbfilename dump.rdb
```

### AOF

- 将被执行的写命令写到AOF文件末尾, 以此来记录发生的变化. 

- 缺陷
  - redis不断运行, AOF文件不断增长, 在极端情况下, 体积不断增大的AOF文件甚至可能会用完硬盘的所有可用空间
  - 重新执行AOF文件记录的所有写命令来还原数据集, 如果AOF文件的体积非常大, 还原操作执行的时间就可能会非常长

##### 同步频率 appendfsync

- always: 每个写命令都同步写入硬盘, 严重降低 redis 速度, 用户几乎可以不损失任何数据每次只写入一条命令, 其他选项一次写入多条命令这种同步频率下, 机械硬盘每秒大约处理200个命令, 固态硬盘几万个命令
- everysec: 每秒执行一次同步. 兼顾数据安全和写入性能, 每秒同步一次AOF文件时的性能和不使用任何持久化特性时的性能相差无几
  系统崩溃用户也最多只会丢失一秒之内产生的数据。当硬盘忙于执行写人操作的时候, redis还会优雅地放慢自己的速度以便适应硬盘的最大写人速度。
- no: 由操作系统来决定应该在何时对AOF文件进行同步.  一般情况下不会对redis的性能带来影响, 但系统崩溃将导致使用这种选项的redis服务器丢失不定数量的数据. 如果用户的硬盘处理写入操作的速度不够快的话,那么当缓冲区被等待写入硬盘的数据填满时, redis 的写操作将被阻塞, 并导致redis处理命令请求的速度变慢

##### bgrewriteaof

```
为了解决AOF文件体积不断增大的问题, 用户可以向redis发送BGREWRITEAOF命令, 这个命令会通过移除AOF文件中的冗余命令来重写AOF文件, 使AOF文件的体积变得尽可能地小。


1. redis创建一个子进程重写AOF文件, 会导致的性能问题和内存占用问题
2. AOF文件的体积可能会比快照文件的体积大好几倍, 在进行AOF重写并删除旧AOF文件的时候, 删除一个体积达到数十GB大的旧AOF文件可能会导致操作系统挂起数秒
```

##### 配置文件

```
appendonly no
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb  
# 当AOF文件体积大于64MB, 且AOF文件的体积比上一次重写之后的体积大了至少100%时候, redis将执行BGREWRITEAOF命令
```

# x.05 集群

##### redis集群实现方式

- 主从复制

```
读写分离
假如 master宕机了, redis 没有实现自动进行主备切换



主从链
  - 从服务器也可以有从服务器
  - 从服务器对从服务器复制和从服务器对主服务器复制唯一区别在于, 如果从服务器X拥有从服务器Y, 那么当从服务器X在执行表步骤4时, 它将断开与从服务器Y的连接, 导致从服务器Y需要重新连接并重新同步
```

- Sentinel 哨兵机制

```
支持集群模式
着眼于高可用, 在 master 宕机时会自动将 slave 提升为master, 继续提供服务。
```

- cluster

```
负载均衡
解决单机redis容量有限的问题, 将数据按一定的规则分配到多台机器。

redis扩容方式
1. 垂直扩容表示通过加内存方式来增加整个缓存体系的容量比如将缓存大小由2G调整到4G,这种扩容不需要应用程序支持；
2. 水平扩容表示表示通过增加节点的方式来增加整个缓存体系的容量比如本来有1个节点变成2个节点, 这种扩容方式需要应用程序支持



分布式集群首要解决把整个数据集按照分区规则映射到多个节点的问题, 即把数据集划分到多个节点上, 每个节点负责整个数据的一个子集。redis Cluster采用哈希分区规则中的虚拟槽分区。
```

##### 复制

```
如果主从服务器之间的网络带宽不足, 或者主服务器没有足够的内存来创建子进程和创建记录写命令的缓冲区, 那么redis 处理命令请求的效率就会受到影响

最好还是让主服务器只使用50%~ 65%的内存, 留下30%~ 45%的内存用于执行BGSAVE命令和创建记录写命令的缓冲区。
从服务器在与主服务器进行初始连接时, 数据库中原有的所有数据都将丢失, 并被替换成主服务器发来的数据。
同时使用复制和AOF持久化将数据持久化到多台机器上面
```

| 步骤 | 主服务器操作                                                 | 从服务器操作                                                 |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | (等待命令进入)                                               | 连接主服务器, 发送SYNC命令                                   |
| 2    | 开始执行bgsave, 并使用缓冲区记录bgsave之后执行的所有命令     | 根据配置选项决定是否继续使用现有的数据处理客户端的命令请求, 还是想发送请求的客户端返回错误 |
| 3    | bgsave执行完毕向从服务器发送快照文件, 期间继续使用缓冲区记录被执行的写命令 | 丢弃所有旧数据, 载入主服务器发来的快照文件                   |
| 4    | 快照文件发送完毕, 开始向从服务器发送存储的缓冲区里的写命令                          完成快照文件解释操作, 并开始接收命令请求 | 完成快照文件解释操作, 并开始接收命令请求                     |
| 5    | 缓冲区存储的写命令发送完毕, 从现在开始每执行一个写命令就向从服务器发送相同的命令 | 执行主服务器发来的所有缓冲区里面的写命令. 从现在开始接收并执行主服务器传来的每个写命令 |

##### 短结构

```
短结构, 分片结构, 打包存储二进制和字节
```



# 连接池

```
通过预先创建多个连接, 当进行redis操作时, 直接获取已经创建的连接进行操作, 而且操作完成后, 不会释放, 用于后续的其他redis操作, 这样就达到了避免频繁的redis连接创建和释放的目的, 从而提高性能。
redis模块采用ConnectionPool来管理对redis server的所有连接


```



# 性能问题

影响 redis 性能的情况

4个方面: 网络, 磁盘, 内存, cpu

```
带宽: 读写, 同步数据都会受到影响
客户端连接数

内存: 
value 的大小
维护定时器
定时删除过期key: cup 资源紧张时删除 key 影响性能


磁盘性能: 如果缓冲区满了网磁盘持久化时, 如果磁盘写入速度不够快, 会阻塞写操作


bgrewriteaof: 重写 aof 文件时, 占用额外内存, 重写的文件过大导致操作系统挂起


```



# redis分布式锁

##### 分布式锁

- 正确做法

```
使用 set key value [EX seconds][PX milliseconds][NX|XX] 命令 (正确做法)
redis在 2.6.12 版本开始, 为 SET 命令增加一系列选项: 
SET key value[EX seconds][PX milliseconds][NX|XX]
    EX seconds: 设定过期时间, 单位为秒
    PX milliseconds: 设定过期时间, 单位为毫秒
    NX: 仅当key不存在时设置值(就等同于setnx命令)
    XX: 仅当key存在时设置值
    
    
# 当 test 不存在时, 创建并设置过期时间  
SET test 123 NX PX 10000
# 当 test 存在时, 创建并设置过期时间  
SET test 123 XX PX 10000
```

- 1. 使用redis setnx+expire命令 (错误的做法)

```
加锁命令: SETNX key value, 当键不存在时, 对键进行设置操作并返回成功, 否则返回失败。KEY 是锁的唯一标识, 一般按业务来决定命名。
解锁命令: DEL key, 通过删除键值对释放锁, 以便其他线程可以通过 SETNX 命令来获取锁。
锁超时: EXPIRE key timeout, 设置 key 的超时时间, 以保证即使锁没有被显式释放, 锁也可以在一定时间后自动释放, 避免资源被永远锁住。
SETNX 和 EXPIRE 非原子性
如果 SETNX 成功, 在设置锁超时时间后, 服务器挂掉、重启或网络问题等, 导致 EXPIRE 命令没有执行, 锁没有设置超时时间变成死锁。
```

- 2. 锁误解除

```
如果线程 A 成功获取到了锁, 并且设置了过期时间 30 秒, 但线程 A 执行时间超过了 30 秒, 锁过期自动释放, 此时线程 B 获取到了锁；随后 A 执行完成, 线程 A 使用 DEL 命令来释放锁, 但此时线程 B 加的锁还没有执行完成, 线程 A 实际释放的线程 B 加的锁。

通过在 value 中设置当前线程加锁的标识, 在删除之前验证 key 对应的 value 判断锁是否是当前线程持有。可生成一个 UUID 标识当前线程, 使用 lua 脚本做验证标识和解锁操作。
```

- 3. 超时解锁导致并发

```
如果线程 A 成功获取锁并设置过期时间 30 秒, 但线程 A 执行时间超过了 30 秒, 锁过期自动释放, 此时线程 B 获取到了锁, 线程 A 和线程 B 并发执行。

将过期时间设置足够长, 确保代码逻辑在锁释放之前能够执行完成。
为获取锁的线程增加守护线程, 为将要过期但未释放的锁增加有效时间。
```

- 4. 不可重入

```
当线程在持有锁的情况下再次请求加锁, 如果一个锁支持一个线程多次加锁, 那么这个锁就是可重入的。如果一个不可重入锁被再次加锁, 由于该锁已经被持有, 再次加锁会失败。redis 可通过对锁进行重入计数, 加锁时加 1, 解锁时减 1, 当计数归 0 时释放锁。

另一种方式是 redis Map 数据结构来实现分布式锁, 既存锁的标识也对重入次数进行计数
```

- 5. 无法等待锁释放

```

```



```
https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/







5. 无法等待锁释放
上述命令执行都是立即返回的, 如果客户端可以等待锁释放就无法使用。

可以通过客户端轮询的方式解决该问题, 当未获取到锁时, 等待一段时间重新获取锁, 直到成功获取锁或等待超时。这种方式比较消耗服务器资源, 当并发量比较大时, 会影响服务器的效率。
另一种方式是使用 redis 的发布订阅功能, 当获取锁失败时, 订阅锁释放消息, 获取锁成功后释放时, 发送锁释放消息。如下: 



集群
1. 主备切换
为了保证 redis 的可用性, 一般采用主从方式部署。主从数据同步有异步和同步两种方式, redis 将指令记录在本地内存 buffer 中, 然后异步将 buffer 中的指令同步到从节点, 从节点一边执行同步的指令流来达到和主节点一致的状态, 一边向主节点反馈同步情况。

在包含主从模式的集群部署方式中, 当主节点挂掉时, 从节点会取而代之, 但客户端无明显感知。当客户端 A 成功加锁, 指令还未同步, 此时主节点挂掉, 从节点提升为主节点, 新的主节点没有锁的数据, 当客户端 B 加锁时就会成功。


集群脑裂
集群脑裂指因为网络问题, 导致 redis master 节点跟 slave 节点和 sentinel 集群处于不同的网络分区, 因为 sentinel 集群无法感知到 master 的存在, 所以将 slave 节点提升为 master 节点, 此时存在两个不同的 master 节点。redis Cluster 集群部署方式同理。

当不同的客户端连接不同的 master 节点时, 两个客户端可以同时拥有同一把锁。



https://juejin.cn/post/6844903830442737671
```

# 消息队列

> 消息队列要满足三个需求: 有序, 处理重复的消息, 保证消息可靠性

##### list 实现

```
1. 顺序
List 可以使用 LPUSH + RPOP 或 RPUSH + LPOP 实现消息队列
生产者往 List 中写入数据时, List 并不会主动通知消费者有新消息写入, 如果消费者想要及时处理消息，即使没有新消也要不停地调用 RPOP 命令, 带来不必要的性能损失. 
为了解决这个问题, Redis提供了 BRPOP 命令. BRPOP 命令也称为阻塞式读取, 客户端在没有读到队列数据时, 自动阻塞, 直到有新的数据写入队列, 再开始读取新数据


2. 处理重复的消息
自己维护全局唯一消息 ID, 消费者根据 ID 判断消息是否处理过


3. 证消息可靠性
消费者程序从 List 中读取一条消息后, List 就不会再留存这条消息了
如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。
BRPOPLPUSH 从 list1 中 rpop 消息, 再 lpop 到 list2, 并获取这个消息


4. 缺陷:
List 不支持多个消费者消费同一条消息, 因为一旦消费者拉取一条消息后, 这条消息就从 List 中删除了, 无法被其它消费者再次消费
```

##### Stream 实现

```
Stream 
```

# 旧

```
redis Sentinel 与 redis Cluster
https://blog.csdn.net/angjunqiang/article/details/81190562
```

##### redis的并发竞争问题如何解决?

```
redis为单进程单线程模式, 采用队列模式将并发访问变为串行访问。redis本身没有锁的概念, redis对于多个客户端连接并不存在竞争
```

##### 事务

```

```

##### redis 二级缓存

```

```

##### Redlock

```

```

##### pipline

```
pipeline就是用来将n次的网络时间优化为一次的网络时间, 耗时为1次网络时间 + n次命令时间


redis原生有类似 mget mset的批量操作命令, 这些命令都是原子的, 即会阻塞其他的命令, 知道命令完成返回。而pipeline的每一条命令是拆分过的（非原子）, 假设打包1000个命令的pipeline传到服务端, 则服务端会把pipeline的每个命令当成原子。但无论是pipeline还是M操作 返回的结果都是一样的。



pipeline与M操作都会将数据顺序的传送顺序地返回（redis 单线程）

1.每次pipeline携带数量不推荐过大, 否则会影响网络性能;
2.pipelinepipeline每次只能作用在一个redis节点上;
```

##### 原生M操作

```

```

# 应用问题

##### 缓存数据库的双写一致性的问题

```


问题：一致性的问题是分布式系统中很常见的问题。一致性一般分为两种：强一致性和最终一致性, 当我们要满足强一致性的时候, Redis也无法做到完美无瑕, 因为数据库和缓存双写, 肯定会出现不一致的情况, Redis只能保证最终一致性。

解决：我们如何保证最终一致性呢？

    第一种方式是给缓存设置一定的过期时间, 在缓存过期之后会自动查询数据库, 保证数据库和缓存的一致性。如果不设置过期时间的话, 我们首先要选取正确的更新策略：先更新数据库再删除缓存。但我们删除缓存的时候也可能出现某些问题, 所以需要将要删除的缓存的key放到消息队列中去, 不断重试, 直到删除成功为止。
```

##### 缓存雪崩问题

```


问题： 我们应该都在电影里看到过雪崩, 开始很平静, 然后一瞬间就开始崩塌, 具有很强的毁灭性。这里也是一样的, 我们执行代码的时候将很多缓存的实效时间设定成一样, 接着这些缓存在同一时间都会实效, 然后都会重新访问数据库更新数据, 这样会导致数据库连接数过多、压力过大而崩溃。

解决：

    设置缓存过期时间的时候加一个随机值。设置双缓存, 缓存1设置缓存时间, 缓存2不设置, 1过期后直接返回缓存2, 并且启动一个进程去更新缓存1和2。
```

##### 缓存穿透问题

```


问题： 缓存穿透是指一些非正常用户(黑客)故意去请求缓存中不存在的数据, 导致所有的请求都集中到到数据库上, 从而导致数据库连接异常。

解决:

    利用互斥锁。缓存失效的时候, 不能直接访问数据库, 而是要先获取到锁, 才能去请求数据库。没得到锁, 则休眠一段时间后重试。采用异步更新策略。无论key是否取到值, 都直接返回。value值中维护一个缓存失效时间, 缓存如果过期, 异步起一个线程去读数据库, 更新缓存。需要做缓存预热(项目启动前, 先加载缓存)操作。提供一个能迅速判断请求是否有效的拦截机制。比如利用布隆过滤器, 内部维护一系列合法有效的key, 迅速判断出请求所携带的Key是否合法有效。如果不合法, 则直接返回。
```

##### 缓存的并发竞争问题

```
问题：

缓存并发竞争的问题, 主要发生在多线程对某个key进行set的时候, 这时会出现数据不一致的情况。

比如Redis中我们存着一个key为amount的值, 它的value是100, 两个线程同时都对value加100然后更新, 正确的结果应该是变为300。但是两个线程拿到这个值的时候都是100, 最后结果也就是200, 这就导致了缓存的并发竞争问题。

解决

    如果多线程操作没有顺序要求的话, 我们可以设置一个分布式锁, 然后多个线程去争夺锁, 谁先抢到锁谁就可以先执行。这个分布式锁可以用zookeeper或者Redis本身去实现。可以利用Redis的incr命令。当我们的多线程操作需要顺序的时候, 我们可以设置一个消息队列, 把需要的操作加到消息队列中去, 严格按照队列的先后执行命令。
```



# 参考

[官网文档](http://redis.cn/documentation.html)

数据类型

- [ ] https://blog.csdn.net/u012060033/article/details/129168155
- [ ] https://www.cnblogs.com/kmcl1314/articles/15896129.html string
- [ ] https://zhuanlan.zhihu.com/p/364720565
- [ ] https://zhuanlan.zhihu.com/p/148562122
- [ ] https://zhuanlan.zhihu.com/p/593111008
- [x] https://zhuanlan.zhihu.com/p/64772193 1
- [ ] https://zhuanlan.zhihu.com/p/68667360 2
- [ ] https://juejin.cn/post/6844903951502934030
- [ ] https://cloud.tencent.com/developer/article/1667574
- [ ] https://cloud.tencent.com/developer/article/1442961?from=article.detail.1667574&areaSource=106000.12&traceId=DA3zaAlbl_6IooH3Cs-sm
- [ ] https://cloud.tencent.com/developer/article/1921542?from=article.detail.1442961&areaSource=106000.8&traceId=iaayeX_P3We0kPNxU543b
- [ ] https://zhuanlan.zhihu.com/p/528146852 详细
- [ ] https://zhuanlan.zhihu.com/p/345618221
- [ ] https://www.cnblogs.com/hunternet/p/12742390.html
- [ ] https://www.cnblogs.com/qdhxhz/p/15669348.html
- [ ] https://www.cnblogs.com/bbgs-xc/p/14376109.html
- [ ] http://kaito-kidd.com/2021/04/19/can-redis-be-used-as-a-queue/

基本原理

- [ ] https://zhuanlan.zhihu.com/p/364494952
- [ ] https://cloud.tencent.com/developer/article/1158989?from=article.detail.1442961&areaSource=106000.9&traceId=iaayeX_P3We0kPNxU543b



- **[Redis 数据类型和应用场景](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/data_struct/command.html)**
  - **[图解 Redis 数据结构](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/data_struct/data_struct.html)**

- 持久化篇 

- - **[AOF 持久化是怎么实现的？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/storage/aof.html)**
  - **[RDB 快照是怎么实现的？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/storage/rdb.html)** 

- 集群篇 

- - **[什么是缓存雪崩、击穿、穿透？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/cluster/cache_problem.html)**
  - **[主从复制是怎么实现的？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/cluster/master_slave_replication.html)**
  - **[为什么要有哨兵？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/cluster/sentinel.html)**

- 架构篇 

- - **[数据库和缓存如何保证一致性？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/architecture/mysql_redis_consistency.html)**



