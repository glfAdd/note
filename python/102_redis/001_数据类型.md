# x.01 数据类型

## redisObject

##### 编码方式

<img src=".\image\数据结构2.webp" alt="数据结构2" style="zoom:80%;" />

<img src=".\image\数据结构3.webp" alt="数据结构3" style="zoom:100%;" />



```
1. redis 用 c 语言开发
2. redis 的 key 限制为 512MB
3. redis 中所有 key 和 value 都包含 redisObject 结构体
```

##### redisObject 结构体

```c
// 4 + 4 + 24 + 32 + 64 = 128bits = 16bytes
struct RedisObject {
    int4 type; 				// 数据类型(string、list、hash等), 4bits
    int4 encoding; 			// 编码形式, 4bits
    int24 lru; 				// 对象的LRU信息, 24bits
    int32 refcount; 		// 引用计数器, 32bits
    void *ptr; 				// 指针指向对象的具体内容, 64bits
}
```

## dict 数据结构

<img src=".\image\dict数据结构2.png" alt="dict数据结构2" style="zoom:80%;" />

```
Redis 的 key value 映射用一个 dict 数据结构维护, 基于哈希表算法, 用 key 计算哈希值, 得到 key 在哈希表中的位置, 用拉链的方式解决哈希冲突, 在装在因子为超过预定值时自动扩容, 此时引发 rehasing (重哈希)
```

##### 数据结构

<img src=".\image\dict数据结构.webp" alt="dict数据结构" style="zoom:100%;" />

```c
// dict字典的数据结构
typedef struct dict{
    dictType *type; 			//直线dictType结构, dictType结构中包含自定义的函数, 这些函数使得key和value能够存储任何类型的数据
    void *privdata; 			// 私有数据, 保存着dictType结构中函数的 参数
    dictht ht[2]; 				// 两张哈希表
    long rehashidx; 			// rehash 的标记, rehash 时每迁移一个桶就对rehashidx +1, (-1 表示没有进行 rehash)
    int itreators;  			//正在迭代的迭代器数量
}
 
// dict 结构中 ht[0] ht[1] 哈希表的数据结构
typedef struct dictht{
    dictEntry[] table;        	// 存放元素数组的地址, 数组中存放哈希节点dictEntry的地址
    unsingned long size;      	// 哈希表table的大小, 出始大小为4
    unsingned long  sizemask; 	// 用于将 hash 值映射到 table 位置的索引
    unsingned long  used;     	// 记录哈希表已有节点（键值对）的数量  (所有链表中节点总数)?
}
```

##### 负载因子

```c
// 负载因子 = 哈希表已保存节点数量 / 哈希表大小
load_factor = ht[0].used / ht[0].size
```

##### rehash

```
1. 随着操作的不断执行, 哈希表保存的键值对会逐渐地增多或者减少, 为了让哈希表的负载因子 (load factor) 维持在一个合理的范围之内, 当哈希表保存的键值对数量太多或者太少时, 程序需要对哈希表的大小进行相应的扩展或者收缩
2. rehash 触发条件: 扩容操作 或 收缩操作
3. 扩展和收缩哈希表的通过执行 rehash (重新散列) 操作来完成
4. rehash 指的是重新计算键的哈希值和索引值
5. dict 采用哈希函数对 key 取哈希值得到在哈希表中的位置(桶的位置), 采用拉链法解决hash冲突
6. ht[2] 这两个哈希表 ht[0]和ht[1], rehash 时才都有效; 平常情况下, 只有 ht[0] 有效, ht[1] 没有任何数据.
7. 当装载因子 (load factor) 超过预定值时就会进行rehash


扩容和缩容都会通过 rehash 来实现
```

##### 扩容条件

```
满足其一:
    1. 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且哈希表的负载因子大于等于 1
    2. 哈希表的负载因子大于等于 5, 强制扩容, 无论是否在执行 BGSAVE 或 BGREWRITEAOF


在执行 BGSAVE 命令或 BGREWRITEAOF命令时, Redis 会 fork 一个子进程, 而大多数操作系统都采用写时复制（copy-on-write）技术来优化子进程的使用效率, 所以在子进程存在期间, 服务器会提高执行扩展操作所需的负载因子, 尽可能地避免在子进程存在期间进行哈希表扩展操作, 这可以避免不必要的内存写入操作, 最大限度地节约内存
```

##### 收缩条件

```c
不用考虑是否在执行 BGSAVE 或 BGREWRITEAOF

// 当哈希表的负载因子小于 0.1 时, 即填充率必须<10%
(ht[0].used / ht[0].siz) < 0.1
```

##### rehash 过程

```
1. 为 dict 的 ht[1] 哈希表分配空间, 大小取决于要执行的操作, 以及 ht[0] 当前包含的键值对数量:
    如果扩是展操作, 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n （2 的 n 次方幂） (也就是原来的 2 倍)
    如果是收缩操作, 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n 
2. 字典的 rehashidx 设置为0, 表示 rehash 工作正式开始. rehashidx 表示 rehash 到哪个链表了, table[rehashidx]得到对应的桶
3. 在 rehash 进行期间, 每次对字典执行 添加/删除/查找/更新 操作时, 除了执行指定的操作以外, 对这个 key 进行 rehash
	a. dict 添加操作: 如果正在重哈希中, 会把数据插入到 ht[1], 否则插入到 ht[0]
    b. dict 查询操作: 先在第一个哈希表ht[0]上进行查找, 再判断当前是否在重哈希, 如果没有, 那么在ht[0]上的查找结果就是最终结果。否则, 在ht[1]上进行查找。查询时会先根据key计算出桶的位置, 在到桶里的链表上寻找key。
    c. dict 删除操作: 如果正在重哈希中, 同时在 ht[0] 和 ht[1] 删除, 否则只在 ht[0] 中删除
4. 当 rehash 完成一个链表所在的桶之后, 将rehashidx 属性的值 +1, 表示下一次要迁移链表所在桶的位置
5. 随着字典操作的不断执行, 最终 ht[0] 的所有桶对应的键值对都会被 rehash 至 ht[1], ht[0] 变为空表, 释放 ht[0], 将 ht[1] 设置为 ht[0], 并在 ht[1] 新创建一个空白哈希表, 为下一次 rehash 做准备
6. 将 rehashidx 属性的值设为 -1, 表示 rehash 操作已完成
```

##### 渐进式 rehash

```
1. 将扩容和收缩操作分为多次执行, 每次只 rehash 一个链表, 避免一次 rehash 的数据数据量过大, 导致 redis 服务阻塞
2. rehash 过程中如果执行了增删改查操作, 除了增删改查操作外, 还会对 ht[0] 和 ht[1] 这个 key 进行 rehash
3. 渐进式 rehash 执行期间的哈希表操作
    a. 删除、查找、更新: 在渐进式 rehash 执行期间, 字典会同时使用 ht[0] 和 ht[1] 两个哈希表 (例如, 查找一个键, 先在 ht[0] 里面查找, 如果没找到, 到 ht[1] 里面进行查找)
    b. 新增数据: 在渐进式 rehash 执行期间, 新添加到字典的键值对都只保存到 ht[1], ht[0] 不进行任何添加操作
```

##### rehash 实例

<img src=".\image\rehash1.png" alt="rehash1" style="zoom:80%;" />

```
ht[0].used 当前的值为 4, 4 * 2 = 8, 而 8 （2^3）恰好是第一个大于等于 4 的 2 的 n 次方,  所以程序会将 ht[1] 哈希表的大小设置为 8 
```

<img src=".\image\rehash2.png" alt="rehash2" style="zoom:80%;" />

```
ht[1] 在分配空间之后
```

<img src=".\image\rehash3.png" alt="rehash3" style="zoom:80%;" />

```
将 ht[0] 包含的四个键值对都 rehash 到 ht[1] 
```

<img src=".\image\rehash4.webp" alt="rehash4" style="zoom:80%;" />

```
释放 ht[0] , 并将 ht[1] 设置为 ht[0] , 然后为 ht[1] 分配一个空白哈希表
```

##### hash 冲突

<img src=".\image\hash.webp" alt="hash" style="zoom:100%;" />

```
1. 通过 hash 表达式, 不同的 key 得到的 hash 值相同, 即为 hash 冲突
2. redis 使用链地址法 (hash 桶) 解决冲突, 每个 hash 值对应一个单链表, 即桶. 将 hash 冲突的值放入桶中
rehash 增加现有的哈希桶数量减少哈希冲突



```



## string

#### 底层实现

<img src=".\image\int2.webp" alt="int2" style="zoom:80%;" />

```
1. string 内部 encoding 有 3 种: 
	int, raw 和 embstr
2. string 底层数据结构有 2 种: 
	int 和 SDS
3. redis 的 key 和 string 类型 value 限制均为 512MB. key 太大影响检索性能
4. encoding 方式如何选择 (分界值不同版本不一样, 44 是最新的)
    1. 如果字符串对象保存的是整数值, 并且这个整数值可以用 long 类型来表示, 会用 int 数据结构, 编码是 int, 整数值保存在 ptr 属性里面
    2. 如果字符串对象保存的是字符串, 并且这个字符申的长度 <= 44, 会用 SDS 数据结构, SDS 编码是 embstr 
    3. 如果字符串对象保存的是字符串, 并且这个字符申的长度 > 44, 会用 SDS 数据结构, SDS 编码是 raw 
```

#### int

<img src=".\image\int2.jpg" alt="int2" style="zoom:50%;" />

```
8字节的长整型 long, 范围 2^63-1 (40亿)
```

#### SDS

> 二进制安全: c 语言 "\0" 表示字符串的结束, 如果字符串本身就有 "\0" 字符, 字符串就会被截断, 即非二进制安全. 若通过某种机制保证读写字符串时不损害其内容, 则是二进制安全.
>
> SDS (Simple Dynamic string): 简单动态字符串

1. Redis 用 C 语言编写, 但 Redis 没用 char 来表示字符串, 而是用 SDS 来存储字符串数据.
2. c 语言字符串不记录长度, 每次获取长度都需要遍历, 时间的复杂度是O(n); SDS 用 len 属性记录长度, 获取长度时间复杂度变为O(1).
4. c 语言字符串以空字符串 "\0" 作为结束符, 一些图片中含有结束符, 不是二进制安全; SDS 是二进制安全的, 使用 len 属性的值判断字符串是否结束, 而不是空字符来 "\0". SDS 所有 API 都会以处理二进制的方式来处理存放在 buf[ ] 数组里的数据. 所以可以保存文本数据和二进制数据(图片, 视频等).
6. c 语言两个字符串拼接, 若没有分配足够长度的内存空间就会出现缓冲区溢出; SDS 先根据 len 判断空间是否满足要求, 若是空间不够, 就会进行相应的空间扩展, 不会出现缓冲区溢出.
5. SDS 空间预分配: 给字符串分配空间时, 分配的空间比实际要多, 减少连续的执行字符串增长带来内存重新分配的次数
    1. 如果 SDS 的长度 len 小于 1MB, redis 会分配和 len 同样大小的未使用空间 (例如 len 为 13字节, redis 也会分配 13字节的未使用空间, 因此 SDS 的 buf 数组实际长度 13+13+1=27 字节, 额外的 1 字节用于保存空字符)
    2. 如果 SDS 的长度 len 大于等于 1MB, redis 会分配 1MB 的未 使用空间。例如, len 的长度为 30MB, 那么将分配 1MB 的未使用空间, 因此 SDS 的 buf 数组实际长度变 30MB + 1MB + 1byte
6. SDS 惰性空间释放: 当字符串被缩短的时候, SDS也不会立即回收不适用的空间, 而是通过 free 属性将不使用的空间记录下来, 等后面使用的时候再释放, 并为将来可能的增长操作提供了优化. 在需要的时候回释放 SDS 未使用的空间, 不会浪费内存.

```

```



##### raw 编码

<img src=".\image\raw编码结构2.webp" alt="raw编码结构2" style="zoom:100%;" />

##### embstr 编码

<img src=".\image\embstr编码结2.png" alt="embstr编码结2" style="zoom:40%;" />

##### embstr 对比 raw

```
1. embstr 和 raw 都是由 redisObject 和 sds 组成
2. raw 需要为 redisObject 和 sds 内存不是连续的
	a. 分配内存时, 要分配 2 次内存
	b. 释放内存时, 要调用 2 次内存释放函数
3. embstr 的 redisObject 和 sds 内存是连续的
	a. 分配内存时, 要分配 1 次内存
	b. 释放内存时, 要调用 1 次内存释放函数
	c. 字符串的长度增加需要重新分配内存时, redisObject 和 sds 都需要重新分配内存
	d. embstr 编码的字符串对象实际上是只读的, redis 没有为 embstr 编码的字符串对象编写任何相应的修改程序. 对 embstr 编码字符串对象执行任何修改命令 (例如 append) 时, 会先将对象的编码从 embstr 转换成 raw, 然后再执行修改命令


例如:
    > set test3 ccc
    OK
    > object encoding test3
    embstr
    > append test3 eee
    6
    > object encoding test3
    raw
    > set test3 ccc
    OK
    > object encoding test3
    embstr	
```

##### SDS 内存优化

```
1. 优化了 sds 的内存使用, 用于存储字符串的内存就会变大
2. raw 和 embstr 编码的分界线:
	redis 2.+ 是 32 字节
	redis 3.0-4.0 是 39 字节
	redis 5.0 是 44 字节
```

- 旧版 sds 占用内存

  ```c
  // 内存分配器 jemalloc 分配的内存如果超出了64个字节就认为是一个大字符串, 用 raw 编码
  // SDS 结构体中的 content 的字符串是以字节 \0 结尾的字符串 (是为了便于直接使用 glibc 的字符串处理函数, 以及为了便于字符串的调试打印输出)
  // 64byte - 16byte - 8byte - 1byte = 39byte
  struct SDS {
      unsigned int capacity;	// 4byte
      unsigned int len; 		// 字符串长度, 4byte
      byte[] content; 		// 数组, 保存字符串的每一个字符元素
  }
  ```
  
- 新版 sds 占用内存

  <img src=".\image\sds.png" alt="sds" style="zoom:90%;" />

  ```c
  // unsigned int 变成了 uint8_t, uint16_t, 还加了一个char flags标识, 总共只用了3个字节的大小。相当于优化了sds的内存使用, 相应的用于存储字符串的内存就会变大
  // 64byte - 16byte -3byte -1byte = 44byte。  
  struct SDS {
      int8 capacity; // 1byte
      int8 len; // 1byte
      int8 flags; // 1byte
      byte[] content; // 内联数组, 长度为 capacity
  }
  ```

#### 命令

```
set k v
get k
del k

incr k                  值自增1
decr k                  值自减1
incrby k n              值加n
decrbu k n              值减n
incrbyfloat k n         值加浮点n

append k v              值末尾追加字符串
getrange k start end    获取start和end之间字符
setrange k start v      从start开始替换为v
getbit
setbit
bitcount
bitop

EXISTS k						判断是否存在
STRLEN k						字符串长度
MSET key1 value1 key2 value2	批量设置
MGET key1 key2 					批量获取
SET number 0					设置 key-value 类型的值 
INCR number						将 key 中储存的数字值增一 
INCRBY number 10				将key中存储的数字值加 10
DECR number						将 key 中储存的数字值减一
DECRBY number 10				将key中存储的数字值键 10
EXPIRE name  60					设置 key 在 60 秒后过期（该方法是针对已经存在的key设置过期时间）
TTL name						查看数据还有多久过期
SETNX key value					不存在就插入
SET key value EX 60				设置 key-value 类型的值, 并设置该key的过期时间为 60 秒
SETEX key  60 value				设置 key-value 类型的值, 并设置该key的过期时间为 60 秒
```

## list

#### 底层实现

```
1. list 是字符串列表, 按照插入顺序排序, 可以从列表头部/尾部的添加/移除元素
2. list 的最大长度为 2^32 - 1 个元素 (40 亿)
3. Redis 3.2 版本前底层数据结构是 ziplist 和 linkedlist, 3.2 后只有 quicklist


3.2 版本前
ziplist: 当哈希类型中元素个数小于 512 个 (默认, hash-max-ziplist-entrie 设置), 并所有值都小于 64 字节 (默认, hash-max-ziplist-value 设置) 时, Redis 会使用 ziplist 作为哈希的内部实现
hashtable: 当上述条件不满足时, Redis 则会采用 hashtable 作为哈希的内部实现。
linkedlist 占用内存比 ziplist 多, 创建新的列表键时, 先用 ziplist, 并且在有需要的时候, 才从 ziplist 实现转换到 linkedlist
```

#### ziplist (压缩列表)

##### 概念

```
ziplist 是一组连续内存块组成的顺序的数据结构, 能节省内存, 压缩列表中使用多个节点来存储数据
```

##### 结构体

```c
struct ziplist<T> {
    int32 zlbytes; 			// 整个压缩列表占用字节数, 4byte
    int32 zltail_offset; 	// 最后一个元素距离压缩列表起始位置的偏移量, 用于快速定位到最后一个节点, 4byte
    int16 zllength; 		// 元素个数, 2byte
    T[] entries; 			// 列表中的每一个节点
    int8 zlend; 			// 压缩列表特殊结束符号, 值恒为 0xFF
}
```

<img src=".\image\hash2.png" alt="hash2" style="zoom:80%;" />

<img src=".\image\hash3.png" alt="hash3" style="zoom:60%;" />

```
entry 节点
	previous_entry_ength: 表示前一个节点 entry 的长度, 可用于计算前一个节点的其实地址, 因为他们的地址是连续的
	content:每个节点的内容
	encoding: content 内容类型和长度
```



```
127.0.0.1:6379> rpush dotahero sf qop doom
(integer) 3
127.0.0.1:6379> object encoding dotahero
"ziplist"
```

#### linkedlist (双向列表)

<img src=".\image\链表.webp" alt="链表" style="zoom:80%;" />

#### quicklist (快速列表)

```
quicklist(快速列表)实现的, 快速列表支持从链表头和尾添加元素, 并且可以获取指定位置的元素内容。
是 linkedlist 和 ziplist 的结合, quicklist 中的每个节点 ziplist 都能够存储多个数据元素
```

#### 命令

```
lpush k v1 v2           左边添加多个元素
rpush k v1 v2           右边添加多个元素
lpop k
rpop k
lindex k v              获取指定位置上一个元素
lrange k start end      获取指定范围所有元素
ltrim k start end       只保留start和end及之间的元素  

blpop k timeout         从第一个非空列表中弹出最左边元素, 或timeout内等待可弹出的元素出现                   
brpop                                        右
rpoplpush k1 k2         弹出 k1 list 最右边, 推入 k2 list 最左, 并获取这个元素 
brpoplpush k1 k2 timeout弹出 k1 list 最右边, 推入 k2 list 最左, 并获取这个元素, 如果k1位空则阻塞timeout直到元素出现
```

## hash

```
2. 每个 hash 可以存储 2^32 - 1 键值对 (40多亿)



新键值添加到字典时, 先根据键计算出哈希值和索引值, 根据索引将新键值对的节点放到哈希表数组(table)的指定索引上面
Redis 通常使用 MurmurHash2 计算键的哈希值, 这种算法的优点在于, 即使输入的键是有规律的, 算法仍能给出一个很好的随机分布性, 并且算法的计算速度也非常快
而索引值计算则非常简单：将哈希值和 dictht::sizemask 做与运算的结果即为索引值。
比如, 哈希值为 6, sizemask 为 3, 则索引值为 6&3 = 2
```



#### redis hash 结构

<img src=".\image\hash结构.webp" alt="hash结构" style="zoom:80%;" />

```c
typedef struct dictht {
    dictEntry **table; 			// 元素数组. 每个元素都是一个链表的头指针, 链表中每个结点都保存着一个键值对
    unsigned long size;			// table 数组的大小, 总是为 2^n
    unsigned long sizemask;		// 用于计算索引值的掩码, 总是等于 size-1
    unsigned long used;			// hash 表中的已有结点数量 (所有链表中节点总数)
} dictht;
```

#### 底层实现

```
Redis 7.0 前, 底层数据结构是 ziplist 或 hashtable
Redis 7.0 后, 弃用 ziplist 和 hashtable, 由 listpack 实现

ziplist: 当 hash 中元素个数小于 hash-max-ziplist-entries配置（默认 512 个）, 且所有值都小于 hash-max-ziplist-value 配置（默认 64 字节）时, Redis 会使用 ziplist 作为哈希的内部实现
hashtable: 当上述条件不满足时, Redis 则会采用 hashtable 作为哈希的内部实现
```

#### rehash

##### hash 冲突

##### 渐进式 rehash 

```
1. rehash: hash 的扩容和缩容
2. 渐进式 rehash: redis 是单线程, 大字典 rehash 耗时久, 阻塞时间长, 因此逐步操作

1. 扩容和缩容都会通过 rehash 来实现
2. 渐进式rehash: 是指我们的大字典的扩容是比较消耗时间的, 需要重新申请新的数组, 然后将旧字典所有链表的元素重新挂接到新的数组下面, 是一个O(n)的操作。但 redis 是单线程, 无法承受这样的耗时过程, 所以采用了渐进式rehash小步搬迁, 虽然慢一点, 但是可以搬迁完毕


扩容时新建一个长度为原始长度 2 倍的空哈希表
, 然后原哈希表上的元素重新 rehash 到新的哈希表中去
```

##### 渐进式 rehash 过程

```
redis 采用渐进式 rehash, 有个变量指向第一个哈希桶, 然后 redis 每执行一个添加key, 删除key的类似命令, 就顺便copy一个哈希桶中的数据到新的哈希表中去,就会所有的数据都被重新hash到新的哈希表中。
那么在这个过程中, 当然再有写的操作, 会直接把数据放到新的哈希表中, 保证旧的肯定有copy完的时候, 如果这段时间对数据库的操作比较少, 也没有关系, redis内部也有定时任务, 每隔一段时间也会copy一次

redis 通过链式哈希解决冲突, 也就是同一个桶里面的元素使用链表保存。但是当链表过长就会导致查找性能变差可能。所以redis为了追求块, 使用了两个全局哈希表。用于rehash操作, 增加现有的哈希桶数量, 减少哈希冲突
开始默认使用hash表1保存键值对数据, hash表2此刻没有分配空间。当数据越来越多的触发rehash操作, 则执行以下操作：

    给hash表2分配更大的空间
    将hash表1的数据重新映射拷贝到hash表2中
    将hash表1的数据重新映射到hash表2的过程并不是一次性的, 这样会造成redis阻塞, 无法提供服务
    释放hash表1的空间

详细步骤：

    为ht[1]分配空间, 让字典同时持有ht[0]和ht[1]两个hash表
    在字典中维持一个索引计数器变量rehashidx, 并将它的值设置为0, 表示rehash工作正式开始
    在rehash进行期间, 每次对字典执行添加, 删除, 查找或者更新操作时, 程序除了执行特定的操作以外, 还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1], 当rehash工作完成之后, 程序将rehashidx属性的值增1
    随着字典操作的不断执行, 最终在某个时间点上, ht[0]的所有键值对都会被rehash至ht[1], 这时程序将rehashidx属性的值设为-1, 表示rehash操作已完成
    将ht[0]释放, 然后将ht[1]设置成ht[0], 最后为ht[1]分配一个空白哈希表

```

##### rehash触发条件

```
1. 扩容
扩容一般会在 Hash 表中的元素个数等于第一维数组的长度的时候, 就会开始扩容。
扩容的大小是原数组的两倍。不过在redis在做bgsave（RDB持久化操作的过程）时, 为了减少内存页的过多分离（Copy On Write）, redis不会去扩容。
但是如果hash表的元素个数已经到达了第一维数组长度的5倍的时候, 就会强制扩容, 不管你是否在持久化。

2. 缩容
当我们的hash表元素逐渐删除的越来越少的时候。redis就会对hash表进行缩容来减少第一维数组长度的空间占用。缩容的条件是元素个数低于数组长度的10%, 并且缩容不考虑是否在做redis持久化。
不用考虑bgsave主要原因是因为我们的缩容的内存都是已经使用过的, 缩容的时候可以直接置空, 而且由于申请的内存比较小, 同时会释放掉一些已经使用的内存, 不会增大系统的压力。
```



#### hashtable (哈希表)



#### 命令

```
hset k1 k2 v
hget k1 k2
hdel k1 k2
hgetall k1              获取所有键值对
hmget K k1 k2           获取1个/多个键的值
hmset K k1 v1 k2 v2     添加1个/多个值
hdel K k1 k2            获取成功删除的数量
hlen K                  获取键值对的数量
hexists K k             查看k是否存在
hkeys K k               删除
hvals K                 获取所有值
hgetall K               获取所有键值对
hincrby K k count       值加上count
hincrbyfloat K k count  值加上count 浮zrange点
```



## set



```
1. 存储 string 类型集合, 无序, 不重复
2. 通过哈希表实现的, 所以添加, 删除, 查找的复杂度都是O(1)
3. 集合中最大的成员数为 2^32 - 1 (每个集合可存储40多亿个成员)




Set 类型是一个无序并唯一的键值集合, 它的存储顺序不会按照插入的先后顺序进行存储。

一个集合最多可以存储 2^32-1 个元素。概念和数学中个的集合基本类似, 可以交集, 并集, 差集等等, 所以 Set 类型除了支持集合内的增删改查, 同时还支持多个集合取交集、并集、差集。

Set 类型和 List 类型的区别如下：

List 可以存储重复元素, Set 只能存储非重复元素；List 是按照元素的先后顺序存储元素的, 而 Set 则是无序方式存储元素的。

Set 的差集、并集和交集的计算复杂度较高, 在数据量较大的情况下, 如果直接执行这些计算, 会导致 Redis 实例阻塞

```

#### 底层实现

```
底层数据结构是 hashtable 或 intset

如果集合中的元素都是整数且元素个数小于 512 （默认值, set-maxintset-entries配置）个, Redis 会使用整数集合作为 Set 类型的底层数据结构；如果集合中的元素不满足上面条件, 则 Redis 使用哈希表作为 Set 类型的底层数据结构。

intset: 当集合中的元素都是整数, 并且集合中的元素个数小于 512 时(默认, set-max-intset-entries 设置), 用 intset 作为底层内部实现
hashtable: 当上述条件不满足时, Redis 会采用 hashtable 作为底层实现。
```





```

```

#### 底层实现

```

```





#### intset (整数集合)

```
inset: 整数集合, 用于保存整数值的数据结构类型, 如 int16_t, int32_t, int64_t

在整数集合中, 有三个属性值
encoding: 编码方式
contents[]: 元素的内容
length: 整数集合的长度


在整数集合新增元素的时候, 若是超出了原集合的长度大小, 就会对集合进行升级, 具体的升级过程如下
	首先扩展底层数组的大小, 并且数组的类型为新元素的类型。
	然后将原来的数组中的元素转为新元素的类型, 并放到扩展后数组对应的位置。
	整数集合升级后就不会再降级, 编码会一直保持升级后的状态。
```



#### 应用

##### 点赞

```
Set 类型可以保证一个用户只能点一个赞, 这里举例子一个场景, key 是文章id, value 是用户id。

uid:1 、uid:2、uid:3 三个用户分别对 article:1 文章点赞了。

# uid:1 用户对文章 article:1 点赞
> SADD article:1 uid:1
(integer) 1
# uid:2 用户对文章 article:1 点赞
> SADD article:1 uid:2
(integer) 1
# uid:3 用户对文章 article:1 点赞
> SADD article:1 uid:3
(integer) 1

uid:1 取消了对 article:1 文章点赞。

> SREM article:1 uid:1
(integer) 1

获取 article:1 文章所有点赞用户 :

> SMEMBERS article:1
1) "uid:3"
2) "uid:2"

获取 article:1 文章的点赞用户数量：

> SCARD article:1
(integer) 2

判断用户 uid:1 是否对文章 article:1 点赞了：

> SISMEMBER article:1 uid:1
(integer) 0  # 返回0说明没点赞, 返回1则说明点赞了

```



##### 共同关注

```


Set 类型支持交集运算, 所以可以用来计算共同关注的好友、公众号等。

key 可以是用户id, value 则是已关注的公众号的id。

uid:1 用户关注公众号 id 为 5、6、7、8、9, uid:2 用户关注公众号 id 为 7、8、9、10、11。

# uid:1 用户关注公众号 id 为 5、6、7、8、9
> SADD uid:1 5 6 7 8 9
(integer) 5
# uid:2  用户关注公众号 id 为 7、8、9、10、11
> SADD uid:2 7 8 9 10 11
(integer) 5

uid:1 和 uid:2 共同关注的公众号：

# 获取共同关注
> SINTER uid:1 uid:2
1) "7"
2) "8"
3) "9"

给 uid:2 推荐 uid:1 关注的公众号：

> SDIFF uid:1 uid:2
1) "5"
2) "6"

验证某个公众号是否同时被 uid:1 或 uid:2 关注:

> SISMEMBER uid:1 5
(integer) 1 # 返回0, 说明关注了
> SISMEMBER uid:2 5
(integer) 0 # 返回0, 说明没关注

```



##### 抽奖活动

```


存储某活动中中奖的用户名 , Set 类型因为有去重功能, 可以保证同一个用户不会中奖两次。

key为抽奖活动名, value为员工名称, 把所有员工名称放入抽奖箱 ：

>SADD lucky Tom Jerry John Sean Marry Lindy Sary Mark
(integer) 5

如果允许重复中奖, 可以使用 SRANDMEMBER 命令。

# 抽取 1 个一等奖：
> SRANDMEMBER lucky 1
1) "Tom"
# 抽取 2 个二等奖：
> SRANDMEMBER lucky 2
1) "Mark"
2) "Jerry"
# 抽取 3 个三等奖：
> SRANDMEMBER lucky 3
1) "Sary"
2) "Tom"
3) "Jerry"

如果不允许重复中奖, 可以使用 SPOP 命令。

# 抽取一等奖1个
> SPOP lucky 1
1) "Sary"
# 抽取二等奖2个
> SPOP lucky 2
1) "Jerry"
2) "Mark"
# 抽取三等奖3个
> SPOP lucky 3
1) "John"
2) "Sean"
3) "Lindy"

```

#### 命令

```
sadd k v1 v2            添加1个/多个元素, 获取不存在新增加的个数        
srem k v1 v2            删除1个/多个元素, 获取删除的个数
scard k                 获取元素个数
smembers k              获取所有元素
sismember k v           是否包含元素v
srandmember k count     随机获取count个元素, 当count为正数时元素不重复, 负数时可以重复
spop k                  随机移除一个元素并获取元素
smove k1 k2 v           如果k1有元素v则移动到k2则


SINTER key [key ...]					交集运算
SINTERSTORE destination key [key ...]	将交集结果存入新集合destination中
SUNION key [key ...]					并集运算
SUNIONSTORE destination key [key ...]	将并集结果存入新集合destination中
SDIFF key [key ...]						差集运算
SDIFFSTORE destination key [key ...]	将差集结果存入新集合destination中
```

## zset

<img src=".\image\zset.jpg" alt="zset" style="zoom:50%;" />

```
1. zset 是有序集合, 每个元素都有一个 double 类型的 score (分数), redis 通过分数来为集合中的成员进行排序
2. score 可以重复
```

#### 底层实现

```
ziplist: 当有序集合的元素个数小于 128 (默认 , zset-max-ziplist-entries 设置), 同时每个元素的值都小于 64 字节(默认, zset-max-ziplist-value 设置), 用 ziplist 作为有序集合的内部实现。
skiplist：当上述条件不满足时, Redis 会采用 skiplist 作为内部编码。

Redis 7.0 中, 废弃了 ziplist 和 skiplist, 改为 listpack 数据结构
```



#### skiplist (跳跃表)

<img src=".\image\skiplist.jpg" alt="skiplist" style="zoom:80%;" />

```
skiplist: 跳跃表, 是一种有序的数据结构, 它通过每一个节点维持多个指向其它节点的指针, 从而达到快速访问的目的。

skiplist由如下几个特点：
有很多层组成, 由上到下节点数逐渐密集, 最上层的节点最稀疏, 跨度也最大。
每一层都是一个有序链表, 只扫包含两个节点, 头节点和尾节点。
每一层的每一个每一个节点都含有指向同一层下一个节点和下一层同一个位置节点的指针。如果一个节点在某一层出现, 那么该以下的所有链表同一个位置都会出现该节点。


在跳跃表的结构中有head和tail表示指向头节点和尾节点的指针, 能后快速的实现定位。level表示层数, len表示跳跃表的长度, BW表示后退指针, 在从尾向前遍历的时候使用。

BW下面还有两个值分别表示分值（score）和成员对象（各个节点保存的成员对象）。

跳跃表的实现中, 除了最底层的一层保存的是原始链表的完整数据, 上层的节点数会越来越少, 并且跨度会越来越大。

跳跃表的上面层就相当于索引层, 都是为了找到最后的数据而服务的, 数据量越大, 条表所体现的查询的效率就越高, 和平衡树的查询效率相差无几。
```

#### listpack

#### 应用

##### 排行榜

```


有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。

我们以博文点赞排名为例, 小林发表了五篇博文, 分别获得赞为 200、40、100、50、150。

# arcticle:1 文章获得了200个赞
> ZADD user:xiaolin:ranking 200 arcticle:1
(integer) 1
# arcticle:2 文章获得了40个赞
> ZADD user:xiaolin:ranking 40 arcticle:2
(integer) 1
# arcticle:3 文章获得了100个赞
> ZADD user:xiaolin:ranking 100 arcticle:3
(integer) 1
# arcticle:4 文章获得了50个赞
> ZADD user:xiaolin:ranking 50 arcticle:4
(integer) 1
# arcticle:5 文章获得了150个赞
> ZADD user:xiaolin:ranking 150 arcticle:5
(integer) 1

文章 arcticle:4 新增一个赞, 可以使用 ZINCRBY 命令（为有序集合key中元素member的分值加上increment）：

> ZINCRBY user:xiaolin:ranking 1 arcticle:4
"51"

查看某篇文章的赞数, 可以使用 ZSCORE 命令（返回有序集合key中元素个数）：

> ZSCORE user:xiaolin:ranking arcticle:4
"50"

获取小林文章赞数最多的 3 篇文章, 可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）：

# WITHSCORES 表示把 score 也显示出来
> ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES
1) "arcticle:1"
2) "200"
3) "arcticle:5"
4) "150"
5) "arcticle:3"
6) "100"

获取小林 100 赞到 200 赞的文章, 可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员, 分数由低到高排序）：

> ZRANGEBYSCORE user:xiaolin:ranking 100 200 WITHSCORES
1) "arcticle:3"
2) "100"
3) "arcticle:5"
4) "150"
5) "arcticle:1"
6) "200"

```

##### 电话、姓名排序

```
电话、姓名排序

使用有序集合的 ZRANGEBYLEX 或 ZREVRANGEBYLEX 可以帮助我们实现电话号码或姓名的排序, 我们以 ZRANGEBYLEX （返回指定成员区间内的成员, 按 key 正序排列, 分数必须相同）为例。

注意：不要在分数不一致的 SortSet 集合中去使用 ZRANGEBYLEX和 ZREVRANGEBYLEX 指令, 因为获取的结果会不准确。

1、电话排序

我们可以将电话号码存储到 SortSet 中, 然后根据需要来获取号段：

> ZADD phone 0 13100111100 0 13110114300 0 13132110901 
(integer) 3
> ZADD phone 0 13200111100 0 13210414300 0 13252110901 
(integer) 3
> ZADD phone 0 13300111100 0 13310414300 0 13352110901 
(integer) 3

获取所有号码:

> ZRANGEBYLEX phone - +
1) "13100111100"
2) "13110114300"
3) "13132110901"
4) "13200111100"
5) "13210414300"
6) "13252110901"
7) "13300111100"
8) "13310414300"
9) "13352110901"

获取 132 号段的号码：

> ZRANGEBYLEX phone [132 (133
1) "13200111100"
2) "13210414300"
3) "13252110901"

获取132、133号段的号码：

> ZRANGEBYLEX phone [132 (134
1) "13200111100"
2) "13210414300"
3) "13252110901"
4) "13300111100"
5) "13310414300"
6) "13352110901"

2、姓名排序

> zadd names 0 Toumas 0 Jake 0 Bluetuo 0 Gaodeng 0 Aimini 0 Aidehua 
(integer) 6

获取所有人的名字:

> ZRANGEBYLEX names - +
1) "Aidehua"
2) "Aimini"
3) "Bluetuo"
4) "Gaodeng"
5) "Jake"
6) "Toumas"

获取名字中大写字母A开头的所有人：

> ZRANGEBYLEX names [A (B
1) "Aidehua"
2) "Aimini"

获取名字中大写字母 C 到 Z 的所有人：

> ZRANGEBYLEX names [C [Z
1) "Gaodeng"
2) "Jake"
3) "Toumas"

```

#### 命令

```
zadd k s1 v1 s2 v2      将分数s1 s2和元素添加到集合
zrem k v1 v2            移除元素, 并获取成功的数量            
zcard k                 获取元素数量
zincrby k count v       v的分数增加count
zcount k s1 s2          获取分数s1和s2之间元素数量
zrank k v               获取元素的排名
zscore k v              获取元素的分值
zrange k start stop [withscores]    返回排名start和stop之间的成员, 如果有withscores则一起返回分数


ZADD key score member [[score member]...]   	往有序集合key中加入带分值元素
ZREM key member [member...] 					往有序集合key中删除元素                
ZSCORE key member								返回有序集合key中元素member的分值
ZCARD key 										返回有序集合key中元素个数
ZINCRBY key increment member 					为有序集合key中元素member的分值加上increment
ZRANGE key start stop [WITHSCORES]				正序获取有序集合key从start下标到stop下标的元素
ZREVRANGE key start stop [WITHSCORES]			倒序获取有序集合key从start下标到stop下标的元素
ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]		返回有序集合中指定分数区间内的成员, 分数由低到高排序。
ZRANGEBYLEX key min max [LIMIT offset count]	返回指定成员区间内的成员, 按字典正序排列, 分数必须相同。
ZREVRANGEBYLEX key max min [LIMIT offset count]	返回指定成员区间内的成员, 按字典倒序排列, 分数必须相同
ZUNIONSTORE destkey numberkeys key [key...] 	并集计算(相同元素分值相加), numberkeys一共多少个key, WEIGHTS每个key对应的分值乘积
ZINTERSTORE destkey numberkeys key [key...]		交集计算(相同元素分值相加), numberkeys一共多少个key, WEIGHTS每个key对应的分值乘积
```



## HyperLogLogs (基数统计)

> 2.8.9 版新增

```
基数统计（hyperloglog）: 基于概率的数据结构
是用来做基数统计的算法, 所谓基数, 也就是不重复的元素
Redis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型, 是一种用于「统计基数」的数据集合类型, 基数统计就是指统计一个集合中不重复的元素个数。但要注意, HyperLogLog 是统计规则是基于概率完成的, 不是非常准确, 标准误算率是 0.81%。
所以, 简单来说 HyperLogLog 提供不精确的去重计数。
HyperLogLog 的优点是, 在输入元素的数量或者体积非常非常大时, 计算基数所需的内存空间总是固定的、并且是很小的。
在 Redis 里面, 每个 HyperLogLog 键只需要花费 12 KB 内存, 就可以计算接近 2^64 个不同元素的基数, 和元素越多就越耗费内存的 Set 和 Hash 类型相比, HyperLogLog 就非常节省空间。
这什么概念？举个例子给大家对比一下。
用 Java 语言来说, 一般 long 类型占用 8 字节, 而 1 字节有 8 位, 即：1 byte = 8 bit, 即 long 数据类型最大可以表示的数是：2^63-1。对应上面的2^64个数, 假设此时有2^63-1这么多个数, 从 0 ~ 2^63-1, 按照long以及1k = 1024 字节的规则来计算内存总数, 就是：((2^63-1) * 8/1024)K, 这是很庞大的一个数, 存储空间远远超过12K, 而 HyperLogLog 却可以用 12K 就能统计完。
优点：
在输入元素的数量或者体积非常大时, 计算基数所需的空间总是固定的、并且是很小的。在 Redis 里面, 每个 HyperLogLog 键只需要花费 12 KB 内存, 就可以计算接近 2^64 个不同元素的基数。
缺点：
因为 HyperLogLog 只会根据输入元素来计算基数, 而不会储存输入元素本身, 所以 HyperLogLog 不能像集合那样, 返回输入的各个元素。
估算的值, 可能存在误差, 带有 0.81% 标准错误的近似值
```

#### 内部实现

```
HyperLogLog
```

#### HyperLogLog

#### 常见命令

```bash
PFADD key element [element ...]				# 添加指定元素到 HyperLogLog
PFCOUNT key [key ...]						# 返回给定 HyperLogLog 的基数估算值
PFMERGE destkey sourcekey [sourcekey ...]	# 将多个 HyperLogLog 合并为一个 HyperLogLog
```

#### **应用场景**

##### 百万级网页 UV 计数

```
Redis HyperLogLog 优势在于只需要花费 12 KB 内存, 就可以计算接近 2^64 个元素的基数, 和元素越多就越耗费内存的 Set 和 Hash 类型相比, HyperLogLog 就非常节省空间。
所以, 非常适合统计百万级以上的网页 UV 的场景。
在统计 UV 时, 你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。
PFADD page1:uv user1 user2 user3 user4 user5
接下来, 就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了, 这个命令的作用就是返回 HyperLogLog 的统计结果。
PFCOUNT page1:uv
不过, 有一点需要你注意一下, HyperLogLog 的统计规则是基于概率完成的, 所以它给出的统计结果是有一定误差的, 标准误算率是 0.81%。
这也就意味着, 你使用 HyperLogLog 统计的 UV 是 100 万, 但实际的 UV 可能是 101 万。虽然误差率不算大, 但是, 如果你需要精确统计结果的话, 最好还是继续用 Set 或 Hash 类型。
```

## Geospatial (地理位置)

> 3.2 版新增

```
地理位置（Geo）: 地理位置信息储存起来,  并对这些信息进行操作 3.2新增

Redis GEO 是 Redis 3.2 版本新增的数据类型, 主要用于存储地理位置信息, 并对存储的信息进行操作。

在日常生活中, 我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车, 这些都离不开基于位置信息服务（Location-Based Service, LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息, 而且要能查询相邻的经纬度范围, GEO 就非常适合应用在 LBS 服务的场景中。
```



#### 内部实现

```
1. Geo 本身不是一种数据结构, 使用 zset 类型实现


使用 GeoHash 编码方法将经纬度装换为 zset




Redis 中将经纬度使用 52 位的整数进行编码, 放进zset中, score 就是 GeoHash 的 52 位整数值
Geo 查询时, 其内部对应的操作其实就是 zset(skiplist)的操作
通过 zset 的 score 进行排序就可以得到坐标附近的其它元素, 通过将score还原成坐标值就可以得到元素的原始坐标。

这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后, 就用区间的编码值来表示, 并把编码值作为 Sorted Set 元素的权重分数。



Redis 中处理这些地理位置坐标点的思想是：
二维平面坐标点 --> 一维整数编码值 --> zset(score为编码值) --> zrangebyrank(获取score相近的元素)、zrangebyscore --> 通过score(整数编码值)反解坐标点 --> 附近点的地理位置坐标
```

#### 常用命令

```bash
# 存储指定的地理空间位置, 可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。
GEOADD key longitude latitude member [longitude latitude member ...]

# 从给定的 key 里返回所有指定名称(member)的位置（经度和纬度）, 不存在的返回 nil。
GEOPOS key member [member ...]

# 返回两个给定位置之间的距离。
GEODIST key member1 member2 [m|km|ft|mi]

# 根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]
```

#### 应用场景

##### 滴滴叫车

```
这里以滴滴叫车的场景为例, 介绍下具体如何使用 GEO 命令：GEOADD 和 GEORADIUS 这两个命令。
假设车辆 ID 是 33, 经纬度位置是（116.034579, 39.030452）, 我们可以用一个 GEO 集合保存所有车辆的经纬度, 集合 key 是 cars:locations。
执行下面的这个命令, 就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：
GEOADD cars:locations 116.034579 39.030452 33
当用户想要寻找自己附近的网约车时, LBS 应用就可以使用 GEORADIUS 命令。
例如, LBS 应用执行下面的命令时, Redis 会根据输入的用户的经纬度信息（116.054579, 39.030452 ）, 查找以这个经纬度为中心的 5 公里内的车辆信息, 并返回给 LBS 应用。
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10
```

## bitmap (位图)

> 2.2 版新增

<img src=".\image\bitmap.png" alt="bitmap" style="zoom:40%;" />

```
更细化的一种操作, 以bit为单位
2. bitmap 类型适合二值状态统计的场景 (只有 0 和 1 两种), 在记录海量数据时, bitmap 能够有效地节省内存空间

bitmap: 即位图, 是一串连续的二进制数组 (0 和 1), 通过 offset (偏移量) 定位元素
bitmap通过最小的单位bit来进行0|1的设置, 表示某s个元素的值或者状态, 时间复杂度为O(1)。
由于 bit 是计算机中最小的单位, 使用它进行储存将非常节省空间, 特别适合一些数据量大且使用二值统计的场景。

bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。
String 类型是会保存为二进制的字节数组, 所以, Redis 就把字节数组的每个 bit 位利用起来, 用来表示一个元素的二值状态, 你可以把 bitmap 看作是一个 bit 数组。




bitmap: 是一种实现对位的操作的’数据结构’, 在数据结构加引号主要因为：bitmap本身不是一种数据结构, 底层实际上是字符串, 可以借助字符串进行位操作。


可以把 bitmaps 想象成一个以位为单位的数组, 数组的每个单元只能存储 0 和 1, 数组的下标在 bitmap 中叫做偏移量 offset。
bitmap的出现是为了大数据量而来的, 但是前提是统计的这个大数据量每个的状态只能有两种, 因为每一个bit位只能表示两种状态。
```

#### 底层实现

```
bitmap 不是一种数据结构, 底层使用字符串存储, 只不过操作的粒度变成了 bit (位), 因此只有 0 和 1 两个值
bitmap 的偏移量 offset 最大值是 (8 * 1024 * 1024 * 512 = 2^32). 由于 C 语言字符串末尾要存储一位分隔符, 所以实际上 bitmap 的偏移量 offset 值上限是 2^32-1
```

#### 常用命令

```bash
SETBIT key offset value			# 设置值, 其中value只能是 0 和 1
GETBIT key offset				# 获取值
BITCOUNT key start end			# 获取指定范围内值为 1 的个数 (start 和 end 以字节为单位)

# bitmap间的运算
# operations 位移操作符, 枚举值
  AND 与运算 &
  OR 或运算 |
  XOR 异或 ^
  NOT 取反 ~
# result 计算的结果, 会存储在该key中
# key1 … keyn 参与运算的key, 可以有多个, 空格分割, not运算只能一个key
# 当 BITOP 处理不同长度的字符串时, 较短的那个字符串所缺少的部分会被看作 0。返回值是保存到 destkey 的字符串的长度（以字节byte为单位）, 和输入 key 中最长的字符串长度相等。
BITOP [operations] [result] [key1] [keyn…]
BITPOS [key] [value]			# 返回指定key中第一次出现指定value(0/1)的位置
```

#### 应用

##### 签到统计

```bash
在签到打卡的场景中, 只记录签到（1）和未签到（0）
签到统计时, 每个用户一天的签到用 1 个 bit 位就能表示, 一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以, 而一年的签到也只需要用 365 个 bit 位, 根本不用太复杂的集合类型

如统计 ID 100 的用户在 2022 年 6 月份的签到情况:
# 1. 记录该用户 6 月 3 号已签到
SETBIT uid:sign:100:202206 2 1
# 2. 检查该用户 6 月 3 日是否签到
GETBIT uid:sign:100:202206 2 
# 3. 统计该用户在 6 月份的签到次数
BITCOUNT uid:sign:100:202206

如何统计这个月首次打卡时间呢？
Redis 提供了 BITPOS key bitValue [start] [end]指令, 返回数据表示 bitmap 中第一个值为 bitValue 的 offset 位置
在默认情况下,  命令将检测整个位图,  用户可以通过可选的 start 参数和 end 参数指定要检测的范围。所以我们可以通过执行这条命令来获取 userID = 100 在 2022 年 6 月份首次打卡日期：
BITPOS uid:sign:100:202206 1
需要注意的是, 因为 offset 从 0 开始的, 所以我们需要将返回的 value + 1
```

##### 判断用户登陆态

```bash
bitmap 提供了 GETBIT、SETBIT 操作, 通过一个偏移值 offset 对 bit 数组的 offset 位置的 bit 位进行读写操作, offset 从 0 开始
只需要一个 key = login_status 表示存储用户登陆状态集合数据,  将用户 ID 作为 offset, 在线就设置为 1, 下线设置 0。通过 GETBIT判断对应的用户是否在线。 50000 万 用户只需要 6 MB 的空间。
假如我们要判断 ID = 10086 的用户的登陆情况：
1. 执行以下指令, 表示用户已登录。
SETBIT login_status 10086 1
2. 检查该用户是否登陆, 返回值 1 表示已登录。
GETBIT login_status 10086
3. 登出, 将 offset 对应的 value 设置成 0。
SETBIT login_status 10086 0
```

##### 连续签到用户总数

```bash
统计连续 7 天连续打卡用户总数
我们把每天的日期作为 bitmap 的 key, userId 作为 offset, 若是打卡则将 offset 位置的 bit 设置成 1。
key 对应的集合的每个 bit 位的数据则是一个用户在该日期的打卡记录。
一共有 7 个这样的 bitmap, 如果我们能对这 7 个 bitmap 的对应的 bit 位做 『与』运算。同样的 UserID offset 都是一样的, 当一个 userID 在 7 个 bitmap 对应对应的 offset 位置的 bit = 1 就说明该用户 7 天连续打卡。
结果保存到一个新 bitmap 中, 我们再通过 BITCOUNT 统计 bit = 1 的个数便得到了连续打卡 3 天的用户总数了。
Redis 提供了 BITOP operation destkey key [key ...]这个指令用于对一个或者多个 key 的 bitmap 进行位元操作。
    opration 可以是 and、OR、NOT、XOR。当 BITOP 处理不同长度的字符串时, 较短的那个字符串所缺少的部分会被看作 0 。空的 key 也被看作是包含 0 的字符串序列。
举个例子, 比如将三个 bitmap 进行 AND 操作, 并将结果保存到 destmap 中, 接着对 destmap 执行 BITCOUNT 统计。
# 与操作
BITOP AND destmap bitmap:01 bitmap:02 bitmap:03
# 统计 bit 位 =  1 的个数
BITCOUNT destmap
即使一天产生一个亿的数据, bitmap 占用的内存也不大, 大约占 12 MB 的内存（10^8/8/1024/1024）, 7 天的 bitmap 的内存开销约为 84 MB。同时我们最好给 bitmap 设置过期时间, 让 Redis 删除过期的打卡数据, 节省内存。
```

## Stream (流)

> 5.0 版本新增

```
1. 为消息队列新增加的数据类型, 用于消息队列.
2. 每个写操作都会写入到 RDB 和 AOF 中
3. 消费者处理完消息后, 需要执行 XACK 命令, Redis 把这条消息标记为 '处理完成', XPENDING 命令查看已读取/但尚未确认处理完成的消息
4. 发布消息时可以指定队列的最大长度, 当队列长度超过上限后, 旧消息被删除
```

#### 底层实现

1. 消息链表

<img src=".\image\Stream.png" alt="Stream" style="zoom:100%;" />

```
每个 Stream 都有唯一的名称，它就是 Redis 的 key，在我们首次使用 xadd 指令追加消息时自动创建。
每个 Stream 中有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容


Consumer Group: 消费组
last_delivered_i: 游标，每个消费组会有个游标，任意一个消费者读取了消息都会使游标 last_delivered_id 往前移动
pending_ids: 消费者的状态变量，作用是维护消费者的未确认的 id。 pending_ids 记录了当前已经被客户端读取的消息，但是还没有 ack (Acknowledge character：确认字符）
```

2. 内部编码

   <img src=".\image\Stream2.png" alt="Stream2" style="zoom:80%;" />

   ```
   stream底层的数据结构是radix tree：Radix Tree(基数树) 事实上就是几乎相同是传统的二叉树。仅仅是在寻找方式上，以一个unsigned int类型数为例，利用这个数的每个比特位作为树节点的推断。能够这样说，比方一个数10001010101010110101010，那么依照Radix 树的插入就是在根节点，假设遇到0，就指向左节点，假设遇到1就指向右节点，在插入过程中构造树节点，在删除过程中删除树节点。
   ```

3. 构成

   ![Stream3](.\image\Stream3.png)

   ```
   stream 总共由 3 部分构成：
   1. robj， 每个 redis 对象实例都会有一个最基本的结构来存储它实际的类型, 编码和对应的结构的位置
   2. rax, 用作存储 stream ID
   3. listpack，rax 下的每一个 key 节点都会把对应的 keys 和 values 的值存在这个 listpack 结构中
   ```

#### 消息队列

##### 发布消息

```bash
# * 表示让 Redis 为插入的数据自动生成一个全局唯一的 ID
# 消息 id 的格式是 '时间戳-自增序号'
# 插入成功后会返回全局唯一的 id "1654254953808-0", 表示在 1654254953808 毫秒内的第 1 条消息
    1654254953808 是数据插入时当前服务器时间
    0 是当前毫秒内的消息序号

> XADD mymq * name xiaolin
"1654254953808-0"
```

##### 读取消息

```bash
# XREAD 从消息队列中读取消息, 可以指定一个消息 ID, 会从这个它的下一条消息开始进行读取
> XREAD STREAMS mymq 1654254953807-0
1) 1) "mymq"
   2) 1) 1) "1654254953808-0"
         2) 1) "name"
            2) "xiaolin"
            

# 从开头读取 5 条消息
# 0-0 表示从开头读取
127.0.0.1:6379> XREAD COUNT 5 STREAMS queue 0-0
1) 1) "queue"
   2) 1) 1) "1618469123380-0"
         2) 1) "name"
            2) "zhangsan"
      2) 1) "1618469127777-0"
         2) 1) "name"
            2) "lisi"
 

> XREAD COUNT 5 STREAMS queue 1618469127777-0
(nil)
```

##### 阻塞读

```bash
# BLOCK 10000 表示阻塞 10000 毫秒,
# $ 表示读取最新的消息
> XREAD BLOCK 10000 STREAMS mymq $
(nil)
(10.00s)


# BLOCK 0 表示阻塞等待, 不设置超时时间
> XREAD COUNT 5 BLOCK 0 STREAMS queue 1618469127777-0
```

##### Stream 发布订阅

<img src=".\image\消息队列6.jpg" alt="消息队列6" style="zoom:100%;" />

生产者发布 2 条消息

```
127.0.0.1:6379> XADD queue * name zhangsan
"1618470740565-0"
127.0.0.1:6379> XADD queue * name lisi
"1618470743793-0"
```

创建 2 个消费者组

```bash
# 创建消费者组 group1 和 group1, 0-0表示从头拉取消息
> XGROUP CREATE queue group1 0-0
OK
> XGROUP CREATE queue group2 0-0
OK
```

group1 消费

```c
# > 表示拉取最新数据
127.0.0.1:6379> XREADGROUP GROUP group1 consumer COUNT 5 STREAMS queue >
1) 1) "queue"
   2) 1) 1) "1618470740565-0"
         2) 1) "name"
            2) "zhangsan"
      2) 1) "1618470743793-0"
         2) 1) "name"
            2) "lisi"
```

group2 消费

```c
127.0.0.1:6379> XREADGROUP GROUP group2 consumer COUNT 5 STREAMS queue >
1) 1) "queue"
   2) 1) 1) "1618470740565-0"
         2) 1) "name"
            2) "zhangsan"
      2) 1) "1618470743793-0"
         2) 1) "name"
            2) "lisi"
```

##### 消息堆积

```c
# 发布消息时可以指定队列的最大长度, 当队列长度超过上限后, 旧消息被删除
# 队列长度最大10000
127.0.0.1:6379> XADD queue MAXLEN 10000 * name zhangsan
"1618473015018-0"
```

#### 命令

```
XADD：插入消息, 保证有序, 可以自动生成全局唯一 ID；
XLEN ：查询消息长度；
XREAD：用于读取消息, 可以按 ID 读取数据；
XDEL ： 根据消息 ID 删除消息；
DEL ：删除整个 Stream；
XRANGE ：读取区间消息XREADGROUP：按消费组形式读取消息；
XPENDING 和 XACK：
        XPENDING 命令可以用来查询每个消费组内所有消费者「已读取、但尚未确认」的消息
        XACK 命令用于向消息队列确认消息处理已完成；
        
        
消息保序：XADD/XREAD
阻塞读取：XREAD block
重复消息处理：Stream 在使用 XADD 命令, 会自动生成全局唯一 ID；
消息可靠性：内部使用 PENDING List 自动保存消息, 使用 XPENDING 命令查看消费组已经读取但是未被确认的消息, 消费者使用 XACK 确认消息；支持消费组形式消费数据
```







# expire persist

<img src=".\image\redis过期时间.png" alt="redis过期时间" style="zoom:80%;" />

# x.02 内存管理

```
设置最大内存, 避免redis内存使用过多对其他程序造成影响

redis.conf 文件, redis.conf 文件默认的最大内存 maxmemory=0 表示不限制redis内存的使用
```

### 删除策略

> 只能删除过期数据
>
> redis 同时使用了惰性删除与定期删除

##### 1. 定时删除

- 含义: 在设置 key 的过期时间的同时, 为该key创建一个定时器, 让定时器在 key 的过期时间来临时对 key 进行删除

- 优点: 保证内存被尽快释放

- 缺点:

  - 若过期 key很多, 删除这些key会占用很多的CPU时间, 在CPU时间紧张的情况下, CPU不能把所有的时间用来做要紧的事儿, 还需要去花时间删除这些key
  - 定时器的创建耗时,若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生）, 性能影响严重


##### 2. 惰性删除

- 含义: key 过期的时候不删除, 每次通过key获取值的时候去检查是否过期, 若过期则删除并返回不存在
- 优点: 节约CPU性能, 发现不得不删除的时候才删除
- 缺点: 内存空间压力大

##### 3. 定期删除

- 每隔一段时间, 我们就对一些key进行检查, 删除里面过期的key。
- 优点
  - 可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响, 解决"定时删除"对 cpu 影响的问题
  - 释放过期键占用的内存, 解决"惰性删除"对内存占用的问题.
- 缺点
  - 难以确定删除操作执行的时长（每次删除执行多长时间）和频率（每隔多长时间做一次删除)。如果执行的太频繁, 定期删除策略变得和定时删除策略一样, 对CPU不友好。如果执行的太少, 那又和惰性删除一样了, 过期键占用的内存不会及时得到释放。
  - 在获取某个键时, 如果某个键的过期时间已经到了, 但是还没执行定期删除, 那么就会返回这个键的值

### 淘汰策略

> 新数据写入时, redis 使用的内存达到上限时
>
> 设置 redis 使用内存的上限

> https://blog.csdn.net/qq_37325859/article/details/125331084

- 每次存储数据前调用 freeMemoryIfNeeded() 检测内存是否充足。如果内存不满足新加入数据的最低存储要求, redis要临时删除一些数据为当前指令清理存储空间. 有时需要反复执行才能才是释放足够的空间. 当对所有数据尝试完毕后, 如果不能达到内存清理的要求, 将出现错误 "OOM command not allowed when used memory>'maxmemory'"

##### 参数

```
maxmemory: redis可使用内存占物理内存的最大比例, 默认为0, 表示不限制redis使用内存。生产环境中根据需求设定, 通常设置在50%以上
maxmemory-samples: 每次选取待删除数据的个数, 选取数据时并不会全库扫描, 导致严重的性能消耗, 降低读写性能。因此采用随机获取数据的方式作为待检测删除数据
maxmemory-policy: 达到最大内存后的, 对被挑选出来的数据进行删除的算法
```

##### 淘汰算法

```
volatile-lru, 针对设置了过期时间的key, 使用lru算法进行淘汰
volatile-lfu, 针对设置了过期时间的key, 使用lfu算法进行淘汰。
volatile-random, 从所有设置了过期时间的key中使用随机淘汰的方式进行淘汰。
volatile-ttl, 针对设置了过期时间的key, 越早过期的越先被淘汰。
allkeys-lru, 针对所有key使用lru算法进行淘汰。
allkeys-lfu, 针对所有key使用lfu算法进行淘汰。
allkeys-random, 针对所有的key使用随机淘汰机制进行淘汰。
noeviction, 不会淘汰任何数据, 当使用的内存空间超过 maxmemory 值时, 再有写请求来时会引发错误OOM（Out Of Memory）
```

##### LRU

```
Least Recently Used 最近很少使用




问题:
一个很久没有被访问的key, 偶尔被访问一次, 导致被误认为是热点数据的问题
```

##### redis LRU

- 3.0 版本以前

  ```
  随机采集淘汰的key, 每次随机选出5个key, 然后淘汰这5个key中最少使用的key
  数量可设置, 值越大越准确, 道消耗资源增加
  ```

- 3.0 版本以后

- > 空闲时长: 多久没有用了. 优先淘汰空闲时长大的

  ```
  1. 维护一个池子存放随机选取的 key, 并根据空闲时长排序
  2. 大于池内最小空闲时长的才能追加入池子
  3. 池子满了以后, 将空闲时长最长的移出池子并淘汰.
  ```

##### LFU

> 4.0 版本加入

```
根据key最近被访问的频率进行淘汰, 比较少访问的key优先淘汰, 反之则保留。
LFU的原理是使用计数器来对key进行排序, 每次key被访问时, 计数器会增大, 当计数器越大, 意味着当前key的访问越频繁, 也就是意味着它是热点数据
```

##### 最大限制

```
string 最大 512M

List、Set、Sorted Set 可以放 2 的 32 次方个元素(受内存影响)
```



# x.03 持久化



> 持久化: 把内存的数据写入磁盘, 防止服务宕机内存数据丢失. 持久化所得的文件最好备份到不同的服务器

### rdb 快照

##### 快照频率

```
save N M
	在 N 秒内至少 M 个改动才触发一次 rdb
	
save 200 20
	200 秒内至少 20 个改动
```

##### 手动执行快照

```
save
或
gbsave
```



```
redis 默认使用快照方式, 默认文件名 dump.rdb 的二进制文件, 每次执行覆盖之前的内容.


创建子进程进行快照
系统发生崩溃丢失快照后更改的所有数据. 适用于丢失一部份数据也不会造成问题的应用程序

例子
  - 如果内存有10GB数据, 上一个快照2:31开始创建并成功, 3:12开始创建快照, 创建之前有51个键进行更新
  - 如果创建成功之前系统崩溃, 则丢失2:31之后的所有数据
  - 如果创建成功以后系统崩溃, 则丢失51的更新

配置文件
save 60 1000
stop-writes-on-bgsave-error no
rdbcompression yes
dbfilename dump.rdb
```

### AOF

- 将被执行的写命令写到AOF文件末尾, 以此来记录发生的变化. 

- 缺陷
  - redis不断运行, AOF文件不断增长, 在极端情况下, 体积不断增大的AOF文件甚至可能会用完硬盘的所有可用空间
  - 重新执行AOF文件记录的所有写命令来还原数据集, 如果AOF文件的体积非常大, 还原操作执行的时间就可能会非常长

##### 同步频率 appendfsync

- always: 每个写命令都同步写入硬盘, 严重降低 redis 速度, 用户几乎可以不损失任何数据每次只写入一条命令, 其他选项一次写入多条命令这种同步频率下, 机械硬盘每秒大约处理200个命令, 固态硬盘几万个命令
- everysec: 每秒执行一次同步. 兼顾数据安全和写入性能, 每秒同步一次AOF文件时的性能和不使用任何持久化特性时的性能相差无几
  系统崩溃用户也最多只会丢失一秒之内产生的数据。当硬盘忙于执行写人操作的时候, redis还会优雅地放慢自己的速度以便适应硬盘的最大写人速度。
- no: 由操作系统来决定应该在何时对AOF文件进行同步.  一般情况下不会对redis的性能带来影响, 但系统崩溃将导致使用这种选项的redis服务器丢失不定数量的数据. 如果用户的硬盘处理写入操作的速度不够快的话,那么当缓冲区被等待写入硬盘的数据填满时, redis 的写操作将被阻塞, 并导致redis处理命令请求的速度变慢

##### bgrewriteaof

```
为了解决AOF文件体积不断增大的问题, 用户可以向redis发送BGREWRITEAOF命令, 这个命令会通过移除AOF文件中的冗余命令来重写AOF文件, 使AOF文件的体积变得尽可能地小。


1. redis创建一个子进程重写AOF文件, 会导致的性能问题和内存占用问题
2. AOF文件的体积可能会比快照文件的体积大好几倍, 在进行AOF重写并删除旧AOF文件的时候, 删除一个体积达到数十GB大的旧AOF文件可能会导致操作系统挂起数秒
```

##### 配置文件

```
appendonly no
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb  
# 当AOF文件体积大于64MB, 且AOF文件的体积比上一次重写之后的体积大了至少100%时候, redis将执行BGREWRITEAOF命令
```

# x.04 集群

##### redis集群实现方式

- 主从复制

```
读写分离
假如 master宕机了, redis 没有实现自动进行主备切换



主从链
  - 从服务器也可以有从服务器
  - 从服务器对从服务器复制和从服务器对主服务器复制唯一区别在于, 如果从服务器X拥有从服务器Y, 那么当从服务器X在执行表步骤4时, 它将断开与从服务器Y的连接, 导致从服务器Y需要重新连接并重新同步
```

- Sentinel 哨兵机制

```
支持集群模式
着眼于高可用, 在 master 宕机时会自动将 slave 提升为master, 继续提供服务。
```

- cluster

```
负载均衡
解决单机redis容量有限的问题, 将数据按一定的规则分配到多台机器。

redis扩容方式
1. 垂直扩容表示通过加内存方式来增加整个缓存体系的容量比如将缓存大小由2G调整到4G,这种扩容不需要应用程序支持；
2. 水平扩容表示表示通过增加节点的方式来增加整个缓存体系的容量比如本来有1个节点变成2个节点, 这种扩容方式需要应用程序支持



分布式集群首要解决把整个数据集按照分区规则映射到多个节点的问题, 即把数据集划分到多个节点上, 每个节点负责整个数据的一个子集。redis Cluster采用哈希分区规则中的虚拟槽分区。
```

##### 复制

```
如果主从服务器之间的网络带宽不足, 或者主服务器没有足够的内存来创建子进程和创建记录写命令的缓冲区, 那么redis 处理命令请求的效率就会受到影响

最好还是让主服务器只使用50%~ 65%的内存, 留下30%~ 45%的内存用于执行BGSAVE命令和创建记录写命令的缓冲区。
从服务器在与主服务器进行初始连接时, 数据库中原有的所有数据都将丢失, 并被替换成主服务器发来的数据。
同时使用复制和AOF持久化将数据持久化到多台机器上面
```

| 步骤 | 主服务器操作                                                 | 从服务器操作                                                 |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | (等待命令进入)                                               | 连接主服务器, 发送SYNC命令                                   |
| 2    | 开始执行bgsave, 并使用缓冲区记录bgsave之后执行的所有命令     | 根据配置选项决定是否继续使用现有的数据处理客户端的命令请求, 还是想发送请求的客户端返回错误 |
| 3    | bgsave执行完毕向从服务器发送快照文件, 期间继续使用缓冲区记录被执行的写命令 | 丢弃所有旧数据, 载入主服务器发来的快照文件                   |
| 4    | 快照文件发送完毕, 开始向从服务器发送存储的缓冲区里的写命令                          完成快照文件解释操作, 并开始接收命令请求 | 完成快照文件解释操作, 并开始接收命令请求                     |
| 5    | 缓冲区存储的写命令发送完毕, 从现在开始每执行一个写命令就向从服务器发送相同的命令 | 执行主服务器发来的所有缓冲区里面的写命令. 从现在开始接收并执行主服务器传来的每个写命令 |

##### 短结构

```
短结构, 分片结构, 打包存储二进制和字节
```



# 连接池

```
通过预先创建多个连接, 当进行redis操作时, 直接获取已经创建的连接进行操作, 而且操作完成后, 不会释放, 用于后续的其他redis操作, 这样就达到了避免频繁的redis连接创建和释放的目的, 从而提高性能。
redis模块采用ConnectionPool来管理对redis server的所有连接


```



# redis分布式锁

##### 分布式锁

- 正确做法

```
使用 set key value [EX seconds][PX milliseconds][NX|XX] 命令 (正确做法)
redis在 2.6.12 版本开始, 为 SET 命令增加一系列选项: 
SET key value[EX seconds][PX milliseconds][NX|XX]
    EX seconds: 设定过期时间, 单位为秒
    PX milliseconds: 设定过期时间, 单位为毫秒
    NX: 仅当key不存在时设置值(就等同于setnx命令)
    XX: 仅当key存在时设置值
    
    
# 当 test 不存在时, 创建并设置过期时间  
SET test 123 NX PX 10000
# 当 test 存在时, 创建并设置过期时间  
SET test 123 XX PX 10000
```

- 1. 使用redis setnx+expire命令 (错误的做法)

```
加锁命令: SETNX key value, 当键不存在时, 对键进行设置操作并返回成功, 否则返回失败。KEY 是锁的唯一标识, 一般按业务来决定命名。
解锁命令: DEL key, 通过删除键值对释放锁, 以便其他线程可以通过 SETNX 命令来获取锁。
锁超时: EXPIRE key timeout, 设置 key 的超时时间, 以保证即使锁没有被显式释放, 锁也可以在一定时间后自动释放, 避免资源被永远锁住。
SETNX 和 EXPIRE 非原子性
如果 SETNX 成功, 在设置锁超时时间后, 服务器挂掉、重启或网络问题等, 导致 EXPIRE 命令没有执行, 锁没有设置超时时间变成死锁。
```

- 2. 锁误解除

```
如果线程 A 成功获取到了锁, 并且设置了过期时间 30 秒, 但线程 A 执行时间超过了 30 秒, 锁过期自动释放, 此时线程 B 获取到了锁；随后 A 执行完成, 线程 A 使用 DEL 命令来释放锁, 但此时线程 B 加的锁还没有执行完成, 线程 A 实际释放的线程 B 加的锁。

通过在 value 中设置当前线程加锁的标识, 在删除之前验证 key 对应的 value 判断锁是否是当前线程持有。可生成一个 UUID 标识当前线程, 使用 lua 脚本做验证标识和解锁操作。
```

- 3. 超时解锁导致并发

```
如果线程 A 成功获取锁并设置过期时间 30 秒, 但线程 A 执行时间超过了 30 秒, 锁过期自动释放, 此时线程 B 获取到了锁, 线程 A 和线程 B 并发执行。

将过期时间设置足够长, 确保代码逻辑在锁释放之前能够执行完成。
为获取锁的线程增加守护线程, 为将要过期但未释放的锁增加有效时间。
```

- 4. 不可重入

```
当线程在持有锁的情况下再次请求加锁, 如果一个锁支持一个线程多次加锁, 那么这个锁就是可重入的。如果一个不可重入锁被再次加锁, 由于该锁已经被持有, 再次加锁会失败。redis 可通过对锁进行重入计数, 加锁时加 1, 解锁时减 1, 当计数归 0 时释放锁。

另一种方式是 redis Map 数据结构来实现分布式锁, 既存锁的标识也对重入次数进行计数
```

- 5. 无法等待锁释放

```

```



```
https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/







5. 无法等待锁释放
上述命令执行都是立即返回的, 如果客户端可以等待锁释放就无法使用。

可以通过客户端轮询的方式解决该问题, 当未获取到锁时, 等待一段时间重新获取锁, 直到成功获取锁或等待超时。这种方式比较消耗服务器资源, 当并发量比较大时, 会影响服务器的效率。
另一种方式是使用 redis 的发布订阅功能, 当获取锁失败时, 订阅锁释放消息, 获取锁成功后释放时, 发送锁释放消息。如下: 



集群
1. 主备切换
为了保证 redis 的可用性, 一般采用主从方式部署。主从数据同步有异步和同步两种方式, redis 将指令记录在本地内存 buffer 中, 然后异步将 buffer 中的指令同步到从节点, 从节点一边执行同步的指令流来达到和主节点一致的状态, 一边向主节点反馈同步情况。

在包含主从模式的集群部署方式中, 当主节点挂掉时, 从节点会取而代之, 但客户端无明显感知。当客户端 A 成功加锁, 指令还未同步, 此时主节点挂掉, 从节点提升为主节点, 新的主节点没有锁的数据, 当客户端 B 加锁时就会成功。


集群脑裂
集群脑裂指因为网络问题, 导致 redis master 节点跟 slave 节点和 sentinel 集群处于不同的网络分区, 因为 sentinel 集群无法感知到 master 的存在, 所以将 slave 节点提升为 master 节点, 此时存在两个不同的 master 节点。redis Cluster 集群部署方式同理。

当不同的客户端连接不同的 master 节点时, 两个客户端可以同时拥有同一把锁。



https://juejin.cn/post/6844903830442737671
```

# 消息队列

## list 队列

##### 1. LPUSH 和 RPOP

<img src=".\image\消息队列1.jpg" alt="消息队列1" style="zoom:100%;" />



```
1. 使用 LPUSH 和 RPOP, 时间复杂度都是 O(1)
2. 当队列中没有消息时, RPOP 返回 NULL, 得用循环的形式 RPOP 消息. 循环快了增加 redis 压力, 循环慢了导致消息不及时.
```

##### 2. BRPOP / BLPOP

<img src=".\image\消息队列2.jpg" alt="消息队列2" style="zoom:100%;" />

```
redis.brpop("queue", 0)

1. BRPOP 和 BLPOP 阻塞式读取命令, 客户端在没有读到队列数据时, 自动阻塞, 直到有新的数据写入队列, 再开始读取新数据.
2. 可以传入 '超时时间', 超时后返回 NULL. 0 表示不设置超时, 直到有新消息才返回

3. 如果超时太长, 这个连接太久没有活跃过, 可能会被 Redis Server 判定为无效连接, Redis Server 会强制断开这个客户端, 采用这种方案客户端要有重连机制
4. 不支持重复消费: 消费者拉取消息后, 这条消息就从 List 中删除了, 无法被其它消费者再次消费, 即不支持多个消费者消费同一批数据
5. 消息丢失: 消费者拉取到消息后, 如果发生异常宕机, 那这条消息就丢失了
```

## Pub/Sub (发布订阅模型)

##### 发布订阅流程

<img src=".\image\消息队列3.jpg" alt="消息队列3" style="zoom:100%;" />

<img src=".\image\消息队列4.jpg" alt="消息队列4" style="zoom:100%;" />

```
0. 可以有多个生产者和多个消费者
1. 发布订阅消息处理流程:
    a. 消费者订阅指定队列, Redis 会记录队列和消费者映射关系
    b. 生产者向这个队列发布消息, Redis 根据映射关系找出对应的消费者, 把消息转发给它
2. 消费者先订阅, 生产者再发消息, 否则丢消息
3. Pub/Sub 的实现没有基于任何数据类型, 整个过程中没有任何的数据存储, 都是实时转发, 只是单纯地为生产者和消费者建立「数据转发通道」, 把符合规则的数据, 从一端转发到另一端
4. 同一条数据可以被多个订阅者读取. 订阅支持表达式, 一个订阅者可以订阅多个队列
    > SUBSCRIBE queue123
    > PSUBSCRIBE queue*
5. 发布消息
	> PUBLISH queue123 msg1
```

##### 丢数据

```
1. 消费者下线: 如果一个消费者异常挂掉了, 下线期间生产者发布的消息被丢弃掉, 它再重新上线后, 只能接收新的消息
2. Redis 宕机: Pub/Sub 没有基于任何数据类型实现, 数据不会持久化, Pub/Sub 的操作不会写入到 RDB 和 AOF 中, 当 Redis 宕机重启, Pub/Sub 的数据也会全部丢失
```

##### 消息堆积

1. 消费者处理速度比生产者慢

2. list 作为列消息积压时, 消息积压时, 会导致这个链表很长, 内存会持续增长, 直到消费者把所有数据都从链表中取出

3. Pub/Sub 消息积压时会导致消费丢失. 每个消费者订阅一个队列时, Redis 会给这个消费者在分配一个缓冲区. 生产者发布消息时, Redis 先把消息写到对应消费者的缓冲区, 消费者从缓冲区读取消息. 从缓冲区取走数据之后, 数据就从 Redis 缓冲区删除. 缓冲区大小有限制, 如果消息积压 超过了缓冲区配置的上限, Redis 就会强制把这个消费者踢下线, 这时消费者就会消费失败, 也会丢失数据. 

4. 配置参数 client-output-buffer-limit pubsub 32mb 8mb 60

       client-output-buffer-limit pubsub 32mb 8mb 60
           32mb: 缓冲区一旦超过 32MB, Redis 直接强制把消费者踢下线
           8mb + 60: 缓冲区超过 8MB, 并且持续 60 秒, Redis 也会把消费者踢下线

## Stream 队列

##### 消息堆积

```
Redis 的据都存储在内存中, 消息积压会导致 Redis 内存增长, 如果超过机器内存上限, 就会面临被 OOM 的风险
Stream 可以指定队列最大长度, 当指定队列最大长度时, 队列长度超过上限后, 旧消息会被删除, 只保留固定长度的新消息

Kafka, RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上, 当消息积压时, 无非就是多占用一些磁盘空间
因此, 把 Redis 当作队列来使用时, 会面临的 2 个问题：
Redis 本身可能会丢数据；
面对消息挤压, 内存资源会紧张；

所以, 能不能将 Redis 作为消息队列来使用, 关键看你的业务场景：
如果你的业务场景足够简单, 对于数据丢失不敏感, 而且消息积压概率比较小的情况下, 把 Redis 当作队列是完全可以的
如果你的业务有海量消息, 消息积压的概率比较大, 并且不能接受数据丢失, 那么还是用专业的消息队列中间件吧
```

##### 消息丢失

<img src=".\image\Stream消息队列.webp" alt="Stream消息队列" style="zoom:80%;" />

1. 生产者

   ```
   1. 发送消息时网络或其他问题导致发送失败, 需要重试
   2. 不确定是否发布成功, 网络问题导致发布超时, 可能数据已发送成功, 但读取响应结果超时了. 为了避免消息丢失, 只能继续重试, 直到发布成功为止, 消息可能重复. 生产者一般会设定一个最大重试次数, 超过上限依旧失败, 需要记录日志报警处理
   3. 消费者收到重复数据数据时, 要设计幂等逻辑, 保证业务的正确性
   ```

2. 消费者

   ```
   消费者处理完消息后, 需要执行 XACK 命令, Redis 把这条消息标记为 '处理完成'
   ```

3. redis 自身丢数据

   ```
   1. AOF 持久化配置为每秒写盘, 但这个写盘过程是异步的, Redis 宕机时会存在数据丢失的可能
   2. 主从复制也是异步的, 主从切换时, 也存在丢失数据的可能（从库还未同步完成主库发来的数据, 就被提成主库）
   ```

4. 消息堆积

   ```
   1. Redis 数据都存储在内存中, 旦发生消息积压, 则会导致 Redis 的内存持续增长, 如果超过机器内存上限, 就会面临被 OOM 的风险
   2. Stream 可以指定队列最大长度, 超过最大长度后丢弃旧的消息
   ```

##### 与专业消息队列对比

```
1. 如果业务场景足够简单, 对于数据丢失不敏感, 而且消息积压概率比较小的情况下, 把 Redis 当作队列是完全可以的. Redis 相比于 Kafka、RabbitMQ, 部署和运维也更加轻量. Kafka、RabbitMQ 数据都会存储在磁盘上, 磁盘的成本要比内存小得多, 当消息积压时, 无非就是多占用一些磁盘空间, 相比于内存, 在面对积压时也会更加「坦然」。
2. 如果业务场景对于数据丢失非常敏感, 而且写入量非常大, 消息积压时会占用很多的机器资源, 那么我建议你使用专业的消息队列中间件。Redis 在队列中间件环节无法保证消息不丢
```

# 应用问题

```
redis Sentinel 与 redis Cluster
https://blog.csdn.net/angjunqiang/article/details/81190562
```

##### redis的并发竞争问题如何解决?

```
redis为单进程单线程模式, 采用队列模式将并发访问变为串行访问。redis本身没有锁的概念, redis对于多个客户端连接并不存在竞争
```

##### 事务

```

```

##### redis 二级缓存

```

```

##### Redlock

```

```

##### pipline

```
pipeline就是用来将n次的网络时间优化为一次的网络时间, 耗时为1次网络时间 + n次命令时间


redis原生有类似 mget mset的批量操作命令, 这些命令都是原子的, 即会阻塞其他的命令, 知道命令完成返回。而pipeline的每一条命令是拆分过的（非原子）, 假设打包1000个命令的pipeline传到服务端, 则服务端会把pipeline的每个命令当成原子。但无论是pipeline还是M操作 返回的结果都是一样的。



pipeline与M操作都会将数据顺序的传送顺序地返回（redis 单线程）

1.每次pipeline携带数量不推荐过大, 否则会影响网络性能;
2.pipelinepipeline每次只能作用在一个redis节点上;
```

##### 原生M操作

```

```



##### 缓存数据库的双写一致性的问题

```


问题：一致性的问题是分布式系统中很常见的问题。一致性一般分为两种：强一致性和最终一致性, 当我们要满足强一致性的时候, Redis也无法做到完美无瑕, 因为数据库和缓存双写, 肯定会出现不一致的情况, Redis只能保证最终一致性。

解决：我们如何保证最终一致性呢？

    第一种方式是给缓存设置一定的过期时间, 在缓存过期之后会自动查询数据库, 保证数据库和缓存的一致性。如果不设置过期时间的话, 我们首先要选取正确的更新策略：先更新数据库再删除缓存。但我们删除缓存的时候也可能出现某些问题, 所以需要将要删除的缓存的key放到消息队列中去, 不断重试, 直到删除成功为止。
```

##### 缓存雪崩问题

```


问题： 我们应该都在电影里看到过雪崩, 开始很平静, 然后一瞬间就开始崩塌, 具有很强的毁灭性。这里也是一样的, 我们执行代码的时候将很多缓存的实效时间设定成一样, 接着这些缓存在同一时间都会实效, 然后都会重新访问数据库更新数据, 这样会导致数据库连接数过多、压力过大而崩溃。

解决：

    设置缓存过期时间的时候加一个随机值。设置双缓存, 缓存1设置缓存时间, 缓存2不设置, 1过期后直接返回缓存2, 并且启动一个进程去更新缓存1和2。
```

##### 缓存穿透问题

```


问题： 缓存穿透是指一些非正常用户(黑客)故意去请求缓存中不存在的数据, 导致所有的请求都集中到到数据库上, 从而导致数据库连接异常。

解决:

    利用互斥锁。缓存失效的时候, 不能直接访问数据库, 而是要先获取到锁, 才能去请求数据库。没得到锁, 则休眠一段时间后重试。采用异步更新策略。无论key是否取到值, 都直接返回。value值中维护一个缓存失效时间, 缓存如果过期, 异步起一个线程去读数据库, 更新缓存。需要做缓存预热(项目启动前, 先加载缓存)操作。提供一个能迅速判断请求是否有效的拦截机制。比如利用布隆过滤器, 内部维护一系列合法有效的key, 迅速判断出请求所携带的Key是否合法有效。如果不合法, 则直接返回。
```

##### 缓存的并发竞争问题

```
问题：

缓存并发竞争的问题, 主要发生在多线程对某个key进行set的时候, 这时会出现数据不一致的情况。

比如Redis中我们存着一个key为amount的值, 它的value是100, 两个线程同时都对value加100然后更新, 正确的结果应该是变为300。但是两个线程拿到这个值的时候都是100, 最后结果也就是200, 这就导致了缓存的并发竞争问题。

解决

    如果多线程操作没有顺序要求的话, 我们可以设置一个分布式锁, 然后多个线程去争夺锁, 谁先抢到锁谁就可以先执行。这个分布式锁可以用zookeeper或者Redis本身去实现。可以利用Redis的incr命令。当我们的多线程操作需要顺序的时候, 我们可以设置一个消息队列, 把需要的操作加到消息队列中去, 严格按照队列的先后执行命令。
```

##### redis 为什么高性能

```
# 性能问题

影响 redis 性能的情况

4个方面: 网络, 磁盘, 内存, cpu

​```
带宽: 读写, 同步数据都会受到影响
客户端连接数

内存: 
value 的大小
维护定时器
定时删除过期key: cup 资源紧张时删除 key 影响性能


磁盘性能: 如果缓冲区满了网磁盘持久化时, 如果磁盘写入速度不够快, 会阻塞写操作


bgrewriteaof: 重写 aof 文件时, 占用额外内存, 重写的文件过大导致操作系统挂起


​```



# re
```



# 参考

[官网文档](http://redis.cn/documentation.html)

##### 数据类型

- [x] https://blog.csdn.net/u012060033/article/details/129168155 全部数据类型
- [ ] https://www.cnblogs.com/kmcl1314/articles/15896129.html string
- [ ] https://zhuanlan.zhihu.com/p/364720565
- [ ] https://zhuanlan.zhihu.com/p/148562122
- [ ] https://zhuanlan.zhihu.com/p/593111008
- [x] https://zhuanlan.zhihu.com/p/64772193 1
- [ ] https://zhuanlan.zhihu.com/p/68667360 2
- [ ] https://juejin.cn/post/6844903951502934030
- [ ] https://cloud.tencent.com/developer/article/1667574
- [ ] https://cloud.tencent.com/developer/article/1442961?from=article.detail.1667574&areaSource=106000.12&traceId=DA3zaAlbl_6IooH3Cs-sm
- [ ] https://cloud.tencent.com/developer/article/1921542?from=article.detail.1442961&areaSource=106000.8&traceId=iaayeX_P3We0kPNxU543b
- [ ] https://zhuanlan.zhihu.com/p/528146852 详细
- [ ] https://zhuanlan.zhihu.com/p/345618221
- [ ] https://www.cnblogs.com/hunternet/p/12742390.html
- [ ] https://www.cnblogs.com/qdhxhz/p/15669348.html
- [ ] https://www.cnblogs.com/bbgs-xc/p/14376109.html
- [ ] http://kaito-kidd.com/2021/04/19/can-redis-be-used-as-a-queue/
- [ ] https://zhuanlan.zhihu.com/p/358366217 rehash (有问题)
- [ ] https://juejin.cn/post/7027757834943234085 rehash

##### 基本原理

- [ ] https://zhuanlan.zhihu.com/p/364494952
- [ ] https://xiaolincoding.com/redis/cluster/master_slave_replication.html#%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%8C%E6%AD%A5 看看

##### 消息队列

- [ ] https://jingzh.blog.csdn.net/article/details/116257400 
- [ ] https://mp.weixin.qq.com/s/uhMrqR__6qgpl7vrE_otTQ

##### 内存管理

- [ ] https://juejin.cn/post/6844903982628864007
- [ ] https://mp.weixin.qq.com/s/SrQIGL_X8wC1eFsGu8gBXg
- [ ] 

- **[Redis 数据类型和应用场景](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/data_struct/command.html)**
  - **[图解 Redis 数据结构](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/data_struct/data_struct.html)**
- 持久化篇 
- - **[AOF 持久化是怎么实现的？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/storage/aof.html)**
  - **[RDB 快照是怎么实现的？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/storage/rdb.html)** 
- 集群篇 
- - **[什么是缓存雪崩、击穿、穿透？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/cluster/cache_problem.html)**
  - **[主从复制是怎么实现的？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/cluster/master_slave_replication.html)**
  - **[为什么要有哨兵？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/cluster/sentinel.html)**
- 架构篇 
- - **[数据库和缓存如何保证一致性？](https://link.zhihu.com/?target=https%3A//xiaolincoding.com/redis/architecture/mysql_redis_consistency.html)**



