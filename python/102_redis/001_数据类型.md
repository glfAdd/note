# x.01 数据类型

## redisObject

##### 编码方式

<img src=".\image\数据结构2.webp" alt="数据结构2" style="zoom:80%;" />

<img src=".\image\数据结构3.webp" alt="数据结构3" style="zoom:100%;" />



```
1. redis 用 c 语言开发
2. redis 的 key 限制为 512MB
3. redis 中所有 key 和 value 都包含 redisObject 结构体
```

##### redisObject 结构体

```c
// 4 + 4 + 24 + 32 + 64 = 128bits = 16bytes
struct RedisObject {
    int4 type; 				// 数据类型(string、list、hash等), 4bits
    int4 encoding; 			// 编码形式, 4bits
    int24 lru; 				// 对象的LRU信息, 24bits
    int32 refcount; 		// 引用计数器, 32bits
    void *ptr; 				// 指针指向对象的具体内容, 64bits
}
```

## dict 数据结构

<img src=".\image\dict数据结构2.png" alt="dict数据结构2" style="zoom:80%;" />

```
Redis 的 key value 映射用一个 dict 数据结构维护, 基于哈希表算法, 用 key 计算哈希值, 得到 key 在哈希表中的位置, 用拉链的方式解决哈希冲突, 在装在因子为超过预定值时自动扩容, 此时引发 rehasing (重哈希)
```

##### 数据结构

<img src=".\image\dict数据结构.webp" alt="dict数据结构" style="zoom:100%;" />

```c
// dict字典的数据结构
typedef struct dict{
    dictType *type; 			//直线dictType结构, dictType结构中包含自定义的函数, 这些函数使得key和value能够存储任何类型的数据
    void *privdata; 			// 私有数据, 保存着dictType结构中函数的 参数
    dictht ht[2]; 				// 两张哈希表
    long rehashidx; 			// rehash 的标记, rehash 时每迁移一个桶就对rehashidx +1, (-1 表示没有进行 rehash)
    int itreators;  			//正在迭代的迭代器数量
}
 
// dict 结构中 ht[0] ht[1] 哈希表的数据结构
typedef struct dictht{
    dictEntry[] table;        	// 存放元素数组的地址, 数组中存放哈希节点dictEntry的地址
    unsingned long size;      	// 哈希表table的大小, 出始大小为4
    unsingned long  sizemask; 	// 用于将 hash 值映射到 table 位置的索引
    unsingned long  used;     	// 记录哈希表已有节点（键值对）的数量  (所有链表中节点总数)?
}
```

##### 负载因子

```c
// 负载因子 = 哈希表已保存节点数量 / 哈希表大小
load_factor = ht[0].used / ht[0].size
```

##### rehash

```
1. 随着操作的不断执行, 哈希表保存的键值对会逐渐地增多或者减少, 为了让哈希表的负载因子 (load factor) 维持在一个合理的范围之内, 当哈希表保存的键值对数量太多或者太少时, 程序需要对哈希表的大小进行相应的扩展或者收缩
2. rehash 触发条件: 扩容操作 或 收缩操作
3. 扩展和收缩哈希表的通过执行 rehash (重新散列) 操作来完成
4. rehash 指的是重新计算键的哈希值和索引值
5. dict 采用哈希函数对 key 取哈希值得到在哈希表中的位置(桶的位置), 采用拉链法解决hash冲突
6. ht[2] 这两个哈希表 ht[0]和ht[1], rehash 时才都有效; 平常情况下, 只有 ht[0] 有效, ht[1] 没有任何数据.
7. 当装载因子 (load factor) 超过预定值时就会进行rehash


扩容和缩容都会通过 rehash 来实现
```

##### 扩容条件

```
满足其一:
    1. 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令, 并且哈希表的负载因子大于等于 1
    2. 哈希表的负载因子大于等于 5, 强制扩容, 无论是否在执行 BGSAVE 或 BGREWRITEAOF


在执行 BGSAVE 命令或 BGREWRITEAOF命令时, Redis 会 fork 一个子进程, 而大多数操作系统都采用写时复制（copy-on-write）技术来优化子进程的使用效率, 所以在子进程存在期间, 服务器会提高执行扩展操作所需的负载因子, 尽可能地避免在子进程存在期间进行哈希表扩展操作, 这可以避免不必要的内存写入操作, 最大限度地节约内存
```

##### 收缩条件

```c
不用考虑是否在执行 BGSAVE 或 BGREWRITEAOF

// 当哈希表的负载因子小于 0.1 时, 即填充率必须<10%
(ht[0].used / ht[0].siz) < 0.1
```

##### rehash 过程

```
1. 为 dict 的 ht[1] 哈希表分配空间, 大小取决于要执行的操作, 以及 ht[0] 当前包含的键值对数量:
    如果扩是展操作, 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n （2 的 n 次方幂） (也就是原来的 2 倍)
    如果是收缩操作, 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n 
2. 字典的 rehashidx 设置为0, 表示 rehash 工作正式开始. rehashidx 表示 rehash 到哪个链表了, table[rehashidx]得到对应的桶
3. 在 rehash 进行期间, 每次对字典执行 添加/删除/查找/更新 操作时, 除了执行指定的操作以外, 对这个 key 进行 rehash
	a. dict 添加操作: 如果正在重哈希中, 会把数据插入到 ht[1], 否则插入到 ht[0]
    b. dict 查询操作: 先在第一个哈希表ht[0]上进行查找, 再判断当前是否在重哈希, 如果没有, 那么在ht[0]上的查找结果就是最终结果。否则, 在ht[1]上进行查找。查询时会先根据key计算出桶的位置, 在到桶里的链表上寻找key。
    c. dict 删除操作: 如果正在重哈希中, 同时在 ht[0] 和 ht[1] 删除, 否则只在 ht[0] 中删除
4. 当 rehash 完成一个链表所在的桶之后, 将rehashidx 属性的值 +1, 表示下一次要迁移链表所在桶的位置
5. 随着字典操作的不断执行, 最终 ht[0] 的所有桶对应的键值对都会被 rehash 至 ht[1], ht[0] 变为空表, 释放 ht[0], 将 ht[1] 设置为 ht[0], 并在 ht[1] 新创建一个空白哈希表, 为下一次 rehash 做准备
6. 将 rehashidx 属性的值设为 -1, 表示 rehash 操作已完成
```

##### 渐进式 rehash

```
1. 将扩容和收缩操作分为多次执行, 每次只 rehash 一个链表, 避免一次 rehash 的数据数据量过大, 导致 redis 服务阻塞
2. rehash 过程中如果执行了增删改查操作, 除了增删改查操作外, 还会对 ht[0] 和 ht[1] 这个 key 进行 rehash
3. 渐进式 rehash 执行期间的哈希表操作
    a. 删除、查找、更新: 在渐进式 rehash 执行期间, 字典会同时使用 ht[0] 和 ht[1] 两个哈希表 (例如, 查找一个键, 先在 ht[0] 里面查找, 如果没找到, 到 ht[1] 里面进行查找)
    b. 新增数据: 在渐进式 rehash 执行期间, 新添加到字典的键值对都只保存到 ht[1], ht[0] 不进行任何添加操作
```

##### rehash 实例

<img src=".\image\rehash1.png" alt="rehash1" style="zoom:80%;" />

```
ht[0].used 当前的值为 4, 4 * 2 = 8, 而 8 （2^3）恰好是第一个大于等于 4 的 2 的 n 次方,  所以程序会将 ht[1] 哈希表的大小设置为 8 
```

<img src=".\image\rehash2.png" alt="rehash2" style="zoom:80%;" />

```
ht[1] 在分配空间之后
```

<img src=".\image\rehash3.png" alt="rehash3" style="zoom:80%;" />

```
将 ht[0] 包含的四个键值对都 rehash 到 ht[1] 
```

<img src=".\image\rehash4.webp" alt="rehash4" style="zoom:80%;" />

```
释放 ht[0] , 并将 ht[1] 设置为 ht[0] , 然后为 ht[1] 分配一个空白哈希表
```

##### hash 冲突

<img src=".\image\hash.webp" alt="hash" style="zoom:100%;" />

```
1. 通过 hash 表达式, 不同的 key 得到的 hash 值相同, 即为 hash 冲突
2. redis 使用链地址法 (hash 桶) 解决冲突, 每个 hash 值对应一个单链表, 即桶. 将 hash 冲突的值放入桶中
rehash 增加现有的哈希桶数量减少哈希冲突



```



## string

#### 底层实现

<img src=".\image\int2.webp" alt="int2" style="zoom:80%;" />

```
1. string 内部 encoding 有 3 种: 
	int, raw 和 embstr
2. string 底层数据结构有 2 种: 
	int 和 SDS
3. redis 的 key 和 string 类型 value 限制均为 512MB. key 太大影响检索性能
4. encoding 方式如何选择 (分界值不同版本不一样, 44 是最新的)
    1. 如果字符串对象保存的是整数值, 并且这个整数值可以用 long 类型来表示, 会用 int 数据结构, 编码是 int, 整数值保存在 ptr 属性里面
    2. 如果字符串对象保存的是字符串, 并且这个字符申的长度 <= 44, 会用 SDS 数据结构, SDS 编码是 embstr 
    3. 如果字符串对象保存的是字符串, 并且这个字符申的长度 > 44, 会用 SDS 数据结构, SDS 编码是 raw 
```

#### int

<img src=".\image\int2.jpg" alt="int2" style="zoom:50%;" />

```
8字节的长整型 long, 范围 2^63-1 (40亿)
```

#### SDS

> 二进制安全: c 语言 "\0" 表示字符串的结束, 如果字符串本身就有 "\0" 字符, 字符串就会被截断, 即非二进制安全. 若通过某种机制保证读写字符串时不损害其内容, 则是二进制安全.
>
> SDS (Simple Dynamic string): 简单动态字符串

1. Redis 用 C 语言编写, 但 Redis 没用 char 来表示字符串, 而是用 SDS 来存储字符串数据.
2. c 语言字符串不记录长度, 每次获取长度都需要遍历, 时间的复杂度是O(n); SDS 用 len 属性记录长度, 获取长度时间复杂度变为O(1).
4. c 语言字符串以空字符串 "\0" 作为结束符, 一些图片中含有结束符, 不是二进制安全; SDS 是二进制安全的, 使用 len 属性的值判断字符串是否结束, 而不是空字符来 "\0". SDS 所有 API 都会以处理二进制的方式来处理存放在 buf[ ] 数组里的数据. 所以可以保存文本数据和二进制数据(图片, 视频等).
6. c 语言两个字符串拼接, 若没有分配足够长度的内存空间就会出现缓冲区溢出; SDS 先根据 len 判断空间是否满足要求, 若是空间不够, 就会进行相应的空间扩展, 不会出现缓冲区溢出.
5. SDS 空间预分配: 给字符串分配空间时, 分配的空间比实际要多, 减少连续的执行字符串增长带来内存重新分配的次数
    1. 如果 SDS 的长度 len 小于 1MB, redis 会分配和 len 同样大小的未使用空间 (例如 len 为 13字节, redis 也会分配 13字节的未使用空间, 因此 SDS 的 buf 数组实际长度 13+13+1=27 字节, 额外的 1 字节用于保存空字符)
    2. 如果 SDS 的长度 len 大于等于 1MB, redis 会分配 1MB 的未 使用空间。例如, len 的长度为 30MB, 那么将分配 1MB 的未使用空间, 因此 SDS 的 buf 数组实际长度变 30MB + 1MB + 1byte
6. SDS 惰性空间释放: 当字符串被缩短的时候, SDS也不会立即回收不适用的空间, 而是通过 free 属性将不使用的空间记录下来, 等后面使用的时候再释放, 并为将来可能的增长操作提供了优化. 在需要的时候回释放 SDS 未使用的空间, 不会浪费内存.

```

```



##### raw 编码

<img src=".\image\raw编码结构2.webp" alt="raw编码结构2" style="zoom:100%;" />

##### embstr 编码

<img src=".\image\embstr编码结2.png" alt="embstr编码结2" style="zoom:40%;" />

##### embstr 对比 raw

```
1. embstr 和 raw 都是由 redisObject 和 sds 组成
2. raw 需要为 redisObject 和 sds 内存不是连续的
	a. 分配内存时, 要分配 2 次内存
	b. 释放内存时, 要调用 2 次内存释放函数
3. embstr 的 redisObject 和 sds 内存是连续的
	a. 分配内存时, 要分配 1 次内存
	b. 释放内存时, 要调用 1 次内存释放函数
	c. 字符串的长度增加需要重新分配内存时, redisObject 和 sds 都需要重新分配内存
	d. embstr 编码的字符串对象实际上是只读的, redis 没有为 embstr 编码的字符串对象编写任何相应的修改程序. 对 embstr 编码字符串对象执行任何修改命令 (例如 append) 时, 会先将对象的编码从 embstr 转换成 raw, 然后再执行修改命令


例如:
    > set test3 ccc
    OK
    > object encoding test3
    embstr
    > append test3 eee
    6
    > object encoding test3
    raw
    > set test3 ccc
    OK
    > object encoding test3
    embstr	
```

##### SDS 内存优化

```
1. 优化了 sds 的内存使用, 用于存储字符串的内存就会变大
2. raw 和 embstr 编码的分界线:
	redis 2.+ 是 32 字节
	redis 3.0-4.0 是 39 字节
	redis 5.0 是 44 字节
```

- 旧版 sds 占用内存

  ```c
  // 内存分配器 jemalloc 分配的内存如果超出了64个字节就认为是一个大字符串, 用 raw 编码
  // SDS 结构体中的 content 的字符串是以字节 \0 结尾的字符串 (是为了便于直接使用 glibc 的字符串处理函数, 以及为了便于字符串的调试打印输出)
  // 64byte - 16byte - 8byte - 1byte = 39byte
  struct SDS {
      unsigned int capacity;	// 4byte
      unsigned int len; 		// 字符串长度, 4byte
      byte[] content; 		// 数组, 保存字符串的每一个字符元素
  }
  ```
  
- 新版 sds 占用内存

  <img src=".\image\sds.png" alt="sds" style="zoom:90%;" />

  ```c
  // unsigned int 变成了 uint8_t, uint16_t, 还加了一个char flags标识, 总共只用了3个字节的大小。相当于优化了sds的内存使用, 相应的用于存储字符串的内存就会变大
  // 64byte - 16byte -3byte -1byte = 44byte。  
  struct SDS {
      int8 capacity; // 1byte
      int8 len; // 1byte
      int8 flags; // 1byte
      byte[] content; // 内联数组, 长度为 capacity
  }
  ```

#### 命令

```
set k v
get k
del k

incr k                  值自增1
decr k                  值自减1
incrby k n              值加n
decrbu k n              值减n
incrbyfloat k n         值加浮点n

append k v              值末尾追加字符串
getrange k start end    获取start和end之间字符
setrange k start v      从start开始替换为v
getbit
setbit
bitcount
bitop

EXISTS k						判断是否存在
STRLEN k						字符串长度
MSET key1 value1 key2 value2	批量设置
MGET key1 key2 					批量获取
SET number 0					设置 key-value 类型的值 
INCR number						将 key 中储存的数字值增一 
INCRBY number 10				将key中存储的数字值加 10
DECR number						将 key 中储存的数字值减一
DECRBY number 10				将key中存储的数字值键 10
EXPIRE name  60					设置 key 在 60 秒后过期（该方法是针对已经存在的key设置过期时间）
TTL name						查看数据还有多久过期
SETNX key value					不存在就插入
SET key value EX 60				设置 key-value 类型的值, 并设置该key的过期时间为 60 秒
SETEX key  60 value				设置 key-value 类型的值, 并设置该key的过期时间为 60 秒
```

## list

#### 底层实现

```
1. list 是字符串列表, 按照插入顺序排序, 可以从列表头部/尾部的添加/移除元素
2. list 的最大长度为 2^32 - 1 个元素 (40 亿)
3. Redis 3.2 版本前底层数据结构是 ziplist 和 linkedlist, 3.2 后只有 quicklist


3.2 版本前
ziplist: 当哈希类型中元素个数小于 512 个 (默认, hash-max-ziplist-entrie 设置), 并所有值都小于 64 字节 (默认, hash-max-ziplist-value 设置) 时, Redis 会使用 ziplist 作为哈希的内部实现
hashtable: 当上述条件不满足时, Redis 则会采用 hashtable 作为哈希的内部实现。
linkedlist 占用内存比 ziplist 多, 创建新的列表键时, 先用 ziplist, 并且在有需要的时候, 才从 ziplist 实现转换到 linkedlist
```

#### ziplist (压缩列表)

##### 概念

```
ziplist 是一组连续内存块组成的顺序的数据结构, 能节省内存, 压缩列表中使用多个节点来存储数据
```

##### 结构体

```c
struct ziplist<T> {
    int32 zlbytes; 			// 整个压缩列表占用字节数, 4byte
    int32 zltail_offset; 	// 最后一个元素距离压缩列表起始位置的偏移量, 用于快速定位到最后一个节点, 4byte
    int16 zllength; 		// 元素个数, 2byte
    T[] entries; 			// 列表中的每一个节点
    int8 zlend; 			// 压缩列表特殊结束符号, 值恒为 0xFF
}
```

<img src=".\image\hash2.png" alt="hash2" style="zoom:80%;" />

<img src=".\image\hash3.png" alt="hash3" style="zoom:60%;" />

```
entry 节点
	previous_entry_ength: 表示前一个节点 entry 的长度, 可用于计算前一个节点的其实地址, 因为他们的地址是连续的
	content:每个节点的内容
	encoding: content 内容类型和长度
```



```
127.0.0.1:6379> rpush dotahero sf qop doom
(integer) 3
127.0.0.1:6379> object encoding dotahero
"ziplist"
```

#### linkedlist (双向列表)

<img src=".\image\链表.webp" alt="链表" style="zoom:80%;" />

#### quicklist (快速列表)

```
quicklist(快速列表)实现的, 快速列表支持从链表头和尾添加元素, 并且可以获取指定位置的元素内容。
是 linkedlist 和 ziplist 的结合, quicklist 中的每个节点 ziplist 都能够存储多个数据元素
```

#### 命令

```
lpush k v1 v2           左边添加多个元素
rpush k v1 v2           右边添加多个元素
lpop k
rpop k
lindex k v              获取指定位置上一个元素
lrange k start end      获取指定范围所有元素
ltrim k start end       只保留start和end及之间的元素  

blpop k timeout         从第一个非空列表中弹出最左边元素, 或timeout内等待可弹出的元素出现                   
brpop                                        右
rpoplpush k1 k2         弹出 k1 list 最右边, 推入 k2 list 最左, 并获取这个元素 
brpoplpush k1 k2 timeout弹出 k1 list 最右边, 推入 k2 list 最左, 并获取这个元素, 如果k1位空则阻塞timeout直到元素出现
```

## hash

```
2. 每个 hash 可以存储 2^32 - 1 键值对 (40多亿)



新键值添加到字典时, 先根据键计算出哈希值和索引值, 根据索引将新键值对的节点放到哈希表数组(table)的指定索引上面
Redis 通常使用 MurmurHash2 计算键的哈希值, 这种算法的优点在于, 即使输入的键是有规律的, 算法仍能给出一个很好的随机分布性, 并且算法的计算速度也非常快
而索引值计算则非常简单：将哈希值和 dictht::sizemask 做与运算的结果即为索引值。
比如, 哈希值为 6, sizemask 为 3, 则索引值为 6&3 = 2
```



#### redis hash 结构

<img src=".\image\hash结构.webp" alt="hash结构" style="zoom:80%;" />

```c
typedef struct dictht {
    dictEntry **table; 			// 元素数组. 每个元素都是一个链表的头指针, 链表中每个结点都保存着一个键值对
    unsigned long size;			// table 数组的大小, 总是为 2^n
    unsigned long sizemask;		// 用于计算索引值的掩码, 总是等于 size-1
    unsigned long used;			// hash 表中的已有结点数量 (所有链表中节点总数)
} dictht;
```

#### 底层实现

```
Redis 7.0 前, 底层数据结构是 ziplist 或 hashtable
Redis 7.0 后, 弃用 ziplist 和 hashtable, 由 listpack 实现

ziplist: 当 hash 中元素个数小于 hash-max-ziplist-entries配置（默认 512 个）, 且所有值都小于 hash-max-ziplist-value 配置（默认 64 字节）时, Redis 会使用 ziplist 作为哈希的内部实现
hashtable: 当上述条件不满足时, Redis 则会采用 hashtable 作为哈希的内部实现
```

#### rehash

##### hash 冲突

##### 渐进式 rehash 

```
1. rehash: hash 的扩容和缩容
2. 渐进式 rehash: redis 是单线程, 大字典 rehash 耗时久, 阻塞时间长, 因此逐步操作

1. 扩容和缩容都会通过 rehash 来实现
2. 渐进式rehash: 是指我们的大字典的扩容是比较消耗时间的, 需要重新申请新的数组, 然后将旧字典所有链表的元素重新挂接到新的数组下面, 是一个O(n)的操作。但 redis 是单线程, 无法承受这样的耗时过程, 所以采用了渐进式rehash小步搬迁, 虽然慢一点, 但是可以搬迁完毕


扩容时新建一个长度为原始长度 2 倍的空哈希表
, 然后原哈希表上的元素重新 rehash 到新的哈希表中去
```

##### 渐进式 rehash 过程

```
redis 采用渐进式 rehash, 有个变量指向第一个哈希桶, 然后 redis 每执行一个添加key, 删除key的类似命令, 就顺便copy一个哈希桶中的数据到新的哈希表中去,就会所有的数据都被重新hash到新的哈希表中。
那么在这个过程中, 当然再有写的操作, 会直接把数据放到新的哈希表中, 保证旧的肯定有copy完的时候, 如果这段时间对数据库的操作比较少, 也没有关系, redis内部也有定时任务, 每隔一段时间也会copy一次

redis 通过链式哈希解决冲突, 也就是同一个桶里面的元素使用链表保存。但是当链表过长就会导致查找性能变差可能。所以redis为了追求块, 使用了两个全局哈希表。用于rehash操作, 增加现有的哈希桶数量, 减少哈希冲突
开始默认使用hash表1保存键值对数据, hash表2此刻没有分配空间。当数据越来越多的触发rehash操作, 则执行以下操作：

    给hash表2分配更大的空间
    将hash表1的数据重新映射拷贝到hash表2中
    将hash表1的数据重新映射到hash表2的过程并不是一次性的, 这样会造成redis阻塞, 无法提供服务
    释放hash表1的空间

详细步骤：

    为ht[1]分配空间, 让字典同时持有ht[0]和ht[1]两个hash表
    在字典中维持一个索引计数器变量rehashidx, 并将它的值设置为0, 表示rehash工作正式开始
    在rehash进行期间, 每次对字典执行添加, 删除, 查找或者更新操作时, 程序除了执行特定的操作以外, 还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1], 当rehash工作完成之后, 程序将rehashidx属性的值增1
    随着字典操作的不断执行, 最终在某个时间点上, ht[0]的所有键值对都会被rehash至ht[1], 这时程序将rehashidx属性的值设为-1, 表示rehash操作已完成
    将ht[0]释放, 然后将ht[1]设置成ht[0], 最后为ht[1]分配一个空白哈希表

```

##### rehash触发条件

```
1. 扩容
扩容一般会在 Hash 表中的元素个数等于第一维数组的长度的时候, 就会开始扩容。
扩容的大小是原数组的两倍。不过在redis在做bgsave（RDB持久化操作的过程）时, 为了减少内存页的过多分离（Copy On Write）, redis不会去扩容。
但是如果hash表的元素个数已经到达了第一维数组长度的5倍的时候, 就会强制扩容, 不管你是否在持久化。

2. 缩容
当我们的hash表元素逐渐删除的越来越少的时候。redis就会对hash表进行缩容来减少第一维数组长度的空间占用。缩容的条件是元素个数低于数组长度的10%, 并且缩容不考虑是否在做redis持久化。
不用考虑bgsave主要原因是因为我们的缩容的内存都是已经使用过的, 缩容的时候可以直接置空, 而且由于申请的内存比较小, 同时会释放掉一些已经使用的内存, 不会增大系统的压力。
```



#### hashtable (哈希表)



#### 命令

```
hset k1 k2 v
hget k1 k2
hdel k1 k2
hgetall k1              获取所有键值对
hmget K k1 k2           获取1个/多个键的值
hmset K k1 v1 k2 v2     添加1个/多个值
hdel K k1 k2            获取成功删除的数量
hlen K                  获取键值对的数量
hexists K k             查看k是否存在
hkeys K k               删除
hvals K                 获取所有值
hgetall K               获取所有键值对
hincrby K k count       值加上count
hincrbyfloat K k count  值加上count 浮zrange点
```



## set



```
1. 存储 string 类型集合, 无序, 不重复
2. 通过哈希表实现的, 所以添加, 删除, 查找的复杂度都是O(1)
3. 集合中最大的成员数为 2^32 - 1 (每个集合可存储40多亿个成员)




Set 类型是一个无序并唯一的键值集合, 它的存储顺序不会按照插入的先后顺序进行存储。

一个集合最多可以存储 2^32-1 个元素。概念和数学中个的集合基本类似, 可以交集, 并集, 差集等等, 所以 Set 类型除了支持集合内的增删改查, 同时还支持多个集合取交集、并集、差集。

Set 类型和 List 类型的区别如下：

List 可以存储重复元素, Set 只能存储非重复元素；List 是按照元素的先后顺序存储元素的, 而 Set 则是无序方式存储元素的。

Set 的差集、并集和交集的计算复杂度较高, 在数据量较大的情况下, 如果直接执行这些计算, 会导致 Redis 实例阻塞

```

#### 底层实现

```
底层数据结构是 hashtable 或 intset

如果集合中的元素都是整数且元素个数小于 512 （默认值, set-maxintset-entries配置）个, Redis 会使用整数集合作为 Set 类型的底层数据结构；如果集合中的元素不满足上面条件, 则 Redis 使用哈希表作为 Set 类型的底层数据结构。

intset: 当集合中的元素都是整数, 并且集合中的元素个数小于 512 时(默认, set-max-intset-entries 设置), 用 intset 作为底层内部实现
hashtable: 当上述条件不满足时, Redis 会采用 hashtable 作为底层实现。
```





```

```

#### 底层实现

```

```





#### intset (整数集合)

```
inset: 整数集合, 用于保存整数值的数据结构类型, 如 int16_t, int32_t, int64_t

在整数集合中, 有三个属性值
encoding: 编码方式
contents[]: 元素的内容
length: 整数集合的长度


在整数集合新增元素的时候, 若是超出了原集合的长度大小, 就会对集合进行升级, 具体的升级过程如下
	首先扩展底层数组的大小, 并且数组的类型为新元素的类型。
	然后将原来的数组中的元素转为新元素的类型, 并放到扩展后数组对应的位置。
	整数集合升级后就不会再降级, 编码会一直保持升级后的状态。
```



#### 应用

##### 点赞

```
Set 类型可以保证一个用户只能点一个赞, 这里举例子一个场景, key 是文章id, value 是用户id。

uid:1 、uid:2、uid:3 三个用户分别对 article:1 文章点赞了。

# uid:1 用户对文章 article:1 点赞
> SADD article:1 uid:1
(integer) 1
# uid:2 用户对文章 article:1 点赞
> SADD article:1 uid:2
(integer) 1
# uid:3 用户对文章 article:1 点赞
> SADD article:1 uid:3
(integer) 1

uid:1 取消了对 article:1 文章点赞。

> SREM article:1 uid:1
(integer) 1

获取 article:1 文章所有点赞用户 :

> SMEMBERS article:1
1) "uid:3"
2) "uid:2"

获取 article:1 文章的点赞用户数量：

> SCARD article:1
(integer) 2

判断用户 uid:1 是否对文章 article:1 点赞了：

> SISMEMBER article:1 uid:1
(integer) 0  # 返回0说明没点赞, 返回1则说明点赞了

```



##### 共同关注

```


Set 类型支持交集运算, 所以可以用来计算共同关注的好友、公众号等。

key 可以是用户id, value 则是已关注的公众号的id。

uid:1 用户关注公众号 id 为 5、6、7、8、9, uid:2 用户关注公众号 id 为 7、8、9、10、11。

# uid:1 用户关注公众号 id 为 5、6、7、8、9
> SADD uid:1 5 6 7 8 9
(integer) 5
# uid:2  用户关注公众号 id 为 7、8、9、10、11
> SADD uid:2 7 8 9 10 11
(integer) 5

uid:1 和 uid:2 共同关注的公众号：

# 获取共同关注
> SINTER uid:1 uid:2
1) "7"
2) "8"
3) "9"

给 uid:2 推荐 uid:1 关注的公众号：

> SDIFF uid:1 uid:2
1) "5"
2) "6"

验证某个公众号是否同时被 uid:1 或 uid:2 关注:

> SISMEMBER uid:1 5
(integer) 1 # 返回0, 说明关注了
> SISMEMBER uid:2 5
(integer) 0 # 返回0, 说明没关注

```



##### 抽奖活动

```


存储某活动中中奖的用户名 , Set 类型因为有去重功能, 可以保证同一个用户不会中奖两次。

key为抽奖活动名, value为员工名称, 把所有员工名称放入抽奖箱 ：

>SADD lucky Tom Jerry John Sean Marry Lindy Sary Mark
(integer) 5

如果允许重复中奖, 可以使用 SRANDMEMBER 命令。

# 抽取 1 个一等奖：
> SRANDMEMBER lucky 1
1) "Tom"
# 抽取 2 个二等奖：
> SRANDMEMBER lucky 2
1) "Mark"
2) "Jerry"
# 抽取 3 个三等奖：
> SRANDMEMBER lucky 3
1) "Sary"
2) "Tom"
3) "Jerry"

如果不允许重复中奖, 可以使用 SPOP 命令。

# 抽取一等奖1个
> SPOP lucky 1
1) "Sary"
# 抽取二等奖2个
> SPOP lucky 2
1) "Jerry"
2) "Mark"
# 抽取三等奖3个
> SPOP lucky 3
1) "John"
2) "Sean"
3) "Lindy"

```

#### 命令

```
sadd k v1 v2            添加1个/多个元素, 获取不存在新增加的个数        
srem k v1 v2            删除1个/多个元素, 获取删除的个数
scard k                 获取元素个数
smembers k              获取所有元素
sismember k v           是否包含元素v
srandmember k count     随机获取count个元素, 当count为正数时元素不重复, 负数时可以重复
spop k                  随机移除一个元素并获取元素
smove k1 k2 v           如果k1有元素v则移动到k2则


SINTER key [key ...]					交集运算
SINTERSTORE destination key [key ...]	将交集结果存入新集合destination中
SUNION key [key ...]					并集运算
SUNIONSTORE destination key [key ...]	将并集结果存入新集合destination中
SDIFF key [key ...]						差集运算
SDIFFSTORE destination key [key ...]	将差集结果存入新集合destination中
```

## zset

<img src=".\image\zset.jpg" alt="zset" style="zoom:50%;" />

```
1. zset 是有序集合, 每个元素都有一个 double 类型的 score (分数), redis 通过分数来为集合中的成员进行排序
2. score 可以重复
```

#### 底层实现

```
ziplist: 当有序集合的元素个数小于 128 (默认 , zset-max-ziplist-entries 设置), 同时每个元素的值都小于 64 字节(默认, zset-max-ziplist-value 设置), 用 ziplist 作为有序集合的内部实现。
skiplist：当上述条件不满足时, Redis 会采用 skiplist 作为内部编码。

Redis 7.0 中, 废弃了 ziplist 和 skiplist, 改为 listpack 数据结构
```



#### skiplist (跳跃表)

<img src=".\image\skiplist.jpg" alt="skiplist" style="zoom:80%;" />

```
skiplist: 跳跃表, 是一种有序的数据结构, 它通过每一个节点维持多个指向其它节点的指针, 从而达到快速访问的目的。

skiplist由如下几个特点：
有很多层组成, 由上到下节点数逐渐密集, 最上层的节点最稀疏, 跨度也最大。
每一层都是一个有序链表, 只扫包含两个节点, 头节点和尾节点。
每一层的每一个每一个节点都含有指向同一层下一个节点和下一层同一个位置节点的指针。如果一个节点在某一层出现, 那么该以下的所有链表同一个位置都会出现该节点。


在跳跃表的结构中有head和tail表示指向头节点和尾节点的指针, 能后快速的实现定位。level表示层数, len表示跳跃表的长度, BW表示后退指针, 在从尾向前遍历的时候使用。

BW下面还有两个值分别表示分值（score）和成员对象（各个节点保存的成员对象）。

跳跃表的实现中, 除了最底层的一层保存的是原始链表的完整数据, 上层的节点数会越来越少, 并且跨度会越来越大。

跳跃表的上面层就相当于索引层, 都是为了找到最后的数据而服务的, 数据量越大, 条表所体现的查询的效率就越高, 和平衡树的查询效率相差无几。
```

#### listpack

#### 应用

##### 排行榜

```


有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。

我们以博文点赞排名为例, 小林发表了五篇博文, 分别获得赞为 200、40、100、50、150。

# arcticle:1 文章获得了200个赞
> ZADD user:xiaolin:ranking 200 arcticle:1
(integer) 1
# arcticle:2 文章获得了40个赞
> ZADD user:xiaolin:ranking 40 arcticle:2
(integer) 1
# arcticle:3 文章获得了100个赞
> ZADD user:xiaolin:ranking 100 arcticle:3
(integer) 1
# arcticle:4 文章获得了50个赞
> ZADD user:xiaolin:ranking 50 arcticle:4
(integer) 1
# arcticle:5 文章获得了150个赞
> ZADD user:xiaolin:ranking 150 arcticle:5
(integer) 1

文章 arcticle:4 新增一个赞, 可以使用 ZINCRBY 命令（为有序集合key中元素member的分值加上increment）：

> ZINCRBY user:xiaolin:ranking 1 arcticle:4
"51"

查看某篇文章的赞数, 可以使用 ZSCORE 命令（返回有序集合key中元素个数）：

> ZSCORE user:xiaolin:ranking arcticle:4
"50"

获取小林文章赞数最多的 3 篇文章, 可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）：

# WITHSCORES 表示把 score 也显示出来
> ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES
1) "arcticle:1"
2) "200"
3) "arcticle:5"
4) "150"
5) "arcticle:3"
6) "100"

获取小林 100 赞到 200 赞的文章, 可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员, 分数由低到高排序）：

> ZRANGEBYSCORE user:xiaolin:ranking 100 200 WITHSCORES
1) "arcticle:3"
2) "100"
3) "arcticle:5"
4) "150"
5) "arcticle:1"
6) "200"

```

##### 电话、姓名排序

```
电话、姓名排序

使用有序集合的 ZRANGEBYLEX 或 ZREVRANGEBYLEX 可以帮助我们实现电话号码或姓名的排序, 我们以 ZRANGEBYLEX （返回指定成员区间内的成员, 按 key 正序排列, 分数必须相同）为例。

注意：不要在分数不一致的 SortSet 集合中去使用 ZRANGEBYLEX和 ZREVRANGEBYLEX 指令, 因为获取的结果会不准确。

1、电话排序

我们可以将电话号码存储到 SortSet 中, 然后根据需要来获取号段：

> ZADD phone 0 13100111100 0 13110114300 0 13132110901 
(integer) 3
> ZADD phone 0 13200111100 0 13210414300 0 13252110901 
(integer) 3
> ZADD phone 0 13300111100 0 13310414300 0 13352110901 
(integer) 3

获取所有号码:

> ZRANGEBYLEX phone - +
1) "13100111100"
2) "13110114300"
3) "13132110901"
4) "13200111100"
5) "13210414300"
6) "13252110901"
7) "13300111100"
8) "13310414300"
9) "13352110901"

获取 132 号段的号码：

> ZRANGEBYLEX phone [132 (133
1) "13200111100"
2) "13210414300"
3) "13252110901"

获取132、133号段的号码：

> ZRANGEBYLEX phone [132 (134
1) "13200111100"
2) "13210414300"
3) "13252110901"
4) "13300111100"
5) "13310414300"
6) "13352110901"

2、姓名排序

> zadd names 0 Toumas 0 Jake 0 Bluetuo 0 Gaodeng 0 Aimini 0 Aidehua 
(integer) 6

获取所有人的名字:

> ZRANGEBYLEX names - +
1) "Aidehua"
2) "Aimini"
3) "Bluetuo"
4) "Gaodeng"
5) "Jake"
6) "Toumas"

获取名字中大写字母A开头的所有人：

> ZRANGEBYLEX names [A (B
1) "Aidehua"
2) "Aimini"

获取名字中大写字母 C 到 Z 的所有人：

> ZRANGEBYLEX names [C [Z
1) "Gaodeng"
2) "Jake"
3) "Toumas"

```

#### 命令

```
zadd k s1 v1 s2 v2      将分数s1 s2和元素添加到集合
zrem k v1 v2            移除元素, 并获取成功的数量            
zcard k                 获取元素数量
zincrby k count v       v的分数增加count
zcount k s1 s2          获取分数s1和s2之间元素数量
zrank k v               获取元素的排名
zscore k v              获取元素的分值
zrange k start stop [withscores]    返回排名start和stop之间的成员, 如果有withscores则一起返回分数


ZADD key score member [[score member]...]   	往有序集合key中加入带分值元素
ZREM key member [member...] 					往有序集合key中删除元素                
ZSCORE key member								返回有序集合key中元素member的分值
ZCARD key 										返回有序集合key中元素个数
ZINCRBY key increment member 					为有序集合key中元素member的分值加上increment
ZRANGE key start stop [WITHSCORES]				正序获取有序集合key从start下标到stop下标的元素
ZREVRANGE key start stop [WITHSCORES]			倒序获取有序集合key从start下标到stop下标的元素
ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]		返回有序集合中指定分数区间内的成员, 分数由低到高排序。
ZRANGEBYLEX key min max [LIMIT offset count]	返回指定成员区间内的成员, 按字典正序排列, 分数必须相同。
ZREVRANGEBYLEX key max min [LIMIT offset count]	返回指定成员区间内的成员, 按字典倒序排列, 分数必须相同
ZUNIONSTORE destkey numberkeys key [key...] 	并集计算(相同元素分值相加), numberkeys一共多少个key, WEIGHTS每个key对应的分值乘积
ZINTERSTORE destkey numberkeys key [key...]		交集计算(相同元素分值相加), numberkeys一共多少个key, WEIGHTS每个key对应的分值乘积
```



## HyperLogLogs (基数统计)

> 2.8.9 版新增

```
基数统计（hyperloglog）: 基于概率的数据结构
是用来做基数统计的算法, 所谓基数, 也就是不重复的元素
Redis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型, 是一种用于「统计基数」的数据集合类型, 基数统计就是指统计一个集合中不重复的元素个数。但要注意, HyperLogLog 是统计规则是基于概率完成的, 不是非常准确, 标准误算率是 0.81%。
所以, 简单来说 HyperLogLog 提供不精确的去重计数。
HyperLogLog 的优点是, 在输入元素的数量或者体积非常非常大时, 计算基数所需的内存空间总是固定的、并且是很小的。
在 Redis 里面, 每个 HyperLogLog 键只需要花费 12 KB 内存, 就可以计算接近 2^64 个不同元素的基数, 和元素越多就越耗费内存的 Set 和 Hash 类型相比, HyperLogLog 就非常节省空间。
这什么概念？举个例子给大家对比一下。
用 Java 语言来说, 一般 long 类型占用 8 字节, 而 1 字节有 8 位, 即：1 byte = 8 bit, 即 long 数据类型最大可以表示的数是：2^63-1。对应上面的2^64个数, 假设此时有2^63-1这么多个数, 从 0 ~ 2^63-1, 按照long以及1k = 1024 字节的规则来计算内存总数, 就是：((2^63-1) * 8/1024)K, 这是很庞大的一个数, 存储空间远远超过12K, 而 HyperLogLog 却可以用 12K 就能统计完。
优点：
在输入元素的数量或者体积非常大时, 计算基数所需的空间总是固定的、并且是很小的。在 Redis 里面, 每个 HyperLogLog 键只需要花费 12 KB 内存, 就可以计算接近 2^64 个不同元素的基数。
缺点：
因为 HyperLogLog 只会根据输入元素来计算基数, 而不会储存输入元素本身, 所以 HyperLogLog 不能像集合那样, 返回输入的各个元素。
估算的值, 可能存在误差, 带有 0.81% 标准错误的近似值
```

#### 内部实现

```
HyperLogLog
```

#### HyperLogLog

#### 常见命令

```bash
PFADD key element [element ...]				# 添加指定元素到 HyperLogLog
PFCOUNT key [key ...]						# 返回给定 HyperLogLog 的基数估算值
PFMERGE destkey sourcekey [sourcekey ...]	# 将多个 HyperLogLog 合并为一个 HyperLogLog
```

#### **应用场景**

##### 百万级网页 UV 计数

```
Redis HyperLogLog 优势在于只需要花费 12 KB 内存, 就可以计算接近 2^64 个元素的基数, 和元素越多就越耗费内存的 Set 和 Hash 类型相比, HyperLogLog 就非常节省空间。
所以, 非常适合统计百万级以上的网页 UV 的场景。
在统计 UV 时, 你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。
PFADD page1:uv user1 user2 user3 user4 user5
接下来, 就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了, 这个命令的作用就是返回 HyperLogLog 的统计结果。
PFCOUNT page1:uv
不过, 有一点需要你注意一下, HyperLogLog 的统计规则是基于概率完成的, 所以它给出的统计结果是有一定误差的, 标准误算率是 0.81%。
这也就意味着, 你使用 HyperLogLog 统计的 UV 是 100 万, 但实际的 UV 可能是 101 万。虽然误差率不算大, 但是, 如果你需要精确统计结果的话, 最好还是继续用 Set 或 Hash 类型。
```

## Geospatial (地理位置)

> 3.2 版新增

```
地理位置（Geo）: 地理位置信息储存起来,  并对这些信息进行操作 3.2新增

Redis GEO 是 Redis 3.2 版本新增的数据类型, 主要用于存储地理位置信息, 并对存储的信息进行操作。

在日常生活中, 我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车, 这些都离不开基于位置信息服务（Location-Based Service, LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息, 而且要能查询相邻的经纬度范围, GEO 就非常适合应用在 LBS 服务的场景中。
```



#### 内部实现

```
1. Geo 本身不是一种数据结构, 使用 zset 类型实现


使用 GeoHash 编码方法将经纬度装换为 zset




Redis 中将经纬度使用 52 位的整数进行编码, 放进zset中, score 就是 GeoHash 的 52 位整数值
Geo 查询时, 其内部对应的操作其实就是 zset(skiplist)的操作
通过 zset 的 score 进行排序就可以得到坐标附近的其它元素, 通过将score还原成坐标值就可以得到元素的原始坐标。

这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后, 就用区间的编码值来表示, 并把编码值作为 Sorted Set 元素的权重分数。



Redis 中处理这些地理位置坐标点的思想是：
二维平面坐标点 --> 一维整数编码值 --> zset(score为编码值) --> zrangebyrank(获取score相近的元素)、zrangebyscore --> 通过score(整数编码值)反解坐标点 --> 附近点的地理位置坐标
```

#### 常用命令

```bash
# 存储指定的地理空间位置, 可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。
GEOADD key longitude latitude member [longitude latitude member ...]

# 从给定的 key 里返回所有指定名称(member)的位置（经度和纬度）, 不存在的返回 nil。
GEOPOS key member [member ...]

# 返回两个给定位置之间的距离。
GEODIST key member1 member2 [m|km|ft|mi]

# 根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]
```

#### 应用场景

##### 滴滴叫车

```
这里以滴滴叫车的场景为例, 介绍下具体如何使用 GEO 命令：GEOADD 和 GEORADIUS 这两个命令。
假设车辆 ID 是 33, 经纬度位置是（116.034579, 39.030452）, 我们可以用一个 GEO 集合保存所有车辆的经纬度, 集合 key 是 cars:locations。
执行下面的这个命令, 就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：
GEOADD cars:locations 116.034579 39.030452 33
当用户想要寻找自己附近的网约车时, LBS 应用就可以使用 GEORADIUS 命令。
例如, LBS 应用执行下面的命令时, Redis 会根据输入的用户的经纬度信息（116.054579, 39.030452 ）, 查找以这个经纬度为中心的 5 公里内的车辆信息, 并返回给 LBS 应用。
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10
```

## bitmap (位图)

> 2.2 版新增

<img src=".\image\bitmap.png" alt="bitmap" style="zoom:40%;" />

```
更细化的一种操作, 以bit为单位
2. bitmap 类型适合二值状态统计的场景 (只有 0 和 1 两种), 在记录海量数据时, bitmap 能够有效地节省内存空间

bitmap: 即位图, 是一串连续的二进制数组 (0 和 1), 通过 offset (偏移量) 定位元素
bitmap通过最小的单位bit来进行0|1的设置, 表示某s个元素的值或者状态, 时间复杂度为O(1)。
由于 bit 是计算机中最小的单位, 使用它进行储存将非常节省空间, 特别适合一些数据量大且使用二值统计的场景。

bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。
String 类型是会保存为二进制的字节数组, 所以, Redis 就把字节数组的每个 bit 位利用起来, 用来表示一个元素的二值状态, 你可以把 bitmap 看作是一个 bit 数组。




bitmap: 是一种实现对位的操作的’数据结构’, 在数据结构加引号主要因为：bitmap本身不是一种数据结构, 底层实际上是字符串, 可以借助字符串进行位操作。


可以把 bitmaps 想象成一个以位为单位的数组, 数组的每个单元只能存储 0 和 1, 数组的下标在 bitmap 中叫做偏移量 offset。
bitmap的出现是为了大数据量而来的, 但是前提是统计的这个大数据量每个的状态只能有两种, 因为每一个bit位只能表示两种状态。
```

#### 底层实现

```
bitmap 不是一种数据结构, 底层使用字符串存储, 只不过操作的粒度变成了 bit (位), 因此只有 0 和 1 两个值
bitmap 的偏移量 offset 最大值是 (8 * 1024 * 1024 * 512 = 2^32). 由于 C 语言字符串末尾要存储一位分隔符, 所以实际上 bitmap 的偏移量 offset 值上限是 2^32-1
```

#### 常用命令

```bash
SETBIT key offset value			# 设置值, 其中value只能是 0 和 1
GETBIT key offset				# 获取值
BITCOUNT key start end			# 获取指定范围内值为 1 的个数 (start 和 end 以字节为单位)

# bitmap间的运算
# operations 位移操作符, 枚举值
  AND 与运算 &
  OR 或运算 |
  XOR 异或 ^
  NOT 取反 ~
# result 计算的结果, 会存储在该key中
# key1 … keyn 参与运算的key, 可以有多个, 空格分割, not运算只能一个key
# 当 BITOP 处理不同长度的字符串时, 较短的那个字符串所缺少的部分会被看作 0。返回值是保存到 destkey 的字符串的长度（以字节byte为单位）, 和输入 key 中最长的字符串长度相等。
BITOP [operations] [result] [key1] [keyn…]
BITPOS [key] [value]			# 返回指定key中第一次出现指定value(0/1)的位置
```

#### 应用

##### 签到统计

```bash
在签到打卡的场景中, 只记录签到（1）和未签到（0）
签到统计时, 每个用户一天的签到用 1 个 bit 位就能表示, 一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以, 而一年的签到也只需要用 365 个 bit 位, 根本不用太复杂的集合类型

如统计 ID 100 的用户在 2022 年 6 月份的签到情况:
# 1. 记录该用户 6 月 3 号已签到
SETBIT uid:sign:100:202206 2 1
# 2. 检查该用户 6 月 3 日是否签到
GETBIT uid:sign:100:202206 2 
# 3. 统计该用户在 6 月份的签到次数
BITCOUNT uid:sign:100:202206

如何统计这个月首次打卡时间呢？
Redis 提供了 BITPOS key bitValue [start] [end]指令, 返回数据表示 bitmap 中第一个值为 bitValue 的 offset 位置
在默认情况下,  命令将检测整个位图,  用户可以通过可选的 start 参数和 end 参数指定要检测的范围。所以我们可以通过执行这条命令来获取 userID = 100 在 2022 年 6 月份首次打卡日期：
BITPOS uid:sign:100:202206 1
需要注意的是, 因为 offset 从 0 开始的, 所以我们需要将返回的 value + 1
```

##### 判断用户登陆态

```bash
bitmap 提供了 GETBIT、SETBIT 操作, 通过一个偏移值 offset 对 bit 数组的 offset 位置的 bit 位进行读写操作, offset 从 0 开始
只需要一个 key = login_status 表示存储用户登陆状态集合数据,  将用户 ID 作为 offset, 在线就设置为 1, 下线设置 0。通过 GETBIT判断对应的用户是否在线。 50000 万 用户只需要 6 MB 的空间。
假如我们要判断 ID = 10086 的用户的登陆情况：
1. 执行以下指令, 表示用户已登录。
SETBIT login_status 10086 1
2. 检查该用户是否登陆, 返回值 1 表示已登录。
GETBIT login_status 10086
3. 登出, 将 offset 对应的 value 设置成 0。
SETBIT login_status 10086 0
```

##### 连续签到用户总数

```bash
统计连续 7 天连续打卡用户总数
我们把每天的日期作为 bitmap 的 key, userId 作为 offset, 若是打卡则将 offset 位置的 bit 设置成 1。
key 对应的集合的每个 bit 位的数据则是一个用户在该日期的打卡记录。
一共有 7 个这样的 bitmap, 如果我们能对这 7 个 bitmap 的对应的 bit 位做 『与』运算。同样的 UserID offset 都是一样的, 当一个 userID 在 7 个 bitmap 对应对应的 offset 位置的 bit = 1 就说明该用户 7 天连续打卡。
结果保存到一个新 bitmap 中, 我们再通过 BITCOUNT 统计 bit = 1 的个数便得到了连续打卡 3 天的用户总数了。
Redis 提供了 BITOP operation destkey key [key ...]这个指令用于对一个或者多个 key 的 bitmap 进行位元操作。
    opration 可以是 and、OR、NOT、XOR。当 BITOP 处理不同长度的字符串时, 较短的那个字符串所缺少的部分会被看作 0 。空的 key 也被看作是包含 0 的字符串序列。
举个例子, 比如将三个 bitmap 进行 AND 操作, 并将结果保存到 destmap 中, 接着对 destmap 执行 BITCOUNT 统计。
# 与操作
BITOP AND destmap bitmap:01 bitmap:02 bitmap:03
# 统计 bit 位 =  1 的个数
BITCOUNT destmap
即使一天产生一个亿的数据, bitmap 占用的内存也不大, 大约占 12 MB 的内存（10^8/8/1024/1024）, 7 天的 bitmap 的内存开销约为 84 MB。同时我们最好给 bitmap 设置过期时间, 让 Redis 删除过期的打卡数据, 节省内存。
```

## Stream (流)

> 5.0 版本新增

```
1. 为消息队列新增加的数据类型, 用于消息队列.
2. 每个写操作都会写入到 RDB 和 AOF 中
3. 消费者处理完消息后, 需要执行 XACK 命令, Redis 把这条消息标记为 '处理完成', XPENDING 命令查看已读取/但尚未确认处理完成的消息
4. 发布消息时可以指定队列的最大长度, 当队列长度超过上限后, 旧消息被删除
```

#### 底层实现

1. 消息链表

<img src=".\image\Stream.png" alt="Stream" style="zoom:100%;" />

```
每个 Stream 都有唯一的名称，它就是 Redis 的 key，在我们首次使用 xadd 指令追加消息时自动创建。
每个 Stream 中有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容


Consumer Group: 消费组
last_delivered_i: 游标，每个消费组会有个游标，任意一个消费者读取了消息都会使游标 last_delivered_id 往前移动
pending_ids: 消费者的状态变量，作用是维护消费者的未确认的 id。 pending_ids 记录了当前已经被客户端读取的消息，但是还没有 ack (Acknowledge character：确认字符）
```

2. 内部编码

   <img src=".\image\Stream2.png" alt="Stream2" style="zoom:80%;" />

   ```
   stream底层的数据结构是radix tree：Radix Tree(基数树) 事实上就是几乎相同是传统的二叉树。仅仅是在寻找方式上，以一个unsigned int类型数为例，利用这个数的每个比特位作为树节点的推断。能够这样说，比方一个数10001010101010110101010，那么依照Radix 树的插入就是在根节点，假设遇到0，就指向左节点，假设遇到1就指向右节点，在插入过程中构造树节点，在删除过程中删除树节点。
   ```

3. 构成

   ![Stream3](.\image\Stream3.png)

   ```
   stream 总共由 3 部分构成：
   1. robj， 每个 redis 对象实例都会有一个最基本的结构来存储它实际的类型, 编码和对应的结构的位置
   2. rax, 用作存储 stream ID
   3. listpack，rax 下的每一个 key 节点都会把对应的 keys 和 values 的值存在这个 listpack 结构中
   ```

#### 消息队列

##### 发布消息

```bash
# * 表示让 Redis 为插入的数据自动生成一个全局唯一的 ID
# 消息 id 的格式是 '时间戳-自增序号'
# 插入成功后会返回全局唯一的 id "1654254953808-0", 表示在 1654254953808 毫秒内的第 1 条消息
    1654254953808 是数据插入时当前服务器时间
    0 是当前毫秒内的消息序号

> XADD mymq * name xiaolin
"1654254953808-0"
```

##### 读取消息

```bash
# XREAD 从消息队列中读取消息, 可以指定一个消息 ID, 会从这个它的下一条消息开始进行读取
> XREAD STREAMS mymq 1654254953807-0
1) 1) "mymq"
   2) 1) 1) "1654254953808-0"
         2) 1) "name"
            2) "xiaolin"
            

# 从开头读取 5 条消息
# 0-0 表示从开头读取
127.0.0.1:6379> XREAD COUNT 5 STREAMS queue 0-0
1) 1) "queue"
   2) 1) 1) "1618469123380-0"
         2) 1) "name"
            2) "zhangsan"
      2) 1) "1618469127777-0"
         2) 1) "name"
            2) "lisi"
 

> XREAD COUNT 5 STREAMS queue 1618469127777-0
(nil)
```

##### 阻塞读

```bash
# BLOCK 10000 表示阻塞 10000 毫秒,
# $ 表示读取最新的消息
> XREAD BLOCK 10000 STREAMS mymq $
(nil)
(10.00s)


# BLOCK 0 表示阻塞等待, 不设置超时时间
> XREAD COUNT 5 BLOCK 0 STREAMS queue 1618469127777-0
```

##### Stream 发布订阅

<img src=".\image\消息队列6.jpg" alt="消息队列6" style="zoom:100%;" />

生产者发布 2 条消息

```
127.0.0.1:6379> XADD queue * name zhangsan
"1618470740565-0"
127.0.0.1:6379> XADD queue * name lisi
"1618470743793-0"
```

创建 2 个消费者组

```bash
# 创建消费者组 group1 和 group1, 0-0表示从头拉取消息
> XGROUP CREATE queue group1 0-0
OK
> XGROUP CREATE queue group2 0-0
OK
```

group1 消费

```c
# > 表示拉取最新数据
127.0.0.1:6379> XREADGROUP GROUP group1 consumer COUNT 5 STREAMS queue >
1) 1) "queue"
   2) 1) 1) "1618470740565-0"
         2) 1) "name"
            2) "zhangsan"
      2) 1) "1618470743793-0"
         2) 1) "name"
            2) "lisi"
```

group2 消费

```c
127.0.0.1:6379> XREADGROUP GROUP group2 consumer COUNT 5 STREAMS queue >
1) 1) "queue"
   2) 1) 1) "1618470740565-0"
         2) 1) "name"
            2) "zhangsan"
      2) 1) "1618470743793-0"
         2) 1) "name"
            2) "lisi"
```

##### 消息堆积

```c
# 发布消息时可以指定队列的最大长度, 当队列长度超过上限后, 旧消息被删除
# 队列长度最大10000
127.0.0.1:6379> XADD queue MAXLEN 10000 * name zhangsan
"1618473015018-0"
```

#### 命令

```
XADD：插入消息, 保证有序, 可以自动生成全局唯一 ID；
XLEN ：查询消息长度；
XREAD：用于读取消息, 可以按 ID 读取数据；
XDEL ： 根据消息 ID 删除消息；
DEL ：删除整个 Stream；
XRANGE ：读取区间消息XREADGROUP：按消费组形式读取消息；
XPENDING 和 XACK：
        XPENDING 命令可以用来查询每个消费组内所有消费者「已读取、但尚未确认」的消息
        XACK 命令用于向消息队列确认消息处理已完成；
        
        
消息保序：XADD/XREAD
阻塞读取：XREAD block
重复消息处理：Stream 在使用 XADD 命令, 会自动生成全局唯一 ID；
消息可靠性：内部使用 PENDING List 自动保存消息, 使用 XPENDING 命令查看消费组已经读取但是未被确认的消息, 消费者使用 XACK 确认消息；支持消费组形式消费数据
```



# expire persist

<img src=".\image\redis过期时间.png" alt="redis过期时间" style="zoom:80%;" />

# 
