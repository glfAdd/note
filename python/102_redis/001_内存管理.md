# 文档

[官网文档](http://redis.cn/documentation.html)





# 数据类型

## redisObject

#### 编码方式

<img src=".\image\数据结构.png" alt="数据结构" style="zoom:30%;" />

<img src=".\image\数据结构2.webp" alt="数据结构2" style="zoom:80%;" />

<img src=".\image\数据结构3.webp" alt="数据结构3" style="zoom:100%;" />

```
对象所使用的底层数据结构	编码常量	object encoding 命令输出
整数	REDIS_ENCODING_INT	“int”
embstr编码简单动态字符串（SDS）	REDIS_ENCODING_EMBSTR	“embstr”
简单动态字符串	REDIS_ENCODING_RAW	“raw”
字典	REDIS_ENCODING_HT	“hashtable”
双端链表	REDIS_ENCODING_LINKEDLIST	“linkedlist”
压缩列表	REDIS_ENCODING_ZIPLiST	“ziplist”
整数集合	REDIS_ENCODING_INTSET	“intset”
跳跃表和字典	REDIS_ENCODING_SKIPLIST	“skiplist”

```



```
1. redis 用 c 开发
2. redis 的 key 限制为 512MB
3. redis 中所有 key 和 value 都用 redisObject 结构体表示
```

#### redisObject 结构体

```c
# 4 + 4 + 24 + 32 + 64 = 128bits = 16bytes
struct RedisObject {
    int4 type; // 不同的 redis 对象会有不同的数据类型(string、list、hash等), 4bits
    int4 encoding; // 编码形式, 4bits
    int24 lru; // 对象的LRU信息, 24bits
    int32 refcount; // 引用计数器, 32bits
    void *ptr; // 指针指向对象的具体内容, 64bits
}
```

#### int

<img src=".\image\int.jpg" alt="int" style="zoom:80%;" />

```
8字节的长整型（long，2^63-1）
整数型值使用 int 的存储方式进行存储, 在 redisObject 的 ptr 属性中就会保存该值
```

#### sds

<img src=".\image\sds.webp" alt="sds" style="zoom:80%;" />

```
SDS (Simple Dynamic String): 简单动态字符串
	buf: 数组, 保存字符串的每一个字符元素
	free: buf 数组中未使用的字节数量
	

存储的是字符串值且长度大于32个字节, 就使用 SDS 方式进行存储, 并且 encoding 设置为 raw
存储的是字符串值且长度小于32个字节, 就会将 encoding 改为 embstr 来保存字符串
```

##### SDS 内存优化

```
raw 和 embstr 编码的分界线 redis 3.2 版本之前是 39byte, 之后变为 44byte.
原因是优化了 sds 的内存使用, 用于存储字符串的内存就会变大
```

- 旧版 sds 占用内存

  ```c
  // 内存分配器 jemalloc 分配的内存如果超出了64个字节就认为是一个大字符串，用 raw 编码
  // SDS 结构体中的 content 的字符串是以字节 \0 结尾的字符串 (是为了便于直接使用 glibc 的字符串处理函数, 以及为了便于字符串的调试打印输出)
  // 64byte - 16byte - 8byte - 1byte = 39byte
  
  
  struct SDS {
      unsigned int capacity; // 4byte
      unsigned int len; // 字符串长度, 4byte
      byte[] content; // 数组, 保存字符串的每一个字符元素
  }
  ```

- 新版 sds 占用内存

  <img src=".\image\sds.png" alt="sds" style="zoom:90%;" />

  ```c
  // unsigned int 变成了 uint8_t, uint16_t, 还加了一个char flags标识，总共只用了3个字节的大小。相当于优化了sds的内存使用，相应的用于存储字符串的内存就会变大
  // 64byte - 16byte -3byte -1byte = 44byte。  
  struct SDS {
      int8 capacity; // 1byte
      int8 len; // 1byte
      int8 flags; // 1byte
      byte[] content; // 内联数组，长度为 capacity
  }
  ```

##### SDS 与 c 语言字符串对比

```
1. c 语言字符串不记录长度, 每次获取长度都会遍历得到, 时间的复杂度是O(n). SDS 中用 len 记录长度, 获取长度时间复杂度变为O(1)
2. c 语言两个字符串拼接, 若没有分配足够长度的内存空间就会出现缓冲区溢出. SDS 会先根据 len 属性判断空间是否满足要求, 若是空间不够, 就会进行相应的空间扩展, 不会出现缓冲区溢出
3. SDS 空间预分配: 给字符串分配空间时, 分配的空间比实际要多, 减少连续的执行字符串增长带来内存重新分配的次数
	当修改字符串后的长度len小于1MB, 就会预分配和len一样长度的空间, 即len=free
	若是len大于1MB, free分配的空间大小就为1MB」。
4. SDS 惰性空间释放: 当字符串被缩短的时候, SDS也不会立即回收不适用的空间, 而是通过free属性将不使用的空间记录下来, 等后面使用的时候再释放。
5. SDS 是二进制安全的, 除了可以储存字符串以外还可以储存二进制文件（如图片、音频, 视频等文件的二进制数据）；而c语言中的字符串是以空字符串作为结束符, 一些图片中含有结束符, 因此不是二进制安全的。
```

#### raw

<img src=".\image\raw编码结构.png" alt="raw编码结构" style="zoom:80%;" />

```
raw: SDS 大于 44 个字节的字符串
(redis 3.2 版本之前是 39字节, 之后是 44字节)
```

#### embstr

<img src=".\image\embstr编码结构.png" alt="embstr编码结构" style="zoom:80%;" />

```
embstr: 小于等于 44 个字节的字符串, embstr 格式的 SDS
(redis 3.2 版本之前是 39字节, 之后是 44字节)
```

##### embstr 对比 raw

```
1. embstr 和 raw 都是由 redisObject 和 sds 组成
2. embstr 的 redisObject 和 sds 是连续的, 
	a. 分配内存时, 要分配 1 次内存
	b. 释放内存时, 要调用 1 次内存释放函数
	c. 如果 embstr 要增加长度, redisObject 和 sds 都需要重新分配内存
3. raw 需要为 redisObject 和 sds 分别分配内存
	a. 分配内存时, 要分配 2 次内存
	b. 释放内存时, 要调用 2 次内存释放函数
```

#### ziplist (压缩列表)

##### 概念

```
是一组连续内存块组成的顺序的数据结构，压缩列表能够节省空间，压缩列表中使用多个节点来存储数据

当哈希类型中元素个数小于 hash-max-ziplist-entries 配置（默认 512 个），同时所有值都小于 hash-max-ziplist-value 配置（默认 64 字节）时，Redis 会使用 ziplist 作为哈希的内部实现
hashtable: 当上述条件不满足时，Redis 则会采用 hashtable 作为哈希的内部实现。
```

##### 结构体

```c
struct ziplist<T> {
    int32 zlbytes; // 整个压缩列表占用字节数, 4byte
    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点, 4byte
    int16 zllength; // 元素个数, 2byte
    T[] entries; // 列表中的每一个节点
    int8 zlend; // 压缩列表特殊结束符号, 值恒为 0xFF
}
```

<img src=".\image\hash2.png" alt="hash2" style="zoom:80%;" />

<img src=".\image\hash3.png" alt="hash3" style="zoom:60%;" />

```
entry 节点
	previous_entry_ength: 表示前一个节点 entry 的长度, 可用于计算前一个节点的其实地址, 因为他们的地址是连续的
	content:每个节点的内容
	encoding: content 内容类型和长度
```



```
127.0.0.1:6379> rpush dotahero sf qop doom
(integer) 3
127.0.0.1:6379> object encoding dotahero
"ziplist"
```



#### linkedlist (双端列表)

<img src=".\image\链表.webp" alt="链表" style="zoom:80%;" />

```
字符串列表
```

```
Redis 中的列表在3.2之前的版本是使用 ziplist 和 linkedlist 进行实现的, 在 3.2 之后 quicklist


linkedlist: 是一个双向链表，他和普通的链表一样都是由指向前后节点的指针。插入、修改、更新的时间复杂度尾O(1), 但是查询的时间复杂度确实O(n)

linkedlist和 quicklist 的底层实现是采用链表进行实现，在c语言中并没有内置的链表这种数据结构，Redis实现了自己的链表结构。
```

#### quicklist (快速列表)

```
quicklist(快速列表)实现的，快速列表支持从链表头和尾添加元素，并且可以获取指定位置的元素内容。
```



#### skiplist

<img src=".\image\skiplist.jpg" alt="skiplist" style="zoom:80%;" />

```
skiplist: 跳跃表, 是一种有序的数据结构，它通过每一个节点维持多个指向其它节点的指针，从而达到快速访问的目的。

skiplist由如下几个特点：
有很多层组成，由上到下节点数逐渐密集，最上层的节点最稀疏，跨度也最大。
每一层都是一个有序链表，只扫包含两个节点，头节点和尾节点。
每一层的每一个每一个节点都含有指向同一层下一个节点和下一层同一个位置节点的指针。如果一个节点在某一层出现，那么该以下的所有链表同一个位置都会出现该节点。


在跳跃表的结构中有head和tail表示指向头节点和尾节点的指针，能后快速的实现定位。level表示层数，len表示跳跃表的长度，BW表示后退指针，在从尾向前遍历的时候使用。

BW下面还有两个值分别表示分值（score）和成员对象（各个节点保存的成员对象）。

跳跃表的实现中，除了最底层的一层保存的是原始链表的完整数据，上层的节点数会越来越少，并且跨度会越来越大。

跳跃表的上面层就相当于索引层，都是为了找到最后的数据而服务的，数据量越大，条表所体现的查询的效率就越高，和平衡树的查询效率相差无几。
```

#### hashtable

##### hash 冲突

<img src=".\image\hash.webp" alt="hash" style="zoom:100%;" />

```
hash 表存在 hash 冲突, 为了解决 hash 冲突, 假如hashtable中不同的key通过计算得到同一个index, 就会形成单向链表（「链地址法」）
```

##### rehash

```
rehash: 字典底层实现中, value 是 dictEntry 结构体进行存储, 当 hash 表中的键值对不断的增加或者减少时, 需要对 hash 表进行一个扩展或者收缩

这里就会和HashMap一样也会就进行rehash操作, 进行重新散列排布。



dictEntry 属性
    dictEntry **table: 哈希表数组
    unsigned long size: hash 表大小
    unsigned long sizemask: 用于计算索引值
    unsigned long used: hash表中已有的节点数


有ht[0]和ht[1]两个对象
ht[0]是用来最开始存储数据的, 当要进行扩展或者收缩时, ht[0]的大小就决定了ht[1]的大小, 
ht[0]中的所有的键值对就会重新散列到ht[1]中。

扩展操作：ht[1]扩展的大小是比当前 ht[0].used 值的二倍大的第一个 2 的整数幂；收缩操作：ht[0].used 的第一个大于等于的 2 的整数幂。

当ht[0]上的所有的键值对都rehash到ht[1]中, 会重新计算所有的数组下标值, 当数据迁移完后ht[0]就会被释放, 然后将ht[1]改为ht[0], 并新创建ht[1], 为下一次的扩展和收缩做准备。
```

##### 渐进式 rehash

```
假如在 rehash 的过程中数据量非常大, Redis 不是一次性把全部数据 rehash 成功, 这样会导致Redis对外服务停止, Redis内部为了处理这种情况采用「渐进式的rehash」。

Redis将所有的rehash的操作分成多步进行, 直到都rehash完成, 具体的实现与对象中的rehashindex属性相关, 「若是rehashindex 表示为-1表示没有rehash操作」。

当rehash操作开始时会将该值改成0, 在渐进式rehash的过程「更新、删除、查询会在ht[0]和ht[1]中都进行」, 比如更新一个值先更新ht[0], 然后再更新ht[1]。

而新增操作直接就新增到ht[1]表中, ht[0]不会新增任何的数据, 这样保证「ht[0]只减不增, 直到最后的某一个时刻变成空表」, 这样rehash操作完成。

上面就是字典的底层hashtable的实现原理, 说完了hashtable的实现原理, 我们再来看看Hash数据结构的两一种存储方式「ziplist（压缩列表）」
```





#### inset

```
inset: 整数集合, 用于保存整数值的数据结构类型, 如 int16_t, int32_t, int64_t

在整数集合中，有三个属性值
encoding: 编码方式
contents[]: 元素的内容
length: 整数集合的长度


在整数集合新增元素的时候，若是超出了原集合的长度大小，就会对集合进行升级，具体的升级过程如下
	首先扩展底层数组的大小，并且数组的类型为新元素的类型。
	然后将原来的数组中的元素转为新元素的类型，并放到扩展后数组对应的位置。
	整数集合升级后就不会再降级，编码会一直保持升级后的状态。
```

1

#### 

#### 

## string

```
String 类型数据有 3 中结构存储: int, raw, embstr
```



```
string 是二进制安全, 可以包含任何数 (数字, 字符串, 图片等)
redis 的 key 和 string 类型 value 限制均为 512MB
key 太大影响检索性能
```

##### 命令

```
set k v
get k
del k

incr k                  值自增1
decr k                  值自减1
incrby k n              值加n
decrbu k n              值减n
incrbyfloat k n         值加浮点n

append k v              值末尾追加字符串
getrange k start end    获取start和end之间字符
setrange k start v      从start开始替换为v
getbit
setbit
bitcount
bitop

* 对不存在的值进行自增/自减, 会将这个值当0处理
* 对无法解释为整数/浮点的字符串自增/自减返回错误
```

## list

```
起初 redis 的 list 的底层是 ziplist 或 linkedlist, 之后使用 quicklist
```



##### 命令

```
lpush k v1 v2           左边添加多个元素
rpush k v1 v2           右边添加多个元素
lpop k
rpop k
lindex k v              获取指定位置上一个元素
lrange k start end      获取指定范围所有元素
ltrim k start end       只保留start和end及之间的元素  

blpop k timeout         从第一个非空列表中弹出最左边元素, 或timeout内等待可弹出的元素出现                   
brpop                                        右
rpoplpush k1 k2         弹出k1最右边, 推入k2最左, 并获取这个元素
brpoplpush k1 k2 timeout弹出k1最右边, 推入k2最左, 并获取这个元素, 如果k1位空则阻塞timeout直到元素出现
```

## set

```
存储 string 类型, 无序, 不重复
集合是通过哈希表实现的, 所以添加, 删除, 查找的复杂度都是O(1)
set 底层实现是 hashtable 和 intset
```



##### 命令

```
sadd k v1 v2            添加1个/多个元素, 获取不存在新增加的个数        
srem k v1 v2            删除1个/多个元素, 获取删除的个数
scard k                 获取元素个数
smembers k              获取所有元素
sismember k v           是否包含元素v
srandmember k count     随机获取count个元素, 当count为正数时元素不重复, 负数时可以重复
spop k                  随机移除一个元素并获取元素
smove k1 k2 v           如果k1有元素v则移动到k2则
```

## zset

```
zset 是有序集合
zset 底层实现是 ziplist 和 skiplist 实现的


```



```
zset(有序集合)
string类型元素的集合, 且不允许重复的成员。
格式: zadd  name score value
不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。
zset的成员是唯一的,但分数(score)却可以重复。
```

##### 命令

```
zadd k s1 v1 s2 v2      将分数s1 s2和元素添加到集合
zrem k v1 v2            移除元素, 并获取成功的数量            
zcard k                 获取元素数量
zincrby k count v       v的分数增加count
zcount k s1 s2          获取分数s1和s2之间元素数量
zrank k v               获取元素的排名
zscore k v              获取元素的分值
zrange k start stop [withscores]    返回排名start和stop之间的成员, 如果有withscores则一起返回分数
```

## hash

##### 定义

```
Hash 对象的实现方式有两种分别是 ziplist, hashtable
	hashtable的存储方式key是String类型的, value也是以key value的形式进行存储

两者在新增时都会通过key计算出数组下标, 不同的是计算法方式不同, HashMap中是以hash函数的方式, 而 hashtable 中计算出 hash 值后, 还要通过sizemask 属性和哈希值再次得到数组下标

redis 中每个 hash 可以存储 2^32 - 1 键值对 (40多亿)



ziplist（压缩列表）：当哈希类型中元素个数小于 hash-max-ziplist-entries配置（默认 512 个），同时所有值都小于 hash-max-ziplist-value 配置（默认 64 字节）时，Redis 会使用 ziplist 作为哈希的内部实现。
hashtable（哈希表）：当上述条件不满足时，Redis 则会采用 hashtable 作为哈希的内部实现。

```

##### 渐进式 rehash 

```
1. rehash: hash 的扩容和缩容
2. 渐进式 rehash: redis 是单线程, 大字典 rehash 耗时久, 阻塞时间长, 因此逐步操作

1. 扩容和缩容都会通过 rehash 来实现
2. 渐进式rehash: 是指我们的大字典的扩容是比较消耗时间的，需要重新申请新的数组，然后将旧字典所有链表的元素重新挂接到新的数组下面，是一个O(n)的操作。但 redis 是单线程，无法承受这样的耗时过程，所以采用了渐进式rehash小步搬迁，虽然慢一点，但是可以搬迁完毕


扩容时新建一个长度为原始长度 2 倍的空哈希表
，然后原哈希表上的元素重新 rehash 到新的哈希表中去
```

##### 渐进式 rehash 过程

```
redis 采用渐进式 rehash, 有个变量指向第一个哈希桶，然后 redis 每执行一个添加key，删除key的类似命令，就顺便copy一个哈希桶中的数据到新的哈希表中去,就会所有的数据都被重新hash到新的哈希表中。
那么在这个过程中，当然再有写的操作，会直接把数据放到新的哈希表中，保证旧的肯定有copy完的时候，如果这段时间对数据库的操作比较少，也没有关系，redis内部也有定时任务，每隔一段时间也会copy一次

redis 通过链式哈希解决冲突，也就是同一个桶里面的元素使用链表保存。但是当链表过长就会导致查找性能变差可能。所以redis为了追求块，使用了两个全局哈希表。用于rehash操作，增加现有的哈希桶数量，减少哈希冲突
开始默认使用hash表1保存键值对数据，hash表2此刻没有分配空间。当数据越来越多的触发rehash操作，则执行以下操作：

    给hash表2分配更大的空间
    将hash表1的数据重新映射拷贝到hash表2中
    将hash表1的数据重新映射到hash表2的过程并不是一次性的，这样会造成redis阻塞，无法提供服务
    释放hash表1的空间

详细步骤：

    为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个hash表
    在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始
    在rehash进行期间，每次对字典执行添加，删除，查找或者更新操作时，程序除了执行特定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增1
    随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成
    将ht[0]释放，然后将ht[1]设置成ht[0]，最后为ht[1]分配一个空白哈希表

```



##### 命令

```
hset k1 k2 v
hget k1 k2
hdel k1 k2
hgetall k1              获取所有键值对
hmget K k1 k2           获取1个/多个键的值
hmset K k1 v1 k2 v2     添加1个/多个值
hdel K k1 k2            获取成功删除的数量
hlen K                  获取键值对的数量
hexists K k             查看k是否存在
hkeys K k               删除
hvals K                 获取所有值
hgetall K               获取所有键值对
hincrby K k count       值加上count
hincrbyfloat K k count  值加上count 浮zrange点
```

## HyperLogLogs 基数统计

```
    基数统计（hyperloglog）: 基于概率的数据结构, 2.8.9新增

```



## Geospatial 地理位置

```
    地理位置（Geo）: 地理位置信息储存起来,  并对这些信息进行操作 3.2新增

```



## BitMaps 位图

```
    位操作（bitmap）: 更细化的一种操作, 以bit为单位。

```

##### Stream

```
    流（Stream） 5.0新增
```



```
expire
persist
```

<img src=".\image\redis过期时间.png" alt="redis过期时间" style="zoom:80%;" />

# 内存管理

```
设置最大内存, 避免redis内存使用过多对其他程序造成影响

redis.conf 文件, redis.conf 文件默认的最大内存 maxmemory=0 表示不限制redis内存的使用
```

### 删除策略

> 只能删除过期数据
>
> redis 同时使用了惰性删除与定期删除

##### 1. 定时删除

- 含义: 在设置 key 的过期时间的同时, 为该key创建一个定时器, 让定时器在 key 的过期时间来临时对 key 进行删除

- 优点: 保证内存被尽快释放

- 缺点:

  - 若过期 key很多, 删除这些key会占用很多的CPU时间, 在CPU时间紧张的情况下, CPU不能把所有的时间用来做要紧的事儿, 还需要去花时间删除这些key
  - 定时器的创建耗时,若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生）, 性能影响严重


##### 2. 惰性删除

- 含义: key 过期的时候不删除, 每次通过key获取值的时候去检查是否过期, 若过期则删除并返回不存在
- 优点: 节约CPU性能, 发现不得不删除的时候才删除
- 缺点: 内存空间压力大

##### 3. 定期删除

- 每隔一段时间, 我们就对一些key进行检查, 删除里面过期的key。
- 优点
  - 可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响, 解决"定时删除"对 cpu 影响的问题
  - 释放过期键占用的内存, 解决"惰性删除"对内存占用的问题.
- 缺点
  - 难以确定删除操作执行的时长（每次删除执行多长时间）和频率（每隔多长时间做一次删除)。如果执行的太频繁, 定期删除策略变得和定时删除策略一样, 对CPU不友好。如果执行的太少, 那又和惰性删除一样了, 过期键占用的内存不会及时得到释放。
  - 在获取某个键时, 如果某个键的过期时间已经到了, 但是还没执行定期删除, 那么就会返回这个键的值

### 淘汰策略

> 新数据写入时, redis 使用的内存达到上限时
>
> 设置 redis 使用内存的上限

> https://blog.csdn.net/qq_37325859/article/details/125331084

- 每次存储数据前调用 freeMemoryIfNeeded() 检测内存是否充足。如果内存不满足新加入数据的最低存储要求, redis要临时删除一些数据为当前指令清理存储空间. 有时需要反复执行才能才是释放足够的空间. 当对所有数据尝试完毕后, 如果不能达到内存清理的要求, 将出现错误 "OOM command not allowed when used memory>'maxmemory'"

##### 参数

```
maxmemory: redis可使用内存占物理内存的最大比例, 默认为0, 表示不限制redis使用内存。生产环境中根据需求设定, 通常设置在50%以上
maxmemory-samples: 每次选取待删除数据的个数, 选取数据时并不会全库扫描, 导致严重的性能消耗, 降低读写性能。因此采用随机获取数据的方式作为待检测删除数据
maxmemory-policy: 达到最大内存后的, 对被挑选出来的数据进行删除的算法
```

##### 淘汰算法

```
volatile-lru, 针对设置了过期时间的key, 使用lru算法进行淘汰
volatile-lfu, 针对设置了过期时间的key, 使用lfu算法进行淘汰。
volatile-random, 从所有设置了过期时间的key中使用随机淘汰的方式进行淘汰。
volatile-ttl, 针对设置了过期时间的key, 越早过期的越先被淘汰。
allkeys-lru, 针对所有key使用lru算法进行淘汰。
allkeys-lfu, 针对所有key使用lfu算法进行淘汰。
allkeys-random, 针对所有的key使用随机淘汰机制进行淘汰。
noeviction, 不会淘汰任何数据, 当使用的内存空间超过 maxmemory 值时, 再有写请求来时会引发错误OOM（Out Of Memory）
```

##### LRU

```
Least Recently Used 最近很少使用




问题:
一个很久没有被访问的key, 偶尔被访问一次, 导致被误认为是热点数据的问题
```

##### redis LRU

- 3.0 版本以前

  ```
  随机采集淘汰的key, 每次随机选出5个key, 然后淘汰这5个key中最少使用的key
  数量可设置, 值越大越准确, 道消耗资源增加
  ```

- 3.0 版本以后

- > 空闲时长: 多久没有用了. 优先淘汰空闲时长大的

  ```
  1. 维护一个池子存放随机选取的 key, 并根据空闲时长排序
  2. 大于池内最小空闲时长的才能追加入池子
  3. 池子满了以后, 将空闲时长最长的移出池子并淘汰.
  ```

##### LFU

> 4.0 版本加入

```
根据key最近被访问的频率进行淘汰, 比较少访问的key优先淘汰, 反之则保留。
LFU的原理是使用计数器来对key进行排序, 每次key被访问时, 计数器会增大, 当计数器越大, 意味着当前key的访问越频繁, 也就是意味着它是热点数据
```

##### 最大限制

```
string 最大 512M

List、Set、Sorted Set 可以放 2 的 32 次方个元素(受内存影响)
```



# 持久化



> 持久化: 把内存的数据写入磁盘, 防止服务宕机内存数据丢失. 持久化所得的文件最好备份到不同的服务器

### rdb 快照

##### 快照频率

```
save N M
	在 N 秒内至少 M 个改动才触发一次 rdb
	
save 200 20
	200 秒内至少 20 个改动
```

##### 手动执行快照

```
save
或
gbsave
```



```
redis 默认使用快照方式, 默认文件名 dump.rdb 的二进制文件, 每次执行覆盖之前的内容.


创建子进程进行快照
系统发生崩溃丢失快照后更改的所有数据. 适用于丢失一部份数据也不会造成问题的应用程序

例子
  - 如果内存有10GB数据, 上一个快照2:31开始创建并成功, 3:12开始创建快照, 创建之前有51个键进行更新
  - 如果创建成功之前系统崩溃, 则丢失2:31之后的所有数据
  - 如果创建成功以后系统崩溃, 则丢失51的更新

配置文件
save 60 1000
stop-writes-on-bgsave-error no
rdbcompression yes
dbfilename dump.rdb
```

### AOF

- 将被执行的写命令写到AOF文件末尾, 以此来记录发生的变化. 

- 缺陷
  - redis不断运行, AOF文件不断增长, 在极端情况下, 体积不断增大的AOF文件甚至可能会用完硬盘的所有可用空间
  - 重新执行AOF文件记录的所有写命令来还原数据集, 如果AOF文件的体积非常大, 还原操作执行的时间就可能会非常长

##### 同步频率 appendfsync

- always: 每个写命令都同步写入硬盘, 严重降低 redis 速度, 用户几乎可以不损失任何数据每次只写入一条命令, 其他选项一次写入多条命令这种同步频率下, 机械硬盘每秒大约处理200个命令, 固态硬盘几万个命令
- everysec: 每秒执行一次同步. 兼顾数据安全和写入性能, 每秒同步一次AOF文件时的性能和不使用任何持久化特性时的性能相差无几
  系统崩溃用户也最多只会丢失一秒之内产生的数据。当硬盘忙于执行写人操作的时候, redis还会优雅地放慢自己的速度以便适应硬盘的最大写人速度。
- no: 由操作系统来决定应该在何时对AOF文件进行同步.  一般情况下不会对redis的性能带来影响, 但系统崩溃将导致使用这种选项的redis服务器丢失不定数量的数据. 如果用户的硬盘处理写入操作的速度不够快的话,那么当缓冲区被等待写入硬盘的数据填满时, redis 的写操作将被阻塞, 并导致redis处理命令请求的速度变慢

##### bgrewriteaof

```
为了解决AOF文件体积不断增大的问题, 用户可以向redis发送BGREWRITEAOF命令, 这个命令会通过移除AOF文件中的冗余命令来重写AOF文件, 使AOF文件的体积变得尽可能地小。


1. redis创建一个子进程重写AOF文件, 会导致的性能问题和内存占用问题
2. AOF文件的体积可能会比快照文件的体积大好几倍, 在进行AOF重写并删除旧AOF文件的时候, 删除一个体积达到数十GB大的旧AOF文件可能会导致操作系统挂起数秒
```

##### 配置文件

```
appendonly no
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb  
# 当AOF文件体积大于64MB, 且AOF文件的体积比上一次重写之后的体积大了至少100%时候, redis将执行BGREWRITEAOF命令
```

# 集群

##### redis集群实现方式

- 主从复制

```
读写分离
假如 master宕机了, redis 没有实现自动进行主备切换



主从链
  - 从服务器也可以有从服务器
  - 从服务器对从服务器复制和从服务器对主服务器复制唯一区别在于, 如果从服务器X拥有从服务器Y, 那么当从服务器X在执行表步骤4时, 它将断开与从服务器Y的连接, 导致从服务器Y需要重新连接并重新同步
```

- Sentinel 哨兵机制

```
支持集群模式
着眼于高可用, 在 master 宕机时会自动将 slave 提升为master, 继续提供服务。
```

- cluster

```
负载均衡
解决单机redis容量有限的问题, 将数据按一定的规则分配到多台机器。

redis扩容方式
1. 垂直扩容表示通过加内存方式来增加整个缓存体系的容量比如将缓存大小由2G调整到4G,这种扩容不需要应用程序支持；
2. 水平扩容表示表示通过增加节点的方式来增加整个缓存体系的容量比如本来有1个节点变成2个节点, 这种扩容方式需要应用程序支持



分布式集群首要解决把整个数据集按照分区规则映射到多个节点的问题, 即把数据集划分到多个节点上, 每个节点负责整个数据的一个子集。redis Cluster采用哈希分区规则中的虚拟槽分区。
```

##### 复制

```
如果主从服务器之间的网络带宽不足, 或者主服务器没有足够的内存来创建子进程和创建记录写命令的缓冲区, 那么redis 处理命令请求的效率就会受到影响

最好还是让主服务器只使用50%~ 65%的内存, 留下30%~ 45%的内存用于执行BGSAVE命令和创建记录写命令的缓冲区。
从服务器在与主服务器进行初始连接时, 数据库中原有的所有数据都将丢失, 并被替换成主服务器发来的数据。
同时使用复制和AOF持久化将数据持久化到多台机器上面
```

| 步骤 | 主服务器操作                                                 | 从服务器操作                                                 |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | (等待命令进入)                                               | 连接主服务器, 发送SYNC命令                                   |
| 2    | 开始执行bgsave, 并使用缓冲区记录bgsave之后执行的所有命令     | 根据配置选项决定是否继续使用现有的数据处理客户端的命令请求, 还是想发送请求的客户端返回错误 |
| 3    | bgsave执行完毕向从服务器发送快照文件, 期间继续使用缓冲区记录被执行的写命令 | 丢弃所有旧数据, 载入主服务器发来的快照文件                   |
| 4    | 快照文件发送完毕, 开始向从服务器发送存储的缓冲区里的写命令                          完成快照文件解释操作, 并开始接收命令请求 | 完成快照文件解释操作, 并开始接收命令请求                     |
| 5    | 缓冲区存储的写命令发送完毕, 从现在开始每执行一个写命令就向从服务器发送相同的命令 | 执行主服务器发来的所有缓冲区里面的写命令. 从现在开始接收并执行主服务器传来的每个写命令 |

##### 短结构

```
短结构, 分片结构, 打包存储二进制和字节
```



# 连接池

```
通过预先创建多个连接, 当进行redis操作时, 直接获取已经创建的连接进行操作, 而且操作完成后, 不会释放, 用于后续的其他redis操作, 这样就达到了避免频繁的redis连接创建和释放的目的, 从而提高性能。
redis模块采用ConnectionPool来管理对redis server的所有连接


```



# 性能问题

影响 redis 性能的情况

4个方面: 网络, 磁盘, 内存, cpu

```
带宽: 读写, 同步数据都会受到影响
客户端连接数

内存: 
value 的大小
维护定时器
定时删除过期key: cup 资源紧张时删除 key 影响性能


磁盘性能: 如果缓冲区满了网磁盘持久化时, 如果磁盘写入速度不够快, 会阻塞写操作


bgrewriteaof: 重写 aof 文件时, 占用额外内存, 重写的文件过大导致操作系统挂起


```



# redis分布式锁

- 正确做法

```
使用 set key value [EX seconds][PX milliseconds][NX|XX] 命令 (正确做法)
redis在 2.6.12 版本开始, 为 SET 命令增加一系列选项: 
SET key value[EX seconds][PX milliseconds][NX|XX]
    EX seconds: 设定过期时间, 单位为秒
    PX milliseconds: 设定过期时间, 单位为毫秒
    NX: 仅当key不存在时设置值(就等同于setnx命令)
    XX: 仅当key存在时设置值
```

- 1. 使用redis setnx+expire命令 (错误的做法)

```
加锁命令: SETNX key value, 当键不存在时, 对键进行设置操作并返回成功, 否则返回失败。KEY 是锁的唯一标识, 一般按业务来决定命名。
解锁命令: DEL key, 通过删除键值对释放锁, 以便其他线程可以通过 SETNX 命令来获取锁。
锁超时: EXPIRE key timeout, 设置 key 的超时时间, 以保证即使锁没有被显式释放, 锁也可以在一定时间后自动释放, 避免资源被永远锁住。
SETNX 和 EXPIRE 非原子性
如果 SETNX 成功, 在设置锁超时时间后, 服务器挂掉、重启或网络问题等, 导致 EXPIRE 命令没有执行, 锁没有设置超时时间变成死锁。
```

- 2. 锁误解除

```
如果线程 A 成功获取到了锁, 并且设置了过期时间 30 秒, 但线程 A 执行时间超过了 30 秒, 锁过期自动释放, 此时线程 B 获取到了锁；随后 A 执行完成, 线程 A 使用 DEL 命令来释放锁, 但此时线程 B 加的锁还没有执行完成, 线程 A 实际释放的线程 B 加的锁。

通过在 value 中设置当前线程加锁的标识, 在删除之前验证 key 对应的 value 判断锁是否是当前线程持有。可生成一个 UUID 标识当前线程, 使用 lua 脚本做验证标识和解锁操作。
```

- 3. 超时解锁导致并发

```
如果线程 A 成功获取锁并设置过期时间 30 秒, 但线程 A 执行时间超过了 30 秒, 锁过期自动释放, 此时线程 B 获取到了锁, 线程 A 和线程 B 并发执行。

将过期时间设置足够长, 确保代码逻辑在锁释放之前能够执行完成。
为获取锁的线程增加守护线程, 为将要过期但未释放的锁增加有效时间。
```

- 4. 不可重入

```
当线程在持有锁的情况下再次请求加锁, 如果一个锁支持一个线程多次加锁, 那么这个锁就是可重入的。如果一个不可重入锁被再次加锁, 由于该锁已经被持有, 再次加锁会失败。redis 可通过对锁进行重入计数, 加锁时加 1, 解锁时减 1, 当计数归 0 时释放锁。

另一种方式是 redis Map 数据结构来实现分布式锁, 既存锁的标识也对重入次数进行计数
```

- 5. 无法等待锁释放

```

```



```
https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/







5. 无法等待锁释放
上述命令执行都是立即返回的, 如果客户端可以等待锁释放就无法使用。

可以通过客户端轮询的方式解决该问题, 当未获取到锁时, 等待一段时间重新获取锁, 直到成功获取锁或等待超时。这种方式比较消耗服务器资源, 当并发量比较大时, 会影响服务器的效率。
另一种方式是使用 redis 的发布订阅功能, 当获取锁失败时, 订阅锁释放消息, 获取锁成功后释放时, 发送锁释放消息。如下: 



集群
1. 主备切换
为了保证 redis 的可用性, 一般采用主从方式部署。主从数据同步有异步和同步两种方式, redis 将指令记录在本地内存 buffer 中, 然后异步将 buffer 中的指令同步到从节点, 从节点一边执行同步的指令流来达到和主节点一致的状态, 一边向主节点反馈同步情况。

在包含主从模式的集群部署方式中, 当主节点挂掉时, 从节点会取而代之, 但客户端无明显感知。当客户端 A 成功加锁, 指令还未同步, 此时主节点挂掉, 从节点提升为主节点, 新的主节点没有锁的数据, 当客户端 B 加锁时就会成功。


集群脑裂
集群脑裂指因为网络问题, 导致 redis master 节点跟 slave 节点和 sentinel 集群处于不同的网络分区, 因为 sentinel 集群无法感知到 master 的存在, 所以将 slave 节点提升为 master 节点, 此时存在两个不同的 master 节点。redis Cluster 集群部署方式同理。

当不同的客户端连接不同的 master 节点时, 两个客户端可以同时拥有同一把锁。



https://juejin.cn/post/6844903830442737671
```

# 旧

```
redis Sentinel 与 redis Cluster
https://blog.csdn.net/angjunqiang/article/details/81190562
```

##### redis的并发竞争问题如何解决?

```
redis为单进程单线程模式, 采用队列模式将并发访问变为串行访问。redis本身没有锁的概念, redis对于多个客户端连接并不存在竞争
```

##### 事务

```

```

##### redis 二级缓存

```

```

##### Redlock

```

```

##### pipline

```
pipeline就是用来将n次的网络时间优化为一次的网络时间, 耗时为1次网络时间 + n次命令时间


redis原生有类似 mget mset的批量操作命令, 这些命令都是原子的, 即会阻塞其他的命令, 知道命令完成返回。而pipeline的每一条命令是拆分过的（非原子）, 假设打包1000个命令的pipeline传到服务端, 则服务端会把pipeline的每个命令当成原子。但无论是pipeline还是M操作 返回的结果都是一样的。



pipeline与M操作都会将数据顺序的传送顺序地返回（redis 单线程）

1.每次pipeline携带数量不推荐过大, 否则会影响网络性能;
2.pipelinepipeline每次只能作用在一个redis节点上;
```

##### 原生M操作

```

```

# 应用问题

##### 缓存数据库的双写一致性的问题

```


问题：一致性的问题是分布式系统中很常见的问题。一致性一般分为两种：强一致性和最终一致性，当我们要满足强一致性的时候，Redis也无法做到完美无瑕，因为数据库和缓存双写，肯定会出现不一致的情况，Redis只能保证最终一致性。

解决：我们如何保证最终一致性呢？

    第一种方式是给缓存设置一定的过期时间，在缓存过期之后会自动查询数据库，保证数据库和缓存的一致性。如果不设置过期时间的话，我们首先要选取正确的更新策略：先更新数据库再删除缓存。但我们删除缓存的时候也可能出现某些问题，所以需要将要删除的缓存的key放到消息队列中去，不断重试，直到删除成功为止。
```

##### 缓存雪崩问题

```


问题： 我们应该都在电影里看到过雪崩，开始很平静，然后一瞬间就开始崩塌，具有很强的毁灭性。这里也是一样的，我们执行代码的时候将很多缓存的实效时间设定成一样，接着这些缓存在同一时间都会实效，然后都会重新访问数据库更新数据，这样会导致数据库连接数过多、压力过大而崩溃。

解决：

    设置缓存过期时间的时候加一个随机值。设置双缓存，缓存1设置缓存时间，缓存2不设置，1过期后直接返回缓存2，并且启动一个进程去更新缓存1和2。
```

##### 缓存穿透问题

```


问题： 缓存穿透是指一些非正常用户(黑客)故意去请求缓存中不存在的数据，导致所有的请求都集中到到数据库上，从而导致数据库连接异常。

解决:

    利用互斥锁。缓存失效的时候，不能直接访问数据库，而是要先获取到锁，才能去请求数据库。没得到锁，则休眠一段时间后重试。采用异步更新策略。无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。提供一个能迅速判断请求是否有效的拦截机制。比如利用布隆过滤器，内部维护一系列合法有效的key，迅速判断出请求所携带的Key是否合法有效。如果不合法，则直接返回。
```

##### 缓存的并发竞争问题

```
问题：

缓存并发竞争的问题，主要发生在多线程对某个key进行set的时候，这时会出现数据不一致的情况。

比如Redis中我们存着一个key为amount的值，它的value是100，两个线程同时都对value加100然后更新，正确的结果应该是变为300。但是两个线程拿到这个值的时候都是100，最后结果也就是200，这就导致了缓存的并发竞争问题。

解决

    如果多线程操作没有顺序要求的话，我们可以设置一个分布式锁，然后多个线程去争夺锁，谁先抢到锁谁就可以先执行。这个分布式锁可以用zookeeper或者Redis本身去实现。可以利用Redis的incr命令。当我们的多线程操作需要顺序的时候，我们可以设置一个消息队列，把需要的操作加到消息队列中去，严格按照队列的先后执行命令。
```



# 参考

##### 数据类型

- [ ] https://blog.csdn.net/u012060033/article/details/129168155
- [ ] https://zhuanlan.zhihu.com/p/364720565
- [ ] https://zhuanlan.zhihu.com/p/148562122
- [ ] https://blog.csdn.net/qq_31960623/article/details/117911710
- [ ] https://zhuanlan.zhihu.com/p/593111008
- [x] https://zhuanlan.zhihu.com/p/64772193 1
- [ ] https://zhuanlan.zhihu.com/p/68667360 2
- [ ] https://juejin.cn/post/6844903951502934030
- [ ] https://cloud.tencent.com/developer/article/1667574
- [ ] https://cloud.tencent.com/developer/article/1442961?from=article.detail.1667574&areaSource=106000.12&traceId=DA3zaAlbl_6IooH3Cs-sm
- [ ] https://cloud.tencent.com/developer/article/1921542?from=article.detail.1442961&areaSource=106000.8&traceId=iaayeX_P3We0kPNxU543b

##### 基本原理

- [ ] https://zhuanlan.zhihu.com/p/364494952
- [ ] https://cloud.tencent.com/developer/article/1158989?from=article.detail.1442961&areaSource=106000.9&traceId=iaayeX_P3We0kPNxU543b



