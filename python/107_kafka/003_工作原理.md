##### 消息路由策略

```
在通过 API 方式发布消息时，生产者是以 Record 为消息进行发布的。Record 中包含 key与value，value 才是我们真正的消息本身，而 key 用于路由消息所要存放的 Partition。消息要写入到哪个 Partition 并不是随机的，而是有路由策略的。

1) 若指定了 partition，则直接写入到指定的 partition；
2) 若未指定 partition 但指定了 key，则通过对 key 的 hash 值与 partition 数量取模，该取模
结果就是要选出的 partition 索引；
3) 若 partition 和 key 都未指定，则使用轮询算法选出一个 partition
```

##### AR

```
Assigned Repllicas: 一个分区里面所有的副本
```

##### OSR

```
Out-Sync Replicas: 一个分区不能与 leader 保持同步的所有副本
当 follower 同步追上 leader 就会回到ISR集合当中
```

##### ISR

- In-Sync Replicas: 一个分区与 leader 保持同步的所有副本(包含 leader 自己)

- ISR 作用: kafka 为了平衡可靠性和可用性, 通过参数调整集群的可靠性和可用性. 

- 设置参数

  ```
  1. follower 完全同步 leader 所有数据后, 会更新 follower 副本的 lastCaughtUpTimeMs, 定时检查当前时间与副本的lastCaughtUpTimeMs 差值做比较, 大于的副本从 isr 中剔除, 默认10s.
  	rerplica.lag.time.max.ms=10000
  
  如果一个 follower 一直同步 leader 的数据, 但 follower 速度太慢, 一直没有同步完, 这种 follower 也应该从 isr 删除
  
  
  2. (0.9 版本之后弃用)允许 follower 副本落后 leader 副本的消息数量，超过这个数量后，follower 会被踢出
  	replica.lag.max.messages
  ```

  

 

##### 发送消息过程

```
1. producer 向 broker 集群提交连接请求，其所连接上的任意 broker 都会向其发送 broker controller 的通信
2. 当 producer 指定了要生产消息的 topic 后，其会向 broker controller 发送请求，请求当前 topic 中所有 partition 的 leader 列表地址
3. broker controller在接收到请求后，会从 zk中查找到指定 topic 的所有 partition 的 leader，并返回给 producer
4. producer 在接收到 leader 列表地址后，根据消息路由策略找到当前要发送消息所要发送的 partition leader，然后将消息发送给该 leader
5. leader 将消息写入本地 log，并通知 ISR 中的 followers
6. ISR 中的 followers 从 leader 中同步消息后向 leader 发送 ACK
7. leader 收到所有 ISR 中的 followers 的 ACK 后，增加 HW，表示消费者已经可以消费到该位置
```

##### 发送消息可靠性机制

```
生产者向 kafka 发送消息时, 可以选择需要的可靠性级别。通过 acks参数的值进行设置。
0: 只发送不管是否发送成功, 效率最高, 可靠性最低.

1: (默认值)leader 写入成功后马上发送 ack, 无需等待 ISR 中的 follower 同步完成

-1 或 all: 写入 ISR 中所有的副本才算成功


可能 follower 全部都挂了, ISR 中只剩下 leader, 那么此时设置 acks=all 就等价于 acks=1 
min.insync.replicas
	可以配置最少 ISR 中需要多少个副本，才能继续提供写服务。如果设置为 2，一旦 ISR 中的个数小于 2，那么就不再提供写服务，牺牲一定的可用性，来保障这种高可靠的场景需求。
```

##### 消费消息过程

```
1. consumer 向 broker 集群提交连接请求，其所连接上的任意 broker 都会向其发送 broker controller 的通信 URL
2. 当 consumer 指定了要消费的 topic 后，其会向 broker controller 发送 poll 请求
3. broker controller 会为 consumer 分配一个或几个 partition leader，并将该 partitioin 的当前 offset 发送给 consumer
4. consumer 会按照 broker controller 分配的 partition 对其中的消息进行消费
5. 当消费者消费完该条消息后，消费者会向 broker 发送一个该消息已被消费的反馈，即修改消息的 offset
6. 当 broker 接到消费者的 offset 后，会更新到相应的__consumer_offset 中
7. 消费者可以重置 offset，从而可以灵活消费存储在 broker 上的消息
```

##### HW 截断机制

> HW: HighWatermark 高水位，表示 Consumer 可以消费到的最高 partition 偏移量
>
> LEO: Log End Offset，日志最后写入消息的偏移量, 每个分区都有.
>
> 视频: https://v.youku.com/v_show/id_XNDQ4MTA2NjcwMA==.html?spm=a2hbt.13141534.0.13141534

- 定义: 宕机的机器恢复时，将LEO恢复到宕机时HW的位置，然后进行数据同步

- 刚写入 leader 的消息 consumer 不能立刻消费, leader 会等待该消息被所有 ISR 副本后才会更新 HW, 此时消息才能被 consumer 消费
- 如果 leader 接收到了新的消息, ISR 中其它 Follower 正在同步过程中, 还未同步完毕时 leader挂了. 此时就需要选举出新的 leader。若没有HW截断机制，将会导致partition中leader 与 follower 数据的不一致

##### Partition Leader 选举范围

```
当 leader 挂了后 broker controller 会从 ISR 中选一个 follower 成为新的 leader. 但 ISR 中的所有副本都挂了通过 unclean.leader.election.enable 的取值来设置 Leader选举的范围
	false: 必须等待 ISR 列表中有副本活过来才进行新的选举。该策略可靠性有保证，但可用性低。
	true: 选择任何一个没有宕机主机中该 topic 的 partition 副本作为新的 leader，该策略可用性高，但可靠性没有保证。
```

##### 重复消费

```
（1） 同一个 consumer 重复消费
当 Consumer 由于消费能力较低而引发了消费超时时，则可能会形成重复消费。
（2） 不同的 consumer 重复消费
当 Consumer 消费了消息但还未提交 offset 时宕机，则这些已被消费过的消息会被重复消费
```

##### 高性能原因

- 顺序读写: Kafka 将消息写入到了分区 partition 中，而分区中消息是顺序读写的。顺序读写要远快于随机读写。
- 批量发送: Kafka 允许使用批量消息发送模式。（先把每次要发送的消息都放入缓存，根据不同的策略，比如缓存空间满了，在批量一起发送出去）
- 零拷贝：生产者、消费者对于 kafka 中消息的操作是采用零拷贝实现的。（直接操作内核空间）
- 消息压缩：Kafka 支持对消息集合进行压缩

```
Kafka 实现了零拷贝原理来快速移动数据，避免了内核之间的切换。Kafka 可以将数据记录分批发送，从生产者到文件系统（Kafka 主题日志）到消费者，可以端到端的查看这些批次的数据。
批处理能够进行更有效的数据压缩并减少 I/O 延迟，Kafka 采取顺序写入磁盘的方式，避免了随机磁盘寻址的浪费，更多关于磁盘寻址的了解，请参阅 程序员需要了解的硬核知识之磁盘 。
总结一下其实就是四个要点
```

