# 编译文件

##### 生成 .pyc 文件

> 并不是所有的 .py 文件都生成 .pyc 文件

1. 自动生成, 当 py 文件被当做模块调用时会自动生成 .pyc 文件

   ```
   ├── a.py
   ├── a.pyc
   └── b.py
   ```

   - a.py 文件

     ```python
     print('123')
     ```

   - b.py 文件

     ```python
     import a
     ```

2. 使用参数 -m

   ```bash
   $ python a.py -m
   ```

3. 通过代码来生成 pyc文件

   ```python
   # 生成单个 .pyc 文件
   compile(file[, cfile[, dfile[, doraise]]])
   
   # 批量生成pyc文件
   compile_dir(dir[, maxlevels[, ddir[, force[, rx[, quiet]]]]])
   
   import compileall
   compileall.compile_dir(r'H:/game')
   ```

##### 生成 .pyo 文件

```bash
比 pyc 文件性能高

# 是优化过的字节码文件
python -O -m py_compile file.py
```

##### 生成 .pyd 文件

```
只有 windows 平台才有
```

# 解释器

##### py 文件运行步骤

<img src=".\image\py文件运行步骤.png" alt="py文件运行步骤" style="zoom:60%;" />

```python
1. 字节码编译
	运行 .py 文件时, 将 .py 文件编译成字节码后保存为 .pyc 文件
	下一次运行时, 如果 .py 文件没有修改过, 会直接加载 .pyc 文件, 跳过编译步骤
    (生成 .pyc 文件时, 写入了一个 Long 型的变量, 记录最近修改的时间戳. 每次载入之前先检查 .py 文件和 .pyc 文件最后修改日期, 如果不一致则会生成一个新的 pyc 文件)


2. 虚拟机 Python Virtual Machine (PVM), 将 .pyc 文件发送到 PVM 执行
```

##### 解释器种类

```
CPython
PyPy
Psyco
JPython
```



##### 死锁

```
由于一个资源被多次调用, 而多次调用方都未能释放该资源就会造成死锁。
```

# C10K 问题

```

尽管对于现在的硬件而言，C10K早就不再是什么难题（或者说已经变成了C10M——规模扩大了三个数量级），即使不使用特殊的设计，如今的硬件也能承担这个量级的任务，但在2003年，这却是个大问题：在互联网用户较少的早期，一个网络服务通常不会有太多用户，加之大多数的服务不过是提供一个HTML，交互较少，所以往往使用的是一个进程服务一个连接的形式；而进程不仅仅存在进程数限制，还存在进程切换和通讯带来的巨大代价。改用一个线程服务一个连接模型，能够一定程度减少部分开销，但也只是勉强够用而已。更好的解决办法在哪里？许多人都进行了有意义的尝试，其中实践很多并被证明有效的模型之一便是

一个操作系统级线程向多个Client提供服务；利用非阻塞（non-block）或异步（asynchronous）IO；尽量减少内存复制
解决问题的核心，在于减少无效的资源使用（过多的线程）；方式，则是由于IO慢于计算，等待IO的过程应该把资源让出去做其他的事情。借助poll/select/epoll进行网络IO（还包括使用posix-aio/libaio进行磁盘IO），就可以实现这样的服务了。
```

##### 协程部署方式

```
协程框架都设计成 1:N 模式, 即 1 个线程作为 1 个容器里面放置多个协程 
```

# io 多路复用

```
I/O multiplexing (I/O 多路复用 )
event driven IO (事件驱动 IO): select, poll 和 epoll
提高服务器的吞吐能力
在单线程通过记录跟踪每一个 Sock (I/O流) 的状态来同时管理多个 I/O 流


一个进程可以监视多个描述符
某个描述符就绪 (读/写就绪), 能够通知程序进行相应的读写操作

可以基于一个阻塞对象, 同时在多个描述符上等待就绪, 而不是使用多个线程
(每个文件描述符一个线程, 每次new一个线程), 
这样可以大大节省系统资源
```

##### 文件描述符 (套接字描述符)

```
1. File descriptor (fd) 文件描述符, 是一个索引值, 指向内核为每一个进程所维护的该进程打开文件的记录表
2. 只适用于UNIX、Linux这样的操作系统
3. 当程序打开一个现有文件或者创建一个新文件时, 内核向进程返回一个文件描述符
```

##### I/O 模型分类

```
阻塞 I/O 模型: 用户线程在读写时被阻塞
非阻塞 I/O 模型:用户线程不断发起IO请求. 数据未到达时系统返回一状态值; 数据到达后才真正读取数据
I/O 复用模型: 一个线程, 通过记录I/O流的状态来同时管理多个I/O, 可以提高服务器的吞吐能力。
信号驱动 I/O 模型
异步 I/O 模型
```

##### 应用场景

```
I/O 多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取, 它就通知该进程
    （1）当客户处理多个描述字时（一般是交互式输入和网络套接口）, 必须使用I/O复用
    （2）当一个客户同时处理多个套接口时, 而这种情况是可能的, 但很少出现
    （3）如果一个TCP服务器既要处理监听套接口, 又要处理已连接套接口, 一般也要用到I/O复用
    （4）如果一个服务器即要处理TCP, 又要处理UDP, 一般要使用I/O复用
    （5）如果一个服务器要处理多个服务或多个协议, 一般要使用I/O复用
```

##### 传统的多进程并发处理

```
如果 1 个 I/O 流进来, 就开启 1 个进程处理这个 I/O 流. 如果有 100w 个 I/O 流进来, 要开启 100w 个进程一一对应处理这些I/O流, 占用大量资源.
```

##### IO多路复用

```
1. 不新建进程和线程情况下实现并发
2. 与多进程和多线程相比, I/O 多路复用系统开销小, 系统不必创建进程/线程, 也不必维护这些进程/线程, 从而大大减小了系统的开销
```

```
I/O 多路复用就通过一种机制, 可以监视多个描述符, 一旦某个描述符就绪（一般是读就绪或者写就绪）, 能够通知程序进行相应的读写操作。
但 select, poll, epoll本质上都是同步I/O, 因为他们都需要在读写事件就绪后自己负责进行读写, 也就是说这个读写过程是阻塞的, 
而异步I/O则无需自己负责进行读写, 异步I/O的实现会负责把数据从内核拷贝到用户空间。  
```

### select

```
同个进程能同时等待多个文件描述符, 而这些文件描述符其中的任意一个进入读就绪状态, select() 函数就可以返回
1. 时间复杂度 O(n)
2. select 几乎在所有的平台上支持
3. select 仅知道有 I/O 事件发生, 却不知道哪几个发生, select 只能轮询读取/写入数据, 同时处理的流越多轮询时间就越长, 效率较低
4. select 是通过设置或者检查存放 fd 标志位的数据结构
4. select 将用户传入的数组拷贝到内核空间, 然后查询每个 fd 对应的设备状态
5. 需要维护大量 fd, 这样会使得用户空间和内核空间在传递该结构时复制开销大
6. 单个进程可监视的 fd 数量有限制, 与操作系统有关. 32 位默认 1024, 64 位默认 2048
	查看系统限制 cat /proc/sys/fs/file-max
```

### poll

```
1. 时间复杂度O(n)
2. 与 select 本质相同, 只是 poll 基于链表来存储, 没有最大连接数的限制
如果设备就绪则在设备等待队列中加入一项并继续遍历, 如果遍历完所有fd后没有发现就绪设备, 则挂起当前进程, 直到设备就绪或者主动超时, 被唤醒后它又要再次遍历fd
1. 大量的 fd 的数组被整体复制于用户态和内核地址空间之间               
2. poll 还有一个特点是“水平触发”, 如果报告了 fd 后没有被处理, 那么下次 poll 时会再次报告该 fd
```

### epoll

```
1. 时间复杂度O(1)
epoll 采用事件触发的机制, 不使用轮询. epoll 通过 epoll_ctl 注册 fd, 一旦该 fd 就绪, 内核就会采用类似 callback 的回调机制来激活该 fd, epoll_wait 便可以收到通知
每个事件关联上 fd
给套接字注册回调函数, 当他们活跃时自动完成相关操作
创建 epoll 对象并注册事件监听具体事件, 以达到事件发生时触发任务的执行
```

##### epoll 两种触发模式

- LT

  ```
  1. epollLT 默认模式
  2. 只要这个 fd 还有数据可读, 每次 epoll_wait 都会返回它的事件, 提醒用户程序去操作
  ```

- ET

  ```
  1. epollET 边缘触发模式
  2. 只会提示一次, 直到下次再有数据流入之前都不会再提示了, 无论fd中是否还有数据可读. 即 read 一个 fd 时把它的 buffer 读光, 直到 read 的返回值小于请求值, 或遇到 EAGAIN 错误
  ```

##### tornado 异步原理

```
tornado 底层通过epoll监听其监听列表中的所有soket, epoll是linux操作系统提供的监听多个socket的接口, 因为epool ioloop可以同时监听上千个socket, 加上ioloop的异步机制使得tornado成为高并发的webserver
```

### kqueue

# process (进程)

```
Python实现多进程的方式主要有两种,  一种是使用 os库中的fork方法,  另一种 方法是使用multiprocessing库。
这两种方法的区别在千前者仅适用于Unix/Linux操作系统, 对Windows 不支持,  后者则是跨平台的实现方式。 由于本人使用的是windows电脑, 因此演示结果只有multiprocessing的, 但是也给出了fork的代码。本文是基于《Python爬虫与项目实践》一书。
```

##### 概念

```
PID: 进程号
TID: 线程号
0 PID：负责切换进程, 开机创建的第一个进程
1 PID：直接或间接创建其他进程, 可以处理孤儿进程

僵尸进程：父进程一般等子进程结束后才结束, 用来处理结束的子进程, 父进已经结束但还没处理的子进程为僵尸进程
孤儿进程：父进程已经结束还没结束的子进程
父进程和子进程哪个先执行不一定

上下文: 在多线程和多进程中记录了某个线程执行的状态，包括线程里用到的各个变量，线程的调用栈等
```

##### 库

```
from multiprocessing import Manager, Pool
from multiprocessing import Process
from multiprocessing import Queue		

multiprocess
# 只在 Unix / Linux / Mac 上运行, windows 不可以
os.fork
```

##### 进程池

```
当需要创建的子进程数量不多时, 可以直接利用multiprocessing中的Process动态成生多个进程。
创建很多进程时用到multiprocessing模块提供的Pool方法。
初始化Pool时, 可以指定一个最大进程数, 当有新的请求提交到Pool中时, 如果池还没有满, 那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到指定的最大值, 那么该请求就会等待, 直到池中有进程结束, 才会创建新的进程来执行。
```

# thread (线程)

##### 特性

> ```
> 一个进程下的子线程与主线程共享同一片数据空间
> 一个线程至少有一个主进程, 主线程结束意味着进程结束了
> 当线程的run()方法结束时该线程完成
> 多线程程序的执行顺序是不确定的, 但可以通过别的方式来影响线程调度的方式。
> ```

##### 线程状态

```
新建 就绪 运行 阻塞 死亡
```

##### 什么是线程

一个进程下的子线程与主线程共享同一片数据空间

一个线程至少有一个主进程, 主线程结束意味着进程结束了

进程是系统正在运行的任务 

##### 避免使用thread模块

```
推荐使用更高级别的threading模块, 而不是用thread模块有很多原因。threading模块更加先进, 有更好的线程支持, 并且thread模块中的一些属性会和threading模块有冲突, 另一个原因是低级别的thread模块拥有的同步原语很少（其实只有一个）, 而threading模块则有很多。
避免使用thread模块的另一个原因是它对于进程何时退出没有控制。当主线程结束时, 所有其他线程也都强制结束, 不会发出警告或者进行适当的清理。如上所述, 至少threading模块能够确保重要的子线程在进程退出前结束（join）
只建议哪些想访问线程的更底层级别的专家使用thread模块。为了增强这点, 在python3中改模块被重命名为_thread。
```

##### 守护线程

```
守护进程: 主进程在其代码结束后就已经算运行完毕了（守护进程在此时就被回收）,然后主进程会一直等非守护的子进程都运行完毕后回收子进程的资源, 否则会产生僵尸进程
守护线程: 主线程在其他非守护线程运行完毕后才算运行完毕（守护线程在此时就被回收）。因为主线程的结束意味着进程的结束, 进程整体的资源都将被回收, 而进程必须保证非守护线程都运行完毕后才能结束。

设置一个线程为守护线程, 就表示你在说这个线程是不重要的, 在进程退出的时候, 不用等待这个线程结束就退出
```

##### ThreadLocal

```
线程自己的全局变量, 别的线程不能用, 多线程中函数传值麻烦

local = threading.local()
def func(name):
    print 'current thread:%s' % threading.currentThread().name
    local.name = name
    print "%s in %s" % (local.name,threading.currentThread().name)
t1 = threading.Thread(target=func,args=('haibo',))
t2 = threading.Thread(target=func,args=('lina',))
t1.start()
t2.start()
t1.join()
t2.join()

current thread:Thread-1
haibo in Thread-1
current thread:Thread-2
lina in Thread-2
```

##### 线程池

```
多线程处理任务不是线程越多越好, 由于在切换线程的时候, 需要切换上下文环境, 依然会造成cpu的大量开销。为解决这个问题, 线程池的概念被提出来了。预先创建好一个较为优化的数量的线程, 让过来的任务立刻能够使用, 就形成了线程池。

线程池是预先创建线程的一种技术。线程池在还没有任务到来之前, 创建一定数量的线程, 放入空闲队列中。这些线程都是处于睡眠状态, 即均为启动, 不消耗 CPU, 而只是占用较小的内存空间。当请求到来之后, 缓冲池给这次请求分配一个空闲线程, 把请求传入此线程中运行, 进行处理。当预先创建的线程都处于运行 状态, 即预制线程不够, 线程池可以自由创建一定数量的新线程, 用于处理更多的请求。当系统比较闲的时候, 也可以通过移除一部分一直处于停用状态的线程
```

##### 生产者消费者模型

```
1、解耦 
假设生产者和消费者分别是两个类。如果让生产者直接调用消费者的某个方法, 那么生产者对于消费者就会产生依赖（也就是耦合）。将来如果消费者的代码发生变化,  可能会影响到生产者。而如果两者都依赖于某个缓冲区, 两者之间不直接依赖, 耦合也就相应降低了。 
2、支持并发 
由于生产者与消费者是两个独立的并发体, 他们之间是用缓冲区作为桥梁连接, 生产者只需要往缓冲区里丢数据, 就可以继续生产下一个数据, 而消费者只需要从缓冲区了拿数据即可, 这样就不会因为彼此的处理速度而发生阻塞。 
3、支持忙闲不均 
缓冲区还有另一个好处。如果制造数据的速度时快时慢, 缓冲区的好处就体现出来了。当数据制造快的时候, 消费者来不及处理, 未处理的数据可以暂时存在缓冲区中。 等生产者的制造速度慢下来, 消费者再慢慢处理掉。
```

##### 信号量

```python

```

##### thrashing (线程颠簸)

```
线程颠簸（thrashing
```

##### 互斥锁

```python
# -*- coding: utf-8 -*-
import threading
import os
import time

class demo():
    def __init__(self, d):
        self.dic = d

    def buy_ticket(self, ):
        time.sleep(2)
        # locks.acquire()
        print('剩余【%s】票' % self.dic['ticket'])
        if self.dic['ticket'] > 0:
            self.dic['ticket'] -= 1
            print('%s购票成功' % os.getpid())
        else:
            print('%s购票失败' % os.getpid())
        # locks.release()

if __name__ == '__main__':
    # locks = threading.Lock()
    d = demo({'ticket': 10})
    for i in range(10):
        t = threading.Thread(target=d.buy_ticket, )
        t.start()
```

## GIL

##### GIL 结构体

```c
typedef struct NRMUTEX {
    LONG owned;
    DWORD thread_id;		// 持有 GIL 锁的线程
    HANDLE hevent;
} NRMUTEX, *PNRMUTEX;
```

##### 是什么

```
1. global interpreter lock 全局解释器锁, 是 CPython 解释器的特性. 因为 CPython 有一部分并不是线程安全的, GIL 为了阻止多个线程同时执行 python 的字节码
2. 同一个进程中, 同一时刻只有 1 个线程能持有 GIL, 线程获取 GIL 后才能被解释器执行, 使得同 1 时刻只有 1 个线程可以执行, 其他线程阻塞, 因此多线程并不是真正的并发
3. 不同进程间各持有 1 个 GIL, 互不干扰
4. 一个线程执行一段时间之后就要释放 GIL 让其他线程有执行的机会, 只有持有 GIL 的线程主动释放, 其他线程才有机会获取 GIL 执行自己的任务
5. 每次释放GIL锁, 线程进行锁竞争、切换线程, 会消耗资源.
```

##### 多线程执行过程

```
0. 线程进行锁竞争
1. 获取GIL
2. 切换进一个线程中去运行
3. 指定数量的字节码指令, 线程主动让出控制权(可以调用time.sleep(0)来完成)
4. 把线程设置会睡眠状态（切换出线程）
5. 释放GIL
6. 重复上述步骤 
```

#####  GIL 释放

- Python3.2 前

  ```
  Python3.2 前
  1. 线程遇见 IO 操作时
  2. ticks 计数达到阈值时
  	sys.setcheckinterval() 设置
  	sys.getswitchinterval() 获取
  	
  存在的问题:
  计算密集型线程释放 GIL 后又会立即去申请 GIL, 通常其它线程还没有调度完它就已经重新获取到了 GIL, 这导致一旦计算密集型线程获得了 GIL, 它很长一段时间内都将占据 GIL, 甚至一直到该线程执行结束
  ```

- Python 3.2 后

  ```
  GIL 用超时时间使当前的线程放弃全局锁. 如果当前线程持有 GIL, 且其他线程请求这个锁时, 当前线程就会在 5 毫秒后被强制释放 GIL. 这使单个线程长期占用 GIL 的情况有所好转
  ```

##### CPU 和 I/O 线程

- CPU 密集型线程

  ```
  ticks 计数很快就会达到阈值, 然后触发 GIL 的释放与再竞争, 多个线程来回切换当然是需要消耗资源的, 单线程会比多线程快
  ```

- I/O 密集型线程

  ```
  每当 I/O 阻塞解释器会释放 GIL
  ```

##### 单核心和多核心

```
多核多线程和单核多线程
多核多线程比单核多线程更差, 
单核下多线程, 每次释放GIL, 唤醒的那个线程都能获取到GIL锁, 所以能够无缝执行
但多核下, CPU-1释放GIL后, 其他CPU上的线程都会进行竞争, 但GIL可能会马上又被CPU0拿到, 导致其他几个CPU上被唤醒后的线程会醒着等待到切换时间后又进入待调度状态, 这样会造成线程颠簸(thrashing), 导致效率更低
```

##### 互斥锁和GIL锁的关系

- GIL锁: 保证同一时刻只有一个线程能使用到cpu
- 互斥锁: 多线程时, 保证在同一时间数据只被一个线程所持有, 保证线程的数据安全

```
假设1个进程有2个线程 Thread1,Thread2, 要修改共享的数据data, 并且有互斥锁
- 1. 假设Thread1获得GIL可以使用cpu, 这时Thread1获得互斥锁LOCK, Thread1可以改data数据(但并没有开始修改数据)
- 2. Thread1修改data数据前发生了I/O操作或者ticks计数满100, 这个时候 Thread1 让出了GIL
- 3. Thread1 和 Thread2 开始竞争 GIL
- 4. 设Thread2正好获得了GIL, 运行代码去修改共享数据date,由于Thread1有互斥锁lock, 所以Thread2无法更改共享数据date,这时Thread2让出GIL锁 , GIL锁再次发生竞争 
- 5. 假设Thread1又抢到GIL, 由于其有互斥锁Lock所以其可以继续修改共享数据data,当Thread1修改完数据释放互斥锁lock,Thread2在获得GIL与lock后才可对data进行修改
```

##### 避免 GIL 影响

```
使用更高版本Python（对GIL机制进行了优化）
使用多进程替换多线程（多进程之间没有GIL，但是进程本身的资源消耗较多）
指定cpu运行线程（使用affinity模块）
使用Jython、IronPython等无GIL解释器
全IO密集型任务时才使用多线程
使用协程（高效的单线程模式，也称微线程；通常与多进程配合使用）
将关键组件用C/C++编写为Python扩展，通过ctypes使Python程序直接调用C语言编译的动态链接库的导出函数。（with nogil调出GIL限制）
```

# coroutines (协程)

##### 概述

```
1. 同一线程内, 函数可以在执行时中断, 保存当前函数的一些临时变量等信息, 切换到另外一个函数中执行, 接着回到之前中断的地方继续开始执行, 这个过程称为协程
2. 可保留运行时的状态数据
是比线程更小的执行单元


3. 调度方式:
可出让自己的执行权, 当重新获得执行权时从上一次暂停的位置继续执行
也就是每个协程池里面有一个调度器, 这个调度器是被动调度的
当一个协程执行 IO 操作时, 这个协程通知调度器, 调度器根据调度算法找到当前最需要CPU的协程。 
切换这个协程的CPU上下文把CPU的运行权交个这个协程, 直到这个协程出现执行不下去需要等等的情况, 或者它调用主动让出CPU的API之类, 触发下一次调度。




- 协程拥有自己的寄存器上下文和栈。协程调度切换时, 将寄存器上下文和栈保存到其他地方, 在切回来的时候, 恢复先前保存的寄存器上下文和栈。因此：协程能保留上一次调用时的状态（即所有局部状态的一个特定组合）, 每次过程重入时, 就相当于进入上一次调用的状态


优势
无需线程上下文切换的开销, 协程避免了无意义的调度, 由此可以提高性能, 协程的调度完全由用户控制, 发生在用户空间而非内核空间, 因此切换的代价非常的小。
无需原子操作锁定及同步的开销
方便切换控制流, 简化编程模型
高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。
一个线程可以有多个协程, 当任务被堵塞的时候执行下一个任务, 当恢复的时候再回来执行这个任务, 任务之间的切换只需要保存每个任务的上下文内容, 这样就完全没有内核切换的开销, 可以不加锁的访问全局变量, 所以上下文的切换非常快


缺点
	协程在同一个线程之内的的任务调度, 本质是个单线程, 无法利用多核资源, 与进程配合才能运行在多 CPU 上
```

##### 状态

```

```

##### 生成器和迭代器

##### 生成器实现协成

```python
协程底层是用生成器实现的
# cpu只是切换执行的函数调用就完成了任务。
import time

def A():
    while True:
        print("----A---")
        yield
        time.sleep(0.5)

def B(c):
    while True:
        print("----B---")
        c.next()
        time.sleep(0.5)

if __name__=='__main__':
    a = A()
    B(a)
    
运行结果    
--B--
--A--
--B--
--A--
--B--
--A--
```

greenlet

```python
为了更好使用协程来完成多任务, python中的greenlet模块对其封装, 从而使得切换任务变的更加简单
安装greenlet模块:sudo pip install greenlet

#coding=utf-8

from greenlet import greenlet
import time

def test1():
    while True:
        print "---A--"
        gr2.switch() #切换到gr2中运行, 再切换回来的时候从下面一句开始执行
        time.sleep(0.5)

def test2():
    while True:
        print "---B--"
        gr1.switch() #切换到gr1中运行
        time.sleep(0.5)

gr1 = greenlet(test1)
gr2 = greenlet(test2)

#切换到gr1中运行
gr1.switch()

---A--
---B--
---A--
---B--
---A--
---B--
```

gevent

```python
greenlet已经实现了协程, 但是这个还的人工切换, gevent能够自动切换任务的模块。

gevent在执行时遇到耗时操作自动切换执行别的协程, 会交出cpu使用, 以此类推。当所有的协成都到了耗时操作了没的切换了, 那就等耗时操作完成。
系统能自动识别哪些操作属于耗时操作。
没有耗时操作不会自动切换。

安装gevent模块:sudo pip install gevent
--------------------------------------------
这个不会切换任务执行
#coding=utf-8
#用python 2 来执行此程序
import gevent

def f(n):
    for i in range(n):
        print gevent.getcurrent(), i

# 创建一个对象来执行f函数。
g1 = gevent.spawn(f, 5)
g2 = gevent.spawn(f, 5)
g3 = gevent.spawn(f, 5)
# 清理资源
g1.join() 
g2.join()
g3.join()    
运行结果
<Greenlet "Greenlet-0" at 0x7f4447d8f050: f(5)> 0
<Greenlet "Greenlet-0" at 0x7f4447d8f050: f(5)> 1
<Greenlet "Greenlet-0" at 0x7f4447d8f050: f(5)> 2
<Greenlet "Greenlet-0" at 0x7f4447d8f050: f(5)> 3
<Greenlet "Greenlet-0" at 0x7f4447d8f050: f(5)> 4
<Greenlet "Greenlet-1" at 0x7f4447d8f158: f(5)> 0
<Greenlet "Greenlet-1" at 0x7f4447d8f158: f(5)> 1
<Greenlet "Greenlet-1" at 0x7f4447d8f158: f(5)> 2
<Greenlet "Greenlet-1" at 0x7f4447d8f158: f(5)> 3
<Greenlet "Greenlet-1" at 0x7f4447d8f158: f(5)> 4
<Greenlet "Greenlet-2" at 0x7f4447d8f260: f(5)> 0
<Greenlet "Greenlet-2" at 0x7f4447d8f260: f(5)> 1
<Greenlet "Greenlet-2" at 0x7f4447d8f260: f(5)> 2
<Greenlet "Greenlet-2" at 0x7f4447d8f260: f(5)> 3
<Greenlet "Greenlet-2" at 0x7f4447d8f260: f(5)> 4

--------------------------------------------
切换任务执行：在执行到IO操作时, gevent自动切换
import gevent

def f(n):
    for i in range(n):
        print gevent.getcurrent(), i
        # 这是一个耗时操作。
        gevent.sleep(1)

g1 = gevent.spawn(f, 5)
g2 = gevent.spawn(f, 5)
g3 = gevent.spawn(f, 5)
g1.join()
g2.join()
g3.join()
运行结果
<Greenlet "Greenlet-0" at 0x7f9f995da050: f(5)> 0
<Greenlet "Greenlet-1" at 0x7f9f995da158: f(5)> 0
<Greenlet "Greenlet-2" at 0x7f9f995da260: f(5)> 0
<Greenlet "Greenlet-0" at 0x7f9f995da050: f(5)> 1
<Greenlet "Greenlet-1" at 0x7f9f995da158: f(5)> 1
<Greenlet "Greenlet-2" at 0x7f9f995da260: f(5)> 1
<Greenlet "Greenlet-0" at 0x7f9f995da050: f(5)> 2
<Greenlet "Greenlet-2" at 0x7f9f995da260: f(5)> 2
<Greenlet "Greenlet-1" at 0x7f9f995da158: f(5)> 2
<Greenlet "Greenlet-0" at 0x7f9f995da050: f(5)> 3
<Greenlet "Greenlet-1" at 0x7f9f995da158: f(5)> 3
<Greenlet "Greenlet-2" at 0x7f9f995da260: f(5)> 3
<Greenlet "Greenlet-0" at 0x7f9f995da050: f(5)> 4
<Greenlet "Greenlet-2" at 0x7f9f995da260: f(5)> 4
<Greenlet "Greenlet-1" at 0x7f9f995da158: f(5)> 4
--------------------------------------------
gevent版-TCP服务器, 单进程单线程完成并发
在执行到IO操作时, gevent自动切换
import sys
import time
import gevent

from gevent import socket,monkey
# 写在最前面
# gevent完成并发服务器需要写这句话, 他在运行过程中修改python源代码。
monkey.patch_all()

def handle_request(conn):
    while True:
        # recv等待接收消息, 耗时操作, 不会阻塞, 而是切换协程
        data = conn.recv(1024)
        if not data:
            conn.close()
            break
        print("recv:", data)
        conn.send(data)


def server(port):
    s = socket.socket()
    s.bind(('', port))
    s.listen(5)
    while True:
        # 如果时第一次执行到这里还没有创建协成, 没法切换, 就一直等, 直到有客户端来连接
        # 当有协程了, accept等待客户端连接, 耗时操作, 不会阻塞而是切换协成执行。
        cli, addr = s.accept()
        # 创建协程
        gevent.spawn(handle_request, cli)

if __name__ == '__main__':
    server(7788)

# 使用gevent的socket, 不能使用socket模块的socket。gevent进行了重写。
# 携程切换会从上次切换的位置继续执行。
```

##### 异步编程



## greenlet

```
greenlet，是一个第三方模块，用于实现协程代码（Gevent协程就是基于greenlet实现）；
```

## yield

```
yield，生成器，借助生成器的特点也可以实现协程代码；
```

## asyncio

```
asyncio，在Python3.4中引入的模块用于编写协程代码；
```

## async

```
async / awiat: Python 3.5 引入, 结合 asyncio 模块使用
```



##### 异步函数

```
1. 函数前面加上 async 就是异步函数, 函数里面可以使用 await
2. await 后面必须跟一个 awaitable 类型或者具有 __await__ 属性的对象
3. sleep() 不是 awaitable, 会导致线程阻塞, 使用asyncio 库的 sleep()
    await asyncio.sleep(3)
```

##### asyncio 控制事件循环

```python
# 得到当前上下文的事件循环
loop = asyncio.get_event_loop()
# 延后 time_delay 秒再执行 callback 方法
loop.call_later(time_delay, callback, argument)
# 尽可能快调用 callback, call_soon() 函数结束主线程回到事件循环之后就会马上调用 callback
loop.call_soon(callback, argument)
# 以float类型返回当前时间循环的内部时间
loop.time()
# 为当前上下文设置事件循环
asyncio.set_event_loop()
# 根据此策略创建一个新的事件循环并返回
asyncio.new_event_loop()
# 在调用 stop() 之前将一直运行
loop.run_forever()
```

##### 异步生成器

```

```

##### 执行过程

```
异步函数不能直接执行, 需要使用事件循环

    创建一个事件循环
    将异步函数加入事件队列
    执行事件队列, 直到最晚的一个事件被处理完毕后结束
    最后建议用 close() 方法关闭事件循环, 以彻底清理 loop 对象防止误用


event loops: 跟踪和调度所有异步任务
coroutines: 对具体执行任务的封装
futures: coroutines 的执行结果

1. 首先事件循环启动之后，会从任务队列获取第一个要执行的 coroutine，并随之创建对应 task 和 future
2. 然后随着task的执行，当遇到coroutine内部需要切换任务的地方，task的执行就会暂停并释放执行线程给event loop，event loop接着会获取下一个待执行的coroutine，并进行相关的初始化之后，执行这个task;

3. 随着event loop执行完队列中的最后一个coroutine才会切换到第一个coroutine;
4. 随着task的执行结束，event loops会将task清除出队列，对应的执行结果会同步到future中，这个过程会持续到所有的task执行结束;
```

##### 实现异步编程的方式

```
https://www.jianshu.com/p/beb147e27041
gevent
yield (弃用)
asyncio.coroutine (弃用)
async, await (3.7 之后这是原生方式, 推荐用这个)
```

##### even loop 事件循环

```
1、事件循环是在线程中执行
2、从队列中取得任务
3、每个任务在协程中执行下一步动作
4、如果在一个协程中调用另一个协程（await ），会触发上下文切换，挂起当前协程，并保存现场环境（变量，状态），然后载入被调用协程
5、如果协程的执行到阻塞部分（阻塞I/O，Sleep），当前协程会挂起，并将控制权返回到线程的消息循环中，然后消息循环继续从队列中执行下一个任务．．．以此类推
6、队列中的所有任务执行完毕后，消息循环返回第一个任务
```

##### Coroutine (协程对象)

```
1. 协程对象: 通过调用协程函数返回的对象
2. 协程对象本质上是一个函数, 指一个使用 async 关键字定义的函数, 它的调用不会立即执行函数, 而是会返回一个协程对象。协程对象由事件循环调用.
3. await 只能用在协程对象里, 用于中断当前协程的执行, event loop 会执行其他携程
4. await 后边的表达式需要返回 waitable 的对象
```

##### Awaitables

```
Awaitables 可等待对象. 主要有三种类型 :coroutine, Task, Future
实现 __await__() 的对象
```

##### Futures

```
它和task上没有本质的区别

1. 代表携程任务执行的结果, 可能还没开始执行, 异步操作结束后会赋值给这个 Future 对象上
2. Future对象有一个result属性，用于存放未来的执行结果。
3. 还有个set_result()方法，是用于设置result的，并且会在给result绑定值以后运行事先给Future对象添加的回调
4. 回调是通过Future对象的add_done_callback()方法添加的。
5. Future 是协程的封装
```

##### future 状态

```
Pending：就绪
Running：运行
Done：完成
Cancelled：取消
```

##### Task

```
1. Task 是 Future 的子类, 提供了回调/取消的方法
2. 一个事件循环每次运行一个Task对象当一个Task对象等待一个Future对象完成时，该事件循环会运行其他Task、回调或执行IO操作

创建 task 方法 (Python 3.7 中被加入)
future1= asyncio.create_task(my_coroutine)
```

# 者区别

```
依赖关系
进程至少有一个线程



进程是资源分配的最小单位，线程是CPU调度的最小单位

进程
资源分配的基本单位, 进程的资源记录在进程控制块 PCB 中


进程也是抢占处理机的调度单位，它拥有一个完整的虚拟地址空间。当进程发生调度时，不同的进程拥有不同的虚拟地址空间，而同一进程内的不同线程共享同一地址空间。



线程属于某个进程, 并与进程内的其他线程一起共享进程的资源
线程只由相关堆栈（系统栈或用户栈）寄存器和线程控制表TCB组成。
寄存器可被用来存储线程内的局部变量，但不能存储其他线程的相关变量。




线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统内多个程序间并发执行的程度，从而显著提高系统资源的利用率和吞吐量。
```

##### 资源占用

```
占用资源: 进程 > 线程 > 协程


进程

不共享任何状态
调度由操作系统完成
有独立的内存空间
通讯主要通过信号传递的方式来实现（实现方式有多种，信号量、管道、事件等，通讯都需要过内核，效率低）

线程
共享变量（解决了通讯麻烦的问题，但是对于变量的访问需要加锁）
调度由操作系统完成（由于共享内存，上下文切换变得高效）
一个进程可以有多个线程，每个线程会共享父进程的资源（创建线程开销占用比进程小很多，可创建的数量也会很多）
通讯除了可使用进程间通讯的方式，还可以通过共享内存的方式进行通信（通过共享内存通信比通过内核要快很多）

协程
调度完全由用户控制
一个线程（进程）可以有多个协程
每个线程（进程）循环按照指定的任务清单顺序完成不同的任务（当任务被堵塞时，执行下一个任务；当恢复时，再回来执行这个任务；任务间切换只需要保存任务的上下文，没有内核的开销，可以不加锁的访问全局变量）
协程需要保证是非堵塞的且没有相互依赖
协程基本上不能同步通讯，多采用异步的消息通讯，效率比较高

总结
进程拥有自己独立的堆和栈，既不共享堆，亦不共享栈，进程由操作系统调度
线程拥有自己独立的栈和共享的堆，共享堆，不共享栈，线程亦由操作系统调度(标准线程是的)
协程和线程一样共享堆，不共享栈，协程由程序员在协程的代码里显示调度




主线程会等待所有的子线程结束后才结束
每个线程一定会有一个名字, 尽管上面的例子中没有指定线程对象的name, 但是python会自动为线程指定一个名字。

进程线程对比
一个程序至少有一个进程,一个进程至少有一个线程.
线程的划分尺度小于进程(资源比进程少), 使得多线程程序的并发性高。
进程在执行过程中拥有独立的内存单元, 而多个线程共享内存, 从而极大地提高了程序的运行效率
线线程不能够独立执行, 必须依存在进程中



一个进程可以包含多个线程
不同进程间数据很难共享
同一进程下不同线程间数据很易共享
进程要比线程消耗更多的计算机资源
进程间不会相互影响，一个线程挂掉将导致整个进程挂掉
进程可以拓展到多机，进程最多适合多核
进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存－”互斥锁（mutex）”
进程使用的内存地址可以限定使用量－“信号量（semaphore）”
```

##### 调度方式

```
1. 进程和线程由操作系统内核调度, 
2. 协程可以自己决定代码执行到哪里切换,


协程的创建、切换发生在用户态
协程的调度由应用自身决定, 协程让出执行机会时才会换出；协程确认已经准备好时才会换入
协程的存在对于操作系统而言是不可知的，所以协程也没必要通知内核，协程的切换无需进入内核态进行调度，也无需保留系统线程必须的其他资源，只需要调整上下文即可，切换几个寄存器和少量状态量的开销仅仅是数ns而已；
协程是应用自身实现的，协程换出是程序确认需要换出时才会发生，换入也可以到应用确实结束等待时再换入，可以减少无意义的切换。换而言之，使用协程（或者叫用户态线程）的线程创建、调度的开销会远低于操作系统线程。



协程和线程差异
线程切换从系统层面远不止保存和恢复CPU上下文这么简单。操作系统为了程序运行的高效性每个线程都有自己缓存Cache等等数据, 操作系统还会帮你做这些数据的恢复操作。 所以线程的切换非常耗性能。
协程的切换只是单纯的操作CPU的上下文, 所以一秒钟切换个上百万次系统都抗的住。



X86 CPU存在特权等级区分，用户态应用运行在 Ring3 上，而内核则运行在 Ring0 上。
一次线程创建，甚至切换，都需要进入到内核态，切换到内核栈，完成相应的计算和资源分配后，再次回到用户态，切换线程栈，进而切换到新的线程，这一进一出就需要进行两次栈切换；
操作系统切换线程，除了替换掉栈帧寄存器，还需要保存其他一系列用于调度和检查的资源，这使得单次进入内核的调用将会产生百ns甚至数us级别的开销；另外，内核并不确切知道当前线程在做什么，正在忙碌中的线程被换出，却切换到某个线程却发现线程还在等待IO这样的情况无法避免，于是多了很多无意义的切换。
```

##### 适用场景

```
计算密集型：占用大量CPU。用多进程
IO密集型：需要网络功能, 大部分时间在等待数据的到来。用多线程、协程
```

# 参考

```
https://juejin.cn/post/7050773195745411085
https://juejin.cn/post/7050280727207739406#heading-18

I/O 多路复用
    总结: https://www.cnblogs.com/Anker/p/3265058.html
    select: http://www.cnblogs.com/Anker/archive/2013/08/14/3258674.html
    poll: http://www.cnblogs.com/Anker/archive/2013/08/15/3261006.html
    epoll: http://www.cnblogs.com/Anker/archive/2013/08/17/3263780.html
    
    
    
-------------------------------------------------------------------- 协程
https://www.jianshu.com/p/84df78d3225a
https://juejin.cn/post/7108367062463938597
```

### 进程

### 线程

- [ ] https://zhuanlan.zhihu.com/p/477826233 进程和线程比较

### GIL

##### 原理

- [ ] https://cloud.tencent.com/developer/article/1538086?from=10680
- [ ] https://blog.csdn.net/hzrandd/article/details/27231737 (有 GIL 结构代码)

### 携程

##### 原理

- [ ] https://zhuanlan.zhihu.com/p/204965836
- [ ] https://zhuanlan.zhihu.com/p/220025846

##### 实现方式

- [ ] https://blog.csdn.net/weixin_45005677/article/details/122379853
- [ ] https://zhuanlan.zhihu.com/p/96969508

##### 携程池

- [ ] https://blog.csdn.net/shykevin/article/details/90338809
- [ ] http://c.biancheng.net/view/2627.html
- [ ] https://blog.csdn.net/weixin_43968923/article/details/111397237

