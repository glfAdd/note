##### 监控系统分类

> https://www.cnblogs.com/jsjwk/p/10899175.html

```
日志类（Log）
调用链类（Tracing）
度量类（Metrics）
```

##### 调用链监控系统

```
https://blog.csdn.net/crave_shy/article/details/81365668
https://juejin.cn/post/6844903510404759565
https://cloud.tencent.com/developer/article/1431424
```

##### 选型考虑因素

```
部署环境

大数据开发能不能用到

java 部署的服务出现了问题, 如果用docker 部署怎么解决, 结合服务监控系统如何重启
```

## 监控系统简介

##### 监控系统作用

```
实时采集监控数据：包括硬件、操作系统、中间件、应用程序等各个维度的数据。
实时反馈监控状态：通过对采集的数据进行多维度统计和可视化展示，能实时体现监控对象的状态是正常还是异常。
预知故障和告警：能够提前预知故障风险，并及时发出告警信息。
辅助定位故障：提供故障发生时的各项指标数据，辅助故障分析和定位。
辅助性能调优：为性能调优提供数据支持，比如慢 SQL，接口响应时间等。
辅助容量规划：为服务器、中间件以及应用集群的容量规划提供数据支撑。
辅助自动化运维：为自动扩容或者根据配置的 SLA 进行服务降级等智能运维提供数据支撑
```

##### 监控指标确定的依据 

```
了解监控对象的工作原理：要做到对监控对象有基本的了解，清楚它的工作原理。比如想对 JVM 进行监控，你必须清楚 JVM 的堆内存结构和垃圾回收机制

确定监控对象的指标：清楚使用哪些指标来刻画监控对象的状态?比如想对某个接口进行监控，可以采用请求量、耗时、超时量、异常量等指标来衡量

定义合理的报警阈值和等级：达到什么阈值需要告警?对应的故障等级是多少?不需要处理的告警不是好告警，可见定义合理的阈值有多重要，否则只会降低运维效率或者让监控系统失去它的作用

建立完善的故障处理流程：收到故障告警后，一定要有相应的处理流程和 oncall 机制，让故障及时被跟进处理。
```

##### 监控指标

```
硬件监控：电源状态、CPU 状态、机器温度、风扇状态、物理磁盘、raid 状态、内存状态、网卡状态。


服务器基础监控: 
    CPU：单个 CPU 以及整体的使用情况。
    内存：已用内存、可用内存。
    磁盘：磁盘使用率、磁盘读写的吞吐量。
    网络：出口流量、入口流量、TCP 连接状态。


数据库监控: 数据库连接数、QPS、TPS、并行处理的会话数、缓存命中率、主从延时、锁状态、慢查询。


中间件监控: 
    Nginx：活跃连接数、等待连接数、丢弃连接数、请求量、耗时、5XX 错误率。
    Tomcat：最大线程数、当前线程数、请求量、耗时、错误量、堆内存使用情况、GC 次数和耗时。
    缓存：成功连接数、阻塞连接数、已使用内存、内存碎片率、请求量、耗时、缓存命中率。
    消息队列：连接数、队列数、生产速率、消费速率、消息堆积量。


应用监控: 
    HTTP 接口：URL 存活、请求量、耗时、异常量。
    RPC 接口：请求量、耗时、超时量、拒绝量。
    JVM：GC 次数、GC 耗时、各个内存区域的大小、当前线程数、死锁线程数。
    线程池：活跃线程数、任务队列大小、任务执行耗时、拒绝任务数。
    连接池：总连接数、活跃连接数。
    日志监控：访问日志、错误日志。
    业务指标：视业务来定，比如 PV、订单量等
```

##### 监控流程

```
数据采集：采集的方式有很多种，包括日志埋点进行采集(通过 Logstash、Filebeat 等进行上报和解析)，JMX 标准接口输出监控指标，被监控对象提供 REST API 进行数据采集(如 Hadoop、ES)，系统命令行，统一的 SDK 进行侵入式的埋点和上报等。

数据传输：将采集的数据以 TCP、UDP 或者 HTTP 协议的形式上报给监控系统，有主动 Push 模式，也有被动 Pull 模式。

数据存储：有使用 MySQL、Oracle 等 RDBMS 存储的，也有使用时序数据库 RRDTool、OpentTSDB、InfluxDB 存储的，还有使用 HBase 存储的。

数据展示：数据指标的图形化展示。

监控告警：灵活的告警设置，以及支持邮件、短信、IM 等多种通知通道。
```

##### 选型

```
先明确清楚你的监控需求：要监控的对象有哪些?机器数量和监控指标有多少?需要具备什么样的告警功能?

监控是一项长期建设的事情，一开始就想做一个 All In One 的监控解决方案，我觉得没有必要。从成本角度考虑，在初期直接使用开源的监控方案即可，先解决有无问题。

从系统成熟度上看，Zabbix 属于老牌的监控系统，资料多，功能全面且稳定，如果机器数量在几百台以内，不用太担心性能问题，另外，采用数据库分区、SSD 硬盘、Proxy 架构、Push 采集模式都可以提高监控性能。

Zabbix 在服务器监控方面占绝对优势，可以满足 90% 以上的监控场景，但是应用层的监控似乎并不擅长，比如要监控线程池的状态、某个内部接口的执行时间等，这种通常都要做侵入式埋点。相反，新一代的监控系统 Open-Falcon 和 Prometheus 在这一点做得很好。

从整体表现上来看，新一代监控系统也有明显的优势，比如：灵活的数据模型、更成熟的时序数据库、强大的告警功能，如果之前对 Zabbix 这种传统监控没有技术积累，建议使用 Open-Falcon 或者 Prometheus。

Open-Falcon 的核心优势在于数据分片功能，能支撑更多的机器和监控项;Prometheus 则是容器监控方面的标配，有 Google 和 K8s 加持。

Zabbix、Open-Falcon 和 Prometheus 都支持和 Grafana 做快速集成，想要美观且强大的可视化体验，可以和 Grafana 进行组合。
用合适的监控系统解决相应的问题即可，可以多套监控同时使用，这种在企业初期很常见。

到中后期，随着机器数据增加和个性化需求增多(比如希望统一监控平台、打通公司的 CMDB 和组织架构关系)，往往需要二次开发或者通过监控系统提供的 API 做集成，从这点来看，Open-Falcon 或者 Prometheus 更合适。
```





